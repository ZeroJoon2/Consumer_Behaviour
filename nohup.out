[I 2025-02-04 11:39:34.656 ServerApp] jupyter_lsp | extension was successfully linked.
[I 2025-02-04 11:39:34.661 ServerApp] jupyter_server_terminals | extension was successfully linked.
[I 2025-02-04 11:39:34.665 ServerApp] jupyterlab | extension was successfully linked.
[W 2025-02-04 11:39:34.667 JupyterNotebookApp] 'password' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-04 11:39:34.670 ServerApp] ServerApp.password config is deprecated in 2.0. Use PasswordIdentityProvider.hashed_password.
[I 2025-02-04 11:39:34.670 ServerApp] notebook | extension was successfully linked.
[I 2025-02-04 11:39:34.864 ServerApp] notebook_shim | extension was successfully linked.
[I 2025-02-04 11:39:34.902 ServerApp] notebook_shim | extension was successfully loaded.
[I 2025-02-04 11:39:34.904 ServerApp] jupyter_lsp | extension was successfully loaded.
[I 2025-02-04 11:39:34.904 ServerApp] jupyter_server_terminals | extension was successfully loaded.
[I 2025-02-04 11:39:34.906 LabApp] JupyterLab extension loaded from /home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyterlab
[I 2025-02-04 11:39:34.906 LabApp] JupyterLab application directory is /home/ubuntu/anaconda3/envs/Project/share/jupyter/lab
[I 2025-02-04 11:39:34.906 LabApp] Extension Manager is 'pypi'.
[I 2025-02-04 11:39:34.934 ServerApp] jupyterlab | extension was successfully loaded.
[I 2025-02-04 11:39:34.937 ServerApp] notebook | extension was successfully loaded.
[I 2025-02-04 11:39:34.938 ServerApp] Serving notebooks from local directory: /home/lab13/project
[I 2025-02-04 11:39:34.938 ServerApp] Jupyter Server 2.14.2 is running at:
[I 2025-02-04 11:39:34.938 ServerApp] http://ip-172-31-13-81:8917/tree
[I 2025-02-04 11:39:34.938 ServerApp]     http://127.0.0.1:8917/tree
[I 2025-02-04 11:39:34.938 ServerApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[I 2025-02-04 11:39:34.955 ServerApp] Skipped non-installed server(s): bash-language-server, dockerfile-language-server-nodejs, javascript-typescript-langserver, jedi-language-server, julia-language-server, pyright, python-language-server, python-lsp-server, r-languageserver, sql-language-server, texlab, typescript-language-server, unified-language-server, vscode-css-languageserver-bin, vscode-html-languageserver-bin, vscode-json-languageserver-bin, yaml-language-server
[I 2025-02-04 11:39:38.008 ServerApp] Kernel started: 9a7491c4-57f1-4f1f-9d46-1b5761257db7
[I 2025-02-04 11:39:38.478 ServerApp] Connecting to kernel 9a7491c4-57f1-4f1f-9d46-1b5761257db7.
[I 2025-02-04 11:39:38.548 ServerApp] Connecting to kernel 9a7491c4-57f1-4f1f-9d46-1b5761257db7.
[I 2025-02-04 11:39:38.616 ServerApp] Connecting to kernel 9a7491c4-57f1-4f1f-9d46-1b5761257db7.
25/02/04 11:39:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [I 2025-02-04 11:41:26.635 ServerApp] Kernel started: f628f0d5-730b-4f60-b089-8ec1507c7bd9
[I 2025-02-04 11:41:26.636 ServerApp] Kernel shutdown: 9a7491c4-57f1-4f1f-9d46-1b5761257db7
[I 2025-02-04 11:41:29.286 ServerApp] Connecting to kernel f628f0d5-730b-4f60-b089-8ec1507c7bd9.
[I 2025-02-04 11:41:32.880 ServerApp] Kernel restarted: f628f0d5-730b-4f60-b089-8ec1507c7bd9
[I 2025-02-04 11:41:32.914 ServerApp] Starting buffering for f628f0d5-730b-4f60-b089-8ec1507c7bd9:ca2456cb-05bf-4243-8bf6-ab17b59e6150
[I 2025-02-04 11:41:32.944 ServerApp] Connecting to kernel f628f0d5-730b-4f60-b089-8ec1507c7bd9.
[I 2025-02-04 11:41:32.944 ServerApp] Restoring connection for f628f0d5-730b-4f60-b089-8ec1507c7bd9:ca2456cb-05bf-4243-8bf6-ab17b59e6150
[I 2025-02-04 11:41:37.800 ServerApp] Saving file at /YJ/youtube_preprocessing.ipynb
25/02/04 11:41:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [IPKernelApp] WARNING | Parent appears to have exited, shutting down.
[I 2025-02-04 11:43:27.934 ServerApp] jupyter_lsp | extension was successfully linked.
[I 2025-02-04 11:43:27.938 ServerApp] jupyter_server_terminals | extension was successfully linked.
[I 2025-02-04 11:43:27.943 ServerApp] jupyterlab | extension was successfully linked.
[W 2025-02-04 11:43:27.945 JupyterNotebookApp] 'password' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-04 11:43:27.948 ServerApp] ServerApp.password config is deprecated in 2.0. Use PasswordIdentityProvider.hashed_password.
[I 2025-02-04 11:43:27.948 ServerApp] notebook | extension was successfully linked.
[I 2025-02-04 11:43:28.140 ServerApp] notebook_shim | extension was successfully linked.
[I 2025-02-04 11:43:28.177 ServerApp] notebook_shim | extension was successfully loaded.
[I 2025-02-04 11:43:28.179 ServerApp] jupyter_lsp | extension was successfully loaded.
[I 2025-02-04 11:43:28.180 ServerApp] jupyter_server_terminals | extension was successfully loaded.
[I 2025-02-04 11:43:28.182 LabApp] JupyterLab extension loaded from /home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyterlab
[I 2025-02-04 11:43:28.182 LabApp] JupyterLab application directory is /home/ubuntu/anaconda3/envs/Project/share/jupyter/lab
[I 2025-02-04 11:43:28.182 LabApp] Extension Manager is 'pypi'.
[I 2025-02-04 11:43:28.209 ServerApp] jupyterlab | extension was successfully loaded.
[I 2025-02-04 11:43:28.213 ServerApp] notebook | extension was successfully loaded.
[I 2025-02-04 11:43:28.213 ServerApp] Serving notebooks from local directory: /home/lab13/project
[I 2025-02-04 11:43:28.213 ServerApp] Jupyter Server 2.14.2 is running at:
[I 2025-02-04 11:43:28.213 ServerApp] http://ip-172-31-13-81:8917/tree
[I 2025-02-04 11:43:28.213 ServerApp]     http://127.0.0.1:8917/tree
[I 2025-02-04 11:43:28.213 ServerApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[I 2025-02-04 11:43:28.231 ServerApp] Skipped non-installed server(s): bash-language-server, dockerfile-language-server-nodejs, javascript-typescript-langserver, jedi-language-server, julia-language-server, pyright, python-language-server, python-lsp-server, r-languageserver, sql-language-server, texlab, typescript-language-server, unified-language-server, vscode-css-languageserver-bin, vscode-html-languageserver-bin, vscode-json-languageserver-bin, yaml-language-server
[I 2025-02-04 11:43:32.737 ServerApp] Kernel started: bf98f90a-7c57-4747-a087-5a1a5fe20ffc
[I 2025-02-04 11:43:33.178 ServerApp] Connecting to kernel bf98f90a-7c57-4747-a087-5a1a5fe20ffc.
[I 2025-02-04 11:43:33.241 ServerApp] Connecting to kernel bf98f90a-7c57-4747-a087-5a1a5fe20ffc.
[I 2025-02-04 11:43:33.309 ServerApp] Connecting to kernel bf98f90a-7c57-4747-a087-5a1a5fe20ffc.
25/02/04 11:43:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [I 2025-02-04 11:45:33.466 ServerApp] Saving file at /YJ/youtube_preprocessing.ipynb
[I 2025-02-04 11:47:33.618 ServerApp] Saving file at /YJ/youtube_preprocessing.ipynb
[IPKernelApp] WARNING | Parent appears to have exited, shutting down.
[I 2025-02-04 11:53:19.219 ServerApp] jupyter_lsp | extension was successfully linked.
[I 2025-02-04 11:53:19.224 ServerApp] jupyter_server_terminals | extension was successfully linked.
[I 2025-02-04 11:53:19.228 ServerApp] jupyterlab | extension was successfully linked.
[W 2025-02-04 11:53:19.230 JupyterNotebookApp] 'password' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-04 11:53:19.233 ServerApp] ServerApp.password config is deprecated in 2.0. Use PasswordIdentityProvider.hashed_password.
[I 2025-02-04 11:53:19.233 ServerApp] notebook | extension was successfully linked.
[I 2025-02-04 11:53:19.428 ServerApp] notebook_shim | extension was successfully linked.
[I 2025-02-04 11:53:19.466 ServerApp] notebook_shim | extension was successfully loaded.
[I 2025-02-04 11:53:19.467 ServerApp] jupyter_lsp | extension was successfully loaded.
[I 2025-02-04 11:53:19.468 ServerApp] jupyter_server_terminals | extension was successfully loaded.
[I 2025-02-04 11:53:19.470 LabApp] JupyterLab extension loaded from /home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyterlab
[I 2025-02-04 11:53:19.470 LabApp] JupyterLab application directory is /home/ubuntu/anaconda3/envs/Project/share/jupyter/lab
[I 2025-02-04 11:53:19.470 LabApp] Extension Manager is 'pypi'.
[I 2025-02-04 11:53:19.497 ServerApp] jupyterlab | extension was successfully loaded.
[I 2025-02-04 11:53:19.501 ServerApp] notebook | extension was successfully loaded.
[I 2025-02-04 11:53:19.501 ServerApp] Serving notebooks from local directory: /home/lab13/project
[I 2025-02-04 11:53:19.502 ServerApp] Jupyter Server 2.14.2 is running at:
[I 2025-02-04 11:53:19.502 ServerApp] http://ip-172-31-13-81:8917/tree
[I 2025-02-04 11:53:19.502 ServerApp]     http://127.0.0.1:8917/tree
[I 2025-02-04 11:53:19.502 ServerApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[I 2025-02-04 11:53:19.519 ServerApp] Skipped non-installed server(s): bash-language-server, dockerfile-language-server-nodejs, javascript-typescript-langserver, jedi-language-server, julia-language-server, pyright, python-language-server, python-lsp-server, r-languageserver, sql-language-server, texlab, typescript-language-server, unified-language-server, vscode-css-languageserver-bin, vscode-html-languageserver-bin, vscode-json-languageserver-bin, yaml-language-server
[W 2025-02-04 11:53:21.267 ServerApp] 400 GET /api/contents/YJ/df2.parquet?type=file&content=1&hash=1&format=text&1738637600440 (125.129.250.60): /home/lab13/project/YJ/df2.parquet is not UTF-8 encoded
[W 2025-02-04 11:53:21.268 ServerApp] wrote error: '/home/lab13/project/YJ/df2.parquet is not UTF-8 encoded'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_server/services/contents/fileio.py", line 536, in _read_file
        (bcontent.decode("utf8"), "text", bcontent)
    UnicodeDecodeError: 'utf-8' codec can't decode byte 0xdc in position 7: invalid continuation byte
    
    The above exception was the direct cause of the following exception:
    
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_server/services/contents/handlers.py", line 154, in get
        model = await ensure_async(
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_core/utils/__init__.py", line 198, in ensure_async
        result = await obj
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_server/services/contents/filemanager.py", line 926, in get
        model = await self._file_model(
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_server/services/contents/filemanager.py", line 835, in _file_model
        content, format, bytes_content = await self._read_file(os_path, format, raw=True)  # type: ignore[misc]
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_server/services/contents/fileio.py", line 545, in _read_file
        raise HTTPError(
    tornado.web.HTTPError: HTTP 400: bad format (/home/lab13/project/YJ/df2.parquet is not UTF-8 encoded)
[W 2025-02-04 11:53:21.269 ServerApp] 400 GET /api/contents/YJ/df2.parquet?type=file&content=1&hash=1&format=text&1738637600440 (d3510c086d21437a83e97539efffe8c2@125.129.250.60) 4.71ms referer=http://15.168.221.131:8917/tree/YJ
[I 2025-02-04 11:53:24.318 ServerApp] Kernel started: c435ead3-3e73-46e7-8378-7d0876769bb8
[I 2025-02-04 11:53:24.761 ServerApp] Connecting to kernel c435ead3-3e73-46e7-8378-7d0876769bb8.
[I 2025-02-04 11:53:24.844 ServerApp] Connecting to kernel c435ead3-3e73-46e7-8378-7d0876769bb8.
[I 2025-02-04 11:53:24.913 ServerApp] Connecting to kernel c435ead3-3e73-46e7-8378-7d0876769bb8.
25/02/04 11:53:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[I 2025-02-04 11:53:30.465 ServerApp] Connecting to kernel c435ead3-3e73-46e7-8378-7d0876769bb8.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [I 2025-02-04 11:55:24.031 ServerApp] Saving file at /YJ/youtube_preprocessing.ipynb
[I 2025-02-04 12:03:25.442 ServerApp] Saving file at /YJ/youtube_preprocessing.ipynb
[IPKernelApp] WARNING | Parent appears to have exited, shutting down.
[W 2025-02-04 12:05:37.834 LabApp] 'ip' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-04 12:05:37.834 LabApp] 'port' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-04 12:05:37.834 LabApp] 'port' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-04 12:05:37.834 LabApp] 'password' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-04 12:05:37.834 LabApp] 'password' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[I 2025-02-04 12:05:37.842 LabApp] JupyterLab extension loaded from /home/ubuntu/anaconda3/lib/python3.7/site-packages/jupyterlab
[I 2025-02-04 12:05:37.842 LabApp] JupyterLab application directory is /home/ubuntu/anaconda3/share/jupyter/lab
[I 12:05:37.846 NotebookApp] Serving notebooks from local directory: /home/lab13/project
[I 12:05:37.846 NotebookApp] Jupyter Notebook 6.4.11 is running at:
[I 12:05:37.846 NotebookApp] http://ip-172-31-13-81:8917/
[I 12:05:37.846 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[I 12:05:40.533 NotebookApp] Kernel started: c67bde05-5911-496a-b0ba-85c270005d20, name: project
[I 12:05:52.320 NotebookApp] Starting buffering for c67bde05-5911-496a-b0ba-85c270005d20:25b3f6e2d3f34945b88ed75b82396729
25/02/04 12:06:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 3:>                                                          (0 + 4) / 5][Stage 3:=======================>                                   (2 + 3) / 5][Stage 3:===================================>                       (3 + 2) / 5][Stage 3:===============================================>           (4 + 1) / 5]                                                                                [Stage 4:>                                                          (0 + 4) / 5][Stage 4:===========>                                               (1 + 4) / 5][Stage 4:=======================>                                   (2 + 3) / 5][Stage 4:===================================>                       (3 + 2) / 5][Stage 4:===============================================>           (4 + 1) / 5]                                                                                [I 12:07:44.900 NotebookApp] Saving file at /YJ/youtube_preprocessing.ipynb
[IPKernelApp] WARNING | Parent appears to have exited, shutting down.
[W 2025-02-04 12:08:16.909 LabApp] 'ip' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-04 12:08:16.909 LabApp] 'port' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-04 12:08:16.909 LabApp] 'port' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-04 12:08:16.909 LabApp] 'password' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-04 12:08:16.909 LabApp] 'password' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[I 2025-02-04 12:08:16.919 LabApp] JupyterLab extension loaded from /home/ubuntu/anaconda3/lib/python3.7/site-packages/jupyterlab
[I 2025-02-04 12:08:16.919 LabApp] JupyterLab application directory is /home/ubuntu/anaconda3/share/jupyter/lab
[I 12:08:16.923 NotebookApp] Serving notebooks from local directory: /home/lab13/project
[I 12:08:16.923 NotebookApp] Jupyter Notebook 6.4.11 is running at:
[I 12:08:16.923 NotebookApp] http://ip-172-31-13-81:8917/
[I 12:08:16.923 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[W 12:08:17.140 NotebookApp] 404 GET /api/kernels/c67bde05-5911-496a-b0ba-85c270005d20/channels?session_id=84fd3a0339c94a0e9e96c33a6f8b0f54 (125.129.250.60): Kernel does not exist: c67bde05-5911-496a-b0ba-85c270005d20
[W 12:08:17.160 NotebookApp] 404 GET /api/kernels/c67bde05-5911-496a-b0ba-85c270005d20/channels?session_id=84fd3a0339c94a0e9e96c33a6f8b0f54 (125.129.250.60) 21.320000ms referer=None
[I 12:08:19.864 NotebookApp] Kernel started: 53de2ffa-08a8-40a3-a940-718224705bf2, name: project
[I 12:08:21.014 NotebookApp] Starting buffering for 53de2ffa-08a8-40a3-a940-718224705bf2:c5bf3accbc8f4c8a89d1475a57be2dff
[W 12:08:21.034 NotebookApp] 404 GET /api/events/subscribe (125.129.250.60) 1.080000ms referer=None
[I 12:08:32.320 NotebookApp] 302 GET / (125.129.250.60) 0.490000ms
[IPKernelApp] WARNING | Parent appears to have exited, shutting down.
[W 2025-02-04 12:09:47.347 LabApp] 'ip' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-04 12:09:47.347 LabApp] 'port' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-04 12:09:47.347 LabApp] 'port' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-04 12:09:47.347 LabApp] 'password' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-04 12:09:47.347 LabApp] 'password' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[I 2025-02-04 12:09:47.354 LabApp] JupyterLab extension loaded from /home/ubuntu/anaconda3/lib/python3.7/site-packages/jupyterlab
[I 2025-02-04 12:09:47.354 LabApp] JupyterLab application directory is /home/ubuntu/anaconda3/share/jupyter/lab
[I 12:09:47.358 NotebookApp] Serving notebooks from local directory: /home/lab13/project
[I 12:09:47.358 NotebookApp] Jupyter Notebook 6.4.11 is running at:
[I 12:09:47.358 NotebookApp] http://ip-172-31-13-81:8917/
[I 12:09:47.358 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[I 12:10:00.941 NotebookApp] Kernel started: da3eb268-8588-4652-821c-c7a95ae79814, name: project
25/02/04 12:10:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [IPKernelApp] WARNING | Parent appears to have exited, shutting down.
[W 2025-02-04 12:11:33.135 LabApp] 'ip' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-04 12:11:33.135 LabApp] 'port' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-04 12:11:33.135 LabApp] 'port' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-04 12:11:33.135 LabApp] 'password' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-04 12:11:33.135 LabApp] 'password' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[I 2025-02-04 12:11:33.143 LabApp] JupyterLab extension loaded from /home/ubuntu/anaconda3/lib/python3.7/site-packages/jupyterlab
[I 2025-02-04 12:11:33.143 LabApp] JupyterLab application directory is /home/ubuntu/anaconda3/share/jupyter/lab
[I 12:11:33.147 NotebookApp] Serving notebooks from local directory: /home/lab13/project
[I 12:11:33.147 NotebookApp] Jupyter Notebook 6.4.11 is running at:
[I 12:11:33.147 NotebookApp] http://ip-172-31-13-81:8917/
[I 12:11:33.147 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[I 12:11:39.008 NotebookApp] Kernel started: a776f755-8e9a-4ad4-bfa4-e1be29e1ad06, name: project
25/02/04 12:11:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [I 12:12:27.140 NotebookApp] Starting buffering for a776f755-8e9a-4ad4-bfa4-e1be29e1ad06:60e22c3c3dc04c4db1dc6995464ad82e
25/02/04 12:12:27 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /tmp/spark-069a2879-68e2-4ad4-a953-ea5d798fc5be/userFiles-eca9ea6c-1f45-45af-b73f-6334adde145a. Falling back to Java IO way
java.io.IOException: Failed to delete: /tmp/spark-069a2879-68e2-4ad4-a953-ea5d798fc5be/userFiles-eca9ea6c-1f45-45af-b73f-6334adde145a
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:171)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:110)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1141)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:105)
	at org.apache.spark.SparkContext.$anonfun$stop$23(SparkContext.scala:2108)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1419)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2108)
	at org.apache.spark.SparkContext.$anonfun$new$37(SparkContext.scala:661)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1996)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
[I 12:12:29.769 NotebookApp] Kernel restarted: a776f755-8e9a-4ad4-bfa4-e1be29e1ad06
[I 12:12:29.830 NotebookApp] Restoring connection for a776f755-8e9a-4ad4-bfa4-e1be29e1ad06:60e22c3c3dc04c4db1dc6995464ad82e
[I 12:12:29.831 NotebookApp] Replaying 2 buffered messages
25/02/04 12:12:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [I 12:13:39.259 NotebookApp] Saving file at /YJ/youtube_preprocessing.ipynb
[IPKernelApp] WARNING | Parent appears to have exited, shutting down.
[W 2025-02-04 13:05:45.178 LabApp] 'ip' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-04 13:05:45.178 LabApp] 'port' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-04 13:05:45.178 LabApp] 'port' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-04 13:05:45.178 LabApp] 'password' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-04 13:05:45.178 LabApp] 'password' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[I 2025-02-04 13:05:45.185 LabApp] JupyterLab extension loaded from /home/ubuntu/anaconda3/lib/python3.7/site-packages/jupyterlab
[I 2025-02-04 13:05:45.185 LabApp] JupyterLab application directory is /home/ubuntu/anaconda3/share/jupyter/lab
[I 13:05:45.190 NotebookApp] Serving notebooks from local directory: /home/lab13/project
[I 13:05:45.190 NotebookApp] Jupyter Notebook 6.4.11 is running at:
[I 13:05:45.190 NotebookApp] http://ip-172-31-13-81:8917/
[I 13:05:45.190 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[I 13:05:48.761 NotebookApp] Kernel started: 2f45d459-f4ff-4e93-8944-c41d74fb2838, name: project
[I 13:05:56.104 NotebookApp] Starting buffering for 2f45d459-f4ff-4e93-8944-c41d74fb2838:6ead7414de8d4e838eb12bc151537f7a
[I 13:05:56.235 NotebookApp] Kernel restarted: 2f45d459-f4ff-4e93-8944-c41d74fb2838
[I 13:05:56.300 NotebookApp] Restoring connection for 2f45d459-f4ff-4e93-8944-c41d74fb2838:6ead7414de8d4e838eb12bc151537f7a
[I 13:05:56.697 NotebookApp] Replaying 3 buffered messages
25/02/04 13:06:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [I 13:07:48.773 NotebookApp] Saving file at /YJ/youtube_preprocessing.ipynb
[I 13:10:24.749 NotebookApp] Kernel started: b6a1c265-347d-4890-a040-4ce894c44456, name: project
[I 13:11:00.566 NotebookApp] Copying YJ/test/pyspark_test.ipynb to /YJ/test
[I 13:11:02.302 NotebookApp] Kernel started: 3f4d0e02-60c9-49f8-82c3-0af127a55ddc, name: project
25/02/04 13:11:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/02/04 13:11:05 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [I 13:11:28.540 NotebookApp] Starting buffering for 3f4d0e02-60c9-49f8-82c3-0af127a55ddc:aba56e25aea541808670371adbe7c116
[I 13:11:31.171 NotebookApp] Kernel restarted: 3f4d0e02-60c9-49f8-82c3-0af127a55ddc
[I 13:11:31.241 NotebookApp] Restoring connection for 3f4d0e02-60c9-49f8-82c3-0af127a55ddc:aba56e25aea541808670371adbe7c116
[I 13:11:31.241 NotebookApp] Replaying 1 buffered messages
25/02/04 13:11:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/02/04 13:11:35 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[I 13:11:49.383 NotebookApp] Saving file at /YJ/youtube_preprocessing.ipynb
[I 13:11:54.759 NotebookApp] Starting buffering for 3f4d0e02-60c9-49f8-82c3-0af127a55ddc:aba56e25aea541808670371adbe7c116
[I 13:11:57.389 NotebookApp] Kernel restarted: 3f4d0e02-60c9-49f8-82c3-0af127a55ddc
[I 13:11:57.458 NotebookApp] Restoring connection for 3f4d0e02-60c9-49f8-82c3-0af127a55ddc:aba56e25aea541808670371adbe7c116
[I 13:11:57.459 NotebookApp] Replaying 1 buffered messages
25/02/04 13:11:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/02/04 13:12:00 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [I 13:12:10.636 NotebookApp] Starting buffering for b6a1c265-347d-4890-a040-4ce894c44456:97463f47afee458e85116d16c5552bc5
[I 13:12:30.573 NotebookApp] Creating new notebook in /YJ
[I 13:12:31.519 NotebookApp] Kernel started: 2f9333de-d2a9-416e-9c07-2b6b6c721c4a, name: project
25/02/04 13:12:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/02/04 13:12:39 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/02/04 13:12:39 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [I 13:12:56.230 NotebookApp] Starting buffering for 3f4d0e02-60c9-49f8-82c3-0af127a55ddc:aba56e25aea541808670371adbe7c116
25/02/04 13:13:39 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/02/04 13:13:39 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
[Stage 3:>                                                          (0 + 4) / 5][I 13:13:49.361 NotebookApp] Saving file at /YJ/youtube_preprocessing.ipynb
[Stage 3:=======================>                                   (2 + 3) / 5][Stage 3:===============================================>           (4 + 1) / 5]                                                                                [I 13:14:32.348 NotebookApp] Saving file at /YJ/Untitled.ipynb
[I 13:14:39.022 NotebookApp] Starting buffering for 2f45d459-f4ff-4e93-8944-c41d74fb2838:6ead7414de8d4e838eb12bc151537f7a
[I 13:15:27.477 NotebookApp] Saving file at /YJ/youtube_preprocessing.py
[IPKernelApp] WARNING | Parent appears to have exited, shutting down.
[IPKernelApp] WARNING | Parent appears to have exited, shutting down.
[IPKernelApp] WARNING | Parent appears to have exited, shutting down.
[IPKernelApp] WARNING | Parent appears to have exited, shutting down.
[I 13:37:42.581 NotebookApp] Serving notebooks from local directory: /home/lab13/project
[I 13:37:42.581 NotebookApp] Jupyter Notebook 6.4.10 is running at:
[I 13:37:42.581 NotebookApp] http://ip-172-31-13-81:8917/
[I 13:37:42.581 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[W 2025-02-04 13:42:59.017 LabApp] 'ip' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-04 13:42:59.017 LabApp] 'port' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-04 13:42:59.017 LabApp] 'port' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-04 13:42:59.017 LabApp] 'password' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-04 13:42:59.018 LabApp] 'password' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[I 2025-02-04 13:42:59.025 LabApp] JupyterLab extension loaded from /home/ubuntu/anaconda3/lib/python3.7/site-packages/jupyterlab
[I 2025-02-04 13:42:59.025 LabApp] JupyterLab application directory is /home/ubuntu/anaconda3/share/jupyter/lab
[I 13:42:59.029 NotebookApp] Serving notebooks from local directory: /home/lab13/project
[I 13:42:59.029 NotebookApp] Jupyter Notebook 6.4.11 is running at:
[I 13:42:59.029 NotebookApp] http://ip-172-31-13-81:8917/
[I 13:42:59.029 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[W 13:43:23.922 NotebookApp] Notebook YJ/youtube_preprocessing2.ipynb is not trusted
[I 13:43:24.045 NotebookApp] Kernel started: db7c7dae-f0e1-4414-9780-e620b44406aa, name: project
25/02/04 13:43:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [I 13:43:53.611 NotebookApp] Creating new notebook in /YJ
[I 13:43:54.533 NotebookApp] Kernel started: 23bb9a89-6945-4d20-84fd-5d55b8c36e78, name: project
25/02/04 13:44:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/02/04 13:44:31 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [IPKernelApp] WARNING | Parent appears to have exited, shutting down.
[IPKernelApp] WARNING | Parent appears to have exited, shutting down.
[W 2025-02-04 13:45:49.768 LabApp] 'ip' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-04 13:45:49.768 LabApp] 'port' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-04 13:45:49.768 LabApp] 'port' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-04 13:45:49.768 LabApp] 'password' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-04 13:45:49.768 LabApp] 'password' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[I 2025-02-04 13:45:49.775 LabApp] JupyterLab extension loaded from /home/ubuntu/anaconda3/lib/python3.7/site-packages/jupyterlab
[I 2025-02-04 13:45:49.775 LabApp] JupyterLab application directory is /home/ubuntu/anaconda3/share/jupyter/lab
[I 13:45:49.779 NotebookApp] Serving notebooks from local directory: /home/lab13/project
[I 13:45:49.779 NotebookApp] Jupyter Notebook 6.4.11 is running at:
[I 13:45:49.779 NotebookApp] http://ip-172-31-13-81:8917/
[I 13:45:49.779 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[W 13:45:50.141 NotebookApp] 404 GET /api/kernels/23bb9a89-6945-4d20-84fd-5d55b8c36e78/channels?session_id=d76c102b9b894dea8a0a454d31a2c36e (125.129.250.60): Kernel does not exist: 23bb9a89-6945-4d20-84fd-5d55b8c36e78
[W 13:45:50.180 NotebookApp] 404 GET /api/kernels/23bb9a89-6945-4d20-84fd-5d55b8c36e78/channels?session_id=d76c102b9b894dea8a0a454d31a2c36e (125.129.250.60) 40.740000ms referer=None
[I 13:45:55.329 NotebookApp] Saving file at /YJ/Untitled.ipynb
[W 13:45:58.763 NotebookApp] Notebook YJ/Untitled.ipynb is not trusted
[I 13:45:58.876 NotebookApp] Kernel started: 0cbca0a8-0991-4e3c-a335-09622a4eab2b, name: project
25/02/04 13:46:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[W 13:46:05.302 NotebookApp] 404 GET /api/kernels/db7c7dae-f0e1-4414-9780-e620b44406aa/channels?session_id=2d4b3c5c9b33474dace290ab5baa82f4 (125.129.250.60): Kernel does not exist: db7c7dae-f0e1-4414-9780-e620b44406aa
[W 13:46:05.303 NotebookApp] 404 GET /api/kernels/db7c7dae-f0e1-4414-9780-e620b44406aa/channels?session_id=2d4b3c5c9b33474dace290ab5baa82f4 (125.129.250.60) 3.190000ms referer=None
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [W 13:46:38.308 NotebookApp] 404 GET /api/kernels/db7c7dae-f0e1-4414-9780-e620b44406aa/channels?session_id=2d4b3c5c9b33474dace290ab5baa82f4 (125.129.250.60): Kernel does not exist: db7c7dae-f0e1-4414-9780-e620b44406aa
[W 13:46:38.308 NotebookApp] 404 GET /api/kernels/db7c7dae-f0e1-4414-9780-e620b44406aa/channels?session_id=2d4b3c5c9b33474dace290ab5baa82f4 (125.129.250.60) 2.180000ms referer=None
[I 13:47:24.315 NotebookApp] Saving file at /YJ/youtube_preprocessing2.ipynb
[W 13:47:43.303 NotebookApp] 404 GET /api/kernels/db7c7dae-f0e1-4414-9780-e620b44406aa/channels?session_id=2d4b3c5c9b33474dace290ab5baa82f4 (125.129.250.60): Kernel does not exist: db7c7dae-f0e1-4414-9780-e620b44406aa
[W 13:47:43.304 NotebookApp] 404 GET /api/kernels/db7c7dae-f0e1-4414-9780-e620b44406aa/channels?session_id=2d4b3c5c9b33474dace290ab5baa82f4 (125.129.250.60) 2.190000ms referer=None
[I 13:47:58.899 NotebookApp] Saving file at /YJ/Untitled.ipynb
[I 13:49:29.487 NotebookApp] Kernel started: 6e3b5913-beb0-4a96-8b44-05eee7a95ccb, name: project
25/02/04 13:49:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/02/04 13:49:33 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [I 13:49:59.328 NotebookApp] Saving file at /YJ/Untitled.ipynb
[W 13:50:08.320 NotebookApp] 404 GET /api/kernels/db7c7dae-f0e1-4414-9780-e620b44406aa/channels?session_id=2d4b3c5c9b33474dace290ab5baa82f4 (125.129.250.60): Kernel does not exist: db7c7dae-f0e1-4414-9780-e620b44406aa
[W 13:50:08.321 NotebookApp] 404 GET /api/kernels/db7c7dae-f0e1-4414-9780-e620b44406aa/channels?session_id=2d4b3c5c9b33474dace290ab5baa82f4 (125.129.250.60) 2.330000ms referer=None
[W 13:50:17.936 NotebookApp] 404 POST /api/kernels/db7c7dae-f0e1-4414-9780-e620b44406aa/interrupt (125.129.250.60): Kernel does not exist: db7c7dae-f0e1-4414-9780-e620b44406aa
[W 13:50:17.936 NotebookApp] Kernel does not exist: db7c7dae-f0e1-4414-9780-e620b44406aa
[W 13:50:17.937 NotebookApp] 404 POST /api/kernels/db7c7dae-f0e1-4414-9780-e620b44406aa/interrupt (125.129.250.60) 1.050000ms referer=http://15.168.221.131:8917/notebooks/YJ/youtube_preprocessing2.ipynb
[W 13:50:18.731 NotebookApp] 404 POST /api/kernels/db7c7dae-f0e1-4414-9780-e620b44406aa/interrupt (125.129.250.60): Kernel does not exist: db7c7dae-f0e1-4414-9780-e620b44406aa
[W 13:50:18.731 NotebookApp] Kernel does not exist: db7c7dae-f0e1-4414-9780-e620b44406aa
[W 13:50:18.732 NotebookApp] 404 POST /api/kernels/db7c7dae-f0e1-4414-9780-e620b44406aa/interrupt (125.129.250.60) 0.910000ms referer=http://15.168.221.131:8917/notebooks/YJ/youtube_preprocessing2.ipynb
[W 13:50:18.889 NotebookApp] 404 POST /api/kernels/db7c7dae-f0e1-4414-9780-e620b44406aa/interrupt (125.129.250.60): Kernel does not exist: db7c7dae-f0e1-4414-9780-e620b44406aa
[W 13:50:18.889 NotebookApp] Kernel does not exist: db7c7dae-f0e1-4414-9780-e620b44406aa
[W 13:50:18.889 NotebookApp] 404 POST /api/kernels/db7c7dae-f0e1-4414-9780-e620b44406aa/interrupt (125.129.250.60) 0.750000ms referer=http://15.168.221.131:8917/notebooks/YJ/youtube_preprocessing2.ipynb
[E 13:50:22.582 NotebookApp] Exception restarting kernel
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/notebook/services/kernels/handlers.py", line 89, in post
        yield maybe_future(km.restart_kernel(kernel_id))
      File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 762, in run
        value = future.result()
      File "/home/ubuntu/anaconda3/lib/python3.7/asyncio/futures.py", line 181, in result
        raise self._exception
      File "/home/ubuntu/anaconda3/lib/python3.7/asyncio/tasks.py", line 249, in __step
        result = coro.send(None)
      File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/notebook/services/kernels/kernelmanager.py", line 313, in restart_kernel
        self._check_kernel_id(kernel_id)
      File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/notebook/services/kernels/kernelmanager.py", line 394, in _check_kernel_id
        raise web.HTTPError(404, f'Kernel does not exist: {kernel_id}')
    tornado.web.HTTPError: HTTP 404: Not Found (Kernel does not exist: db7c7dae-f0e1-4414-9780-e620b44406aa)
[E 13:50:22.588 NotebookApp] {
      "Host": "15.168.221.131:8917",
      "Accept": "application/json, text/javascript, */*; q=0.01",
      "Referer": "http://15.168.221.131:8917/notebooks/YJ/youtube_preprocessing2.ipynb",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/132.0.0.0 Safari/537.36"
    }
[E 13:50:22.588 NotebookApp] 500 POST /api/kernels/db7c7dae-f0e1-4414-9780-e620b44406aa/restart (125.129.250.60) 6.980000ms referer=http://15.168.221.131:8917/notebooks/YJ/youtube_preprocessing2.ipynb
[W 13:50:22.615 NotebookApp] 404 DELETE /api/sessions/04ba3548-69ee-41bb-bacb-71c7924790b0 (125.129.250.60): Session not found: session_id='04ba3548-69ee-41bb-bacb-71c7924790b0'
[W 13:50:22.615 NotebookApp] Session not found: session_id='04ba3548-69ee-41bb-bacb-71c7924790b0'
[W 13:50:22.615 NotebookApp] 404 DELETE /api/sessions/04ba3548-69ee-41bb-bacb-71c7924790b0 (125.129.250.60) 0.930000ms referer=http://15.168.221.131:8917/notebooks/YJ/youtube_preprocessing2.ipynb
[I 13:50:22.662 NotebookApp] Kernel started: dbf36b43-e2f8-4f16-9df7-f30561c83e0d, name: project
25/02/04 13:50:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/02/04 13:50:25 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/02/04 13:50:25 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [I 13:50:49.078 NotebookApp] Starting buffering for dbf36b43-e2f8-4f16-9df7-f30561c83e0d:2d4b3c5c9b33474dace290ab5baa82f4
[I 13:50:51.706 NotebookApp] Kernel restarted: dbf36b43-e2f8-4f16-9df7-f30561c83e0d
[I 13:50:51.769 NotebookApp] Restoring connection for dbf36b43-e2f8-4f16-9df7-f30561c83e0d:2d4b3c5c9b33474dace290ab5baa82f4
[I 13:50:51.769 NotebookApp] Replaying 1 buffered messages
25/02/04 13:50:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/02/04 13:50:54 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/02/04 13:50:54 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [I 13:51:24.041 NotebookApp] Saving file at /YJ/youtube_preprocessing2.ipynb
[I 13:51:30.306 NotebookApp] Saving file at /YJ/test/pyspark_test-Copy1.ipynb
[I 13:51:41.742 NotebookApp] Starting buffering for 6e3b5913-beb0-4a96-8b44-05eee7a95ccb:980da34273b94dac8bce2fb57cdeed11
[I 13:51:44.374 NotebookApp] Kernel restarted: 6e3b5913-beb0-4a96-8b44-05eee7a95ccb
[I 13:51:44.431 NotebookApp] Restoring connection for 6e3b5913-beb0-4a96-8b44-05eee7a95ccb:980da34273b94dac8bce2fb57cdeed11
[I 13:51:44.431 NotebookApp] Replaying 1 buffered messages
25/02/04 13:51:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/02/04 13:51:47 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [I 13:52:17.646 NotebookApp] Starting buffering for 6e3b5913-beb0-4a96-8b44-05eee7a95ccb:980da34273b94dac8bce2fb57cdeed11
[I 13:52:20.278 NotebookApp] Kernel restarted: 6e3b5913-beb0-4a96-8b44-05eee7a95ccb
[I 13:52:20.340 NotebookApp] Restoring connection for 6e3b5913-beb0-4a96-8b44-05eee7a95ccb:980da34273b94dac8bce2fb57cdeed11
[I 13:52:20.340 NotebookApp] Replaying 1 buffered messages
25/02/04 13:52:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/02/04 13:52:24 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[I 13:52:33.295 NotebookApp] Starting buffering for 6e3b5913-beb0-4a96-8b44-05eee7a95ccb:980da34273b94dac8bce2fb57cdeed11
[I 13:52:35.925 NotebookApp] Kernel restarted: 6e3b5913-beb0-4a96-8b44-05eee7a95ccb
[I 13:52:35.989 NotebookApp] Restoring connection for 6e3b5913-beb0-4a96-8b44-05eee7a95ccb:980da34273b94dac8bce2fb57cdeed11
[I 13:52:35.989 NotebookApp] Replaying 1 buffered messages
25/02/04 13:52:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/02/04 13:52:40 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [I 13:52:55.259 NotebookApp] Starting buffering for 0cbca0a8-0991-4e3c-a335-09622a4eab2b:3f1313c19ba14a1eb7759d09cd0ce170
[I 13:52:57.890 NotebookApp] Kernel restarted: 0cbca0a8-0991-4e3c-a335-09622a4eab2b
[I 13:52:57.956 NotebookApp] Restoring connection for 0cbca0a8-0991-4e3c-a335-09622a4eab2b:3f1313c19ba14a1eb7759d09cd0ce170
[I 13:52:57.956 NotebookApp] Replaying 1 buffered messages
25/02/04 13:53:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [I 13:53:24.295 NotebookApp] Saving file at /YJ/youtube_preprocessing2.ipynb
[I 13:53:30.156 NotebookApp] Saving file at /YJ/test/pyspark_test-Copy1.ipynb
[I 13:53:45.268 NotebookApp] Starting buffering for dbf36b43-e2f8-4f16-9df7-f30561c83e0d:2d4b3c5c9b33474dace290ab5baa82f4
[I 13:53:47.898 NotebookApp] Kernel restarted: dbf36b43-e2f8-4f16-9df7-f30561c83e0d
[I 13:53:47.955 NotebookApp] Restoring connection for dbf36b43-e2f8-4f16-9df7-f30561c83e0d:2d4b3c5c9b33474dace290ab5baa82f4
[I 13:53:47.955 NotebookApp] Replaying 1 buffered messages
25/02/04 13:53:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/02/04 13:53:52 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/02/04 13:53:52 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [I 13:53:59.288 NotebookApp] Saving file at /YJ/Untitled.ipynb
25/02/04 13:54:10 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/02/04 13:54:10 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
25/02/04 13:54:32 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/02/04 13:54:32 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
[Stage 3:>                                                          (0 + 4) / 5][Stage 3:=======================>                                   (2 + 3) / 5][Stage 3:===================================>                       (3 + 2) / 5][Stage 3:===============================================>           (4 + 1) / 5]                                                                                [I 13:55:13.541 NotebookApp] Starting buffering for 6e3b5913-beb0-4a96-8b44-05eee7a95ccb:980da34273b94dac8bce2fb57cdeed11
[I 13:55:14.665 NotebookApp] Starting buffering for 0cbca0a8-0991-4e3c-a335-09622a4eab2b:3f1313c19ba14a1eb7759d09cd0ce170
[I 13:55:20.324 NotebookApp] Saving file at /YJ/youtube_preprocessing2.ipynb
[I 13:55:34.552 NotebookApp] Saving file at /YJ/youtube_preprocessing.py
[I 13:55:37.630 NotebookApp] Saving file at /YJ/youtube_preprocessing.py
25/02/04 13:57:01 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/02/04 13:57:01 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
[Stage 3:>                                                          (0 + 4) / 5][Stage 3:===========>                                               (1 + 4) / 5][Stage 3:=======================>                                   (2 + 3) / 5][Stage 3:===================================>                       (3 + 2) / 5][Stage 3:===============================================>           (4 + 1) / 5]                                                                                [I 13:57:24.296 NotebookApp] Saving file at /YJ/youtube_preprocessing2.ipynb
[I 13:57:44.357 NotebookApp] Saving file at /YJ/youtube_preprocessing.py
[I 13:59:24.300 NotebookApp] Saving file at /YJ/youtube_preprocessing2.ipynb
[W 14:03:12.368 NotebookApp] Notebook YJ/youtube_preprocessing.ipynb is not trusted
[I 14:03:12.541 NotebookApp] Kernel started: 9a14f787-5900-454e-a3ed-325c9d60fce0, name: project
[I 14:03:24.078 NotebookApp] Saving file at /YJ/youtube_preprocessing2.ipynb
[I 14:03:46.049 NotebookApp] Starting buffering for dbf36b43-e2f8-4f16-9df7-f30561c83e0d:2d4b3c5c9b33474dace290ab5baa82f4
[I 14:03:48.710 NotebookApp] Kernel restarted: dbf36b43-e2f8-4f16-9df7-f30561c83e0d
[I 14:03:48.778 NotebookApp] Restoring connection for dbf36b43-e2f8-4f16-9df7-f30561c83e0d:2d4b3c5c9b33474dace290ab5baa82f4
[I 14:03:48.778 NotebookApp] Replaying 1 buffered messages
25/02/04 14:03:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [IPKernelApp] WARNING | Parent appears to have exited, shutting down.
[IPKernelApp] WARNING | Parent appears to have exited, shutting down.
[IPKernelApp] WARNING | Parent appears to have exited, shutting down.
[IPKernelApp] WARNING | Parent appears to have exited, shutting down.
[I 2025-02-04 14:06:17.494 ServerApp] jupyter_lsp | extension was successfully linked.
[I 2025-02-04 14:06:17.498 ServerApp] jupyter_server_terminals | extension was successfully linked.
[I 2025-02-04 14:06:17.503 ServerApp] jupyterlab | extension was successfully linked.
[W 2025-02-04 14:06:17.504 JupyterNotebookApp] 'password' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-04 14:06:17.507 ServerApp] ServerApp.password config is deprecated in 2.0. Use PasswordIdentityProvider.hashed_password.
[I 2025-02-04 14:06:17.507 ServerApp] notebook | extension was successfully linked.
[I 2025-02-04 14:06:17.702 ServerApp] notebook_shim | extension was successfully linked.
[I 2025-02-04 14:06:17.740 ServerApp] notebook_shim | extension was successfully loaded.
[I 2025-02-04 14:06:17.742 ServerApp] jupyter_lsp | extension was successfully loaded.
[I 2025-02-04 14:06:17.743 ServerApp] jupyter_server_terminals | extension was successfully loaded.
[I 2025-02-04 14:06:17.745 LabApp] JupyterLab extension loaded from /home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyterlab
[I 2025-02-04 14:06:17.745 LabApp] JupyterLab application directory is /home/ubuntu/anaconda3/envs/Project/share/jupyter/lab
[I 2025-02-04 14:06:17.745 LabApp] Extension Manager is 'pypi'.
[I 2025-02-04 14:06:17.772 ServerApp] jupyterlab | extension was successfully loaded.
[I 2025-02-04 14:06:17.775 ServerApp] notebook | extension was successfully loaded.
[I 2025-02-04 14:06:17.776 ServerApp] Serving notebooks from local directory: /home/lab13/project
[I 2025-02-04 14:06:17.776 ServerApp] Jupyter Server 2.14.2 is running at:
[I 2025-02-04 14:06:17.776 ServerApp] http://ip-172-31-13-81:8917/tree
[I 2025-02-04 14:06:17.776 ServerApp]     http://127.0.0.1:8917/tree
[I 2025-02-04 14:06:17.776 ServerApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[I 2025-02-04 14:06:17.793 ServerApp] Skipped non-installed server(s): bash-language-server, dockerfile-language-server-nodejs, javascript-typescript-langserver, jedi-language-server, julia-language-server, pyright, python-language-server, python-lsp-server, r-languageserver, sql-language-server, texlab, typescript-language-server, unified-language-server, vscode-css-languageserver-bin, vscode-html-languageserver-bin, vscode-json-languageserver-bin, yaml-language-server
[W 2025-02-04 14:06:22.014 ServerApp] Notebook YJ/youtube_preprocessing2.ipynb is not trusted
[I 2025-02-04 14:06:22.378 ServerApp] Kernel started: 5a29a183-e776-4ce1-bffb-da5553afc7ec
[I 2025-02-04 14:06:22.885 ServerApp] Connecting to kernel 5a29a183-e776-4ce1-bffb-da5553afc7ec.
[I 2025-02-04 14:06:22.966 ServerApp] Connecting to kernel 5a29a183-e776-4ce1-bffb-da5553afc7ec.
[I 2025-02-04 14:06:23.037 ServerApp] Connecting to kernel 5a29a183-e776-4ce1-bffb-da5553afc7ec.
25/02/04 14:06:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [I 2025-02-04 14:08:22.230 ServerApp] Saving file at /YJ/youtube_preprocessing2.ipynb
[I 2025-02-04 14:08:41.532 ServerApp] Saving file at /YJ/youtube_preprocessing2.ipynb
[I 2025-02-04 14:08:47.919 ServerApp] Kernel restarted: 5a29a183-e776-4ce1-bffb-da5553afc7ec
[I 2025-02-04 14:08:47.947 ServerApp] Starting buffering for 5a29a183-e776-4ce1-bffb-da5553afc7ec:53c63dd5-b387-422a-acbb-79bf05f1012e
[I 2025-02-04 14:08:47.975 ServerApp] Connecting to kernel 5a29a183-e776-4ce1-bffb-da5553afc7ec.
[I 2025-02-04 14:08:47.975 ServerApp] Restoring connection for 5a29a183-e776-4ce1-bffb-da5553afc7ec:53c63dd5-b387-422a-acbb-79bf05f1012e
[I 2025-02-04 14:08:56.566 ServerApp] Kernel started: c22487bc-16a6-4bfb-abd3-9da453b88190
[I 2025-02-04 14:08:56.567 ServerApp] Kernel shutdown: 5a29a183-e776-4ce1-bffb-da5553afc7ec
[I 2025-02-04 14:08:57.030 ServerApp] Connecting to kernel c22487bc-16a6-4bfb-abd3-9da453b88190.
25/02/04 14:09:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [I 2025-02-04 14:09:57.666 ServerApp] Connecting to kernel c22487bc-16a6-4bfb-abd3-9da453b88190.
[I 2025-02-04 14:10:00.853 ServerApp] Connecting to kernel c22487bc-16a6-4bfb-abd3-9da453b88190.
[I 2025-02-04 14:10:06.126 ServerApp] Connecting to kernel c22487bc-16a6-4bfb-abd3-9da453b88190.
[I 2025-02-04 14:10:06.521 ServerApp] Kernel started: db722577-241e-4d99-9e7e-a995cd7cb2b6
[I 2025-02-04 14:10:06.968 ServerApp] Connecting to kernel db722577-241e-4d99-9e7e-a995cd7cb2b6.
25/02/04 14:10:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/02/04 14:10:09 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [I 2025-02-04 14:10:41.694 ServerApp] Saving file at /YJ/youtube_preprocessing2.ipynb
[I 2025-02-04 14:11:01.113 ServerApp] Creating new notebook in /YJ
[I 2025-02-04 14:11:01.283 ServerApp] Saving file at /YJ/Untitled1.ipynb
[I 2025-02-04 14:11:01.352 ServerApp] Kernel started: 83f76563-f9e5-406c-bffa-4be165b772bb
[I 2025-02-04 14:11:01.818 ServerApp] Connecting to kernel 83f76563-f9e5-406c-bffa-4be165b772bb.
[I 2025-02-04 14:11:01.895 ServerApp] Connecting to kernel 83f76563-f9e5-406c-bffa-4be165b772bb.
[I 2025-02-04 14:11:02.724 ServerApp] Connecting to kernel c22487bc-16a6-4bfb-abd3-9da453b88190.
[I 2025-02-04 14:11:02.785 ServerApp] Connecting to kernel db722577-241e-4d99-9e7e-a995cd7cb2b6.
[I 2025-02-04 14:11:02.885 ServerApp] Connecting to kernel 83f76563-f9e5-406c-bffa-4be165b772bb.
[I 2025-02-04 14:11:03.114 ServerApp] Connecting to kernel 83f76563-f9e5-406c-bffa-4be165b772bb.
[I 2025-02-04 14:11:10.519 ServerApp] Kernel started: 98b723d9-cc74-4ff7-a126-c3d12fd657dc
[I 2025-02-04 14:11:10.520 ServerApp] Kernel shutdown: 83f76563-f9e5-406c-bffa-4be165b772bb
[I 2025-02-04 14:11:10.970 ServerApp] Connecting to kernel 98b723d9-cc74-4ff7-a126-c3d12fd657dc.
25/02/04 14:11:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/02/04 14:11:15 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [I 2025-02-04 14:11:29.947 ServerApp] Starting buffering for db722577-241e-4d99-9e7e-a995cd7cb2b6:433373f9-74b6-402e-847c-867d6a54b498
25/02/04 14:11:35 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[I 2025-02-04 14:12:42.329 ServerApp] Saving file at /YJ/youtube_preprocessing2.ipynb
[I 2025-02-04 14:13:02.944 ServerApp] Saving file at /YJ/Untitled1.ipynb
25/02/04 14:13:17 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/02/04 14:13:36 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[Stage 3:>                                                          (0 + 4) / 5][Stage 3:=======================>                                   (2 + 3) / 5][Stage 3:===================================>                       (3 + 2) / 5][Stage 3:===============================================>           (4 + 1) / 5]                                                                                [I 2025-02-04 14:14:23.001 ServerApp] Saving file at /YJ/youtube_preprocessing.py
[I 2025-02-04 14:14:34.293 ServerApp] Connecting to kernel 98b723d9-cc74-4ff7-a126-c3d12fd657dc.
[I 2025-02-04 14:14:43.272 ServerApp] Saving file at /YJ/youtube_preprocessing2.ipynb
[I 2025-02-04 14:15:03.271 ServerApp] Saving file at /YJ/Untitled1.ipynb
[I 2025-02-04 14:16:59.590 ServerApp] Connecting to kernel c22487bc-16a6-4bfb-abd3-9da453b88190.
[I 2025-02-04 14:16:59.675 ServerApp] Connecting to kernel db722577-241e-4d99-9e7e-a995cd7cb2b6.
[I 2025-02-04 14:16:59.753 ServerApp] Connecting to kernel 98b723d9-cc74-4ff7-a126-c3d12fd657dc.
[I 2025-02-04 14:16:59.841 ServerApp] Starting buffering for db722577-241e-4d99-9e7e-a995cd7cb2b6:d627419a-5ca7-44cd-bae8-23e5b59f8b89
[I 2025-02-04 14:18:21.195 ServerApp] Kernel restarted: c22487bc-16a6-4bfb-abd3-9da453b88190
[I 2025-02-04 14:18:21.228 ServerApp] Starting buffering for c22487bc-16a6-4bfb-abd3-9da453b88190:53c63dd5-b387-422a-acbb-79bf05f1012e
[I 2025-02-04 14:18:21.258 ServerApp] Connecting to kernel c22487bc-16a6-4bfb-abd3-9da453b88190.
[I 2025-02-04 14:18:21.258 ServerApp] Restoring connection for c22487bc-16a6-4bfb-abd3-9da453b88190:53c63dd5-b387-422a-acbb-79bf05f1012e
25/02/04 14:18:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [I 2025-02-04 14:18:45.265 ServerApp] Saving file at /YJ/youtube_preprocessing2.ipynb
[I 2025-02-04 14:18:53.092 ServerApp] Kernel restarted: 98b723d9-cc74-4ff7-a126-c3d12fd657dc
[I 2025-02-04 14:18:53.155 ServerApp] Connecting to kernel 98b723d9-cc74-4ff7-a126-c3d12fd657dc.
25/02/04 14:18:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [I 2025-02-04 14:19:04.276 ServerApp] Saving file at /YJ/Untitled1.ipynb
[I 2025-02-04 14:20:37.679 ServerApp] Connecting to kernel c22487bc-16a6-4bfb-abd3-9da453b88190.
[I 2025-02-04 14:20:37.772 ServerApp] Connecting to kernel db722577-241e-4d99-9e7e-a995cd7cb2b6.
[I 2025-02-04 14:20:37.866 ServerApp] Connecting to kernel 98b723d9-cc74-4ff7-a126-c3d12fd657dc.
[I 2025-02-04 14:20:38.051 ServerApp] Starting buffering for db722577-241e-4d99-9e7e-a995cd7cb2b6:c13ef8bb-2e70-47dd-8dd0-96d6d0a0cd04
[I 2025-02-04 14:20:38.197 ServerApp] Kernel started: be463339-194a-4453-818c-81b854117143
[I 2025-02-04 14:20:38.650 ServerApp] Connecting to kernel be463339-194a-4453-818c-81b854117143.
[I 2025-02-04 14:20:42.190 ServerApp] Starting buffering for be463339-194a-4453-818c-81b854117143:18038214-6f88-49a2-9db4-74ce12bbbee1
25/02/04 14:20:59 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[I 2025-02-04 14:21:04.399 ServerApp] Saving file at /YJ/Untitled1.ipynb
[I 2025-02-04 14:21:08.692 ServerApp] Connecting to kernel c22487bc-16a6-4bfb-abd3-9da453b88190.
[I 2025-02-04 14:21:08.804 ServerApp] Connecting to kernel db722577-241e-4d99-9e7e-a995cd7cb2b6.
[I 2025-02-04 14:21:08.879 ServerApp] Connecting to kernel 98b723d9-cc74-4ff7-a126-c3d12fd657dc.
[I 2025-02-04 14:21:08.959 ServerApp] Connecting to kernel be463339-194a-4453-818c-81b854117143.
[I 2025-02-04 14:21:08.980 ServerApp] Starting buffering for db722577-241e-4d99-9e7e-a995cd7cb2b6:35163078-621f-444a-b432-495e0211b6c5
[I 2025-02-04 14:21:09.081 ServerApp] Starting buffering for be463339-194a-4453-818c-81b854117143:6207a854-e36b-4242-ad6b-b5ec3685a446
[I 2025-02-04 14:21:09.095 ServerApp] Connecting to kernel db722577-241e-4d99-9e7e-a995cd7cb2b6.
[I 2025-02-04 14:22:15.968 ServerApp] Kernel restarted: c22487bc-16a6-4bfb-abd3-9da453b88190
[I 2025-02-04 14:22:16.002 ServerApp] Starting buffering for c22487bc-16a6-4bfb-abd3-9da453b88190:53c63dd5-b387-422a-acbb-79bf05f1012e
[I 2025-02-04 14:22:16.043 ServerApp] Connecting to kernel c22487bc-16a6-4bfb-abd3-9da453b88190.
[I 2025-02-04 14:22:16.044 ServerApp] Restoring connection for c22487bc-16a6-4bfb-abd3-9da453b88190:53c63dd5-b387-422a-acbb-79bf05f1012e
[I 2025-02-04 14:22:23.796 ServerApp] Kernel started: 2f11043f-dcd9-4b2d-9f80-fd8dce8b8d77
[I 2025-02-04 14:22:23.797 ServerApp] Kernel shutdown: c22487bc-16a6-4bfb-abd3-9da453b88190
[I 2025-02-04 14:22:24.298 ServerApp] Connecting to kernel 2f11043f-dcd9-4b2d-9f80-fd8dce8b8d77.
25/02/04 14:22:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 3:>                                                          (0 + 4) / 5][I 2025-02-04 14:22:45.762 ServerApp] Saving file at /YJ/youtube_preprocessing2.ipynb
[Stage 3:===========>                                               (1 + 4) / 5][Stage 3:=======================>                                   (2 + 3) / 5][Stage 3:===================================>                       (3 + 2) / 5][Stage 3:===============================================>           (4 + 1) / 5]                                                                                [I 2025-02-04 14:23:04.702 ServerApp] Saving file at /YJ/youtube_preprocessing.py
[I 2025-02-04 14:23:05.277 ServerApp] Saving file at /YJ/Untitled1.ipynb
[I 2025-02-04 14:23:29.250 ServerApp] Saving file at /YJ/youtube_preprocessing.py
[I 2025-02-04 14:23:30.436 ServerApp] Saving file at /YJ/youtube_preprocessing.py
[I 2025-02-04 14:24:45.889 ServerApp] Saving file at /YJ/youtube_preprocessing2.ipynb
[I 2025-02-04 14:24:55.389 ServerApp] Kernel restarted: 2f11043f-dcd9-4b2d-9f80-fd8dce8b8d77
[I 2025-02-04 14:24:55.423 ServerApp] Starting buffering for 2f11043f-dcd9-4b2d-9f80-fd8dce8b8d77:53c63dd5-b387-422a-acbb-79bf05f1012e
[I 2025-02-04 14:24:55.456 ServerApp] Connecting to kernel 2f11043f-dcd9-4b2d-9f80-fd8dce8b8d77.
[I 2025-02-04 14:24:55.456 ServerApp] Restoring connection for 2f11043f-dcd9-4b2d-9f80-fd8dce8b8d77:53c63dd5-b387-422a-acbb-79bf05f1012e
25/02/04 14:24:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 3:>                                                          (0 + 4) / 5][Stage 3:===========>                                               (1 + 4) / 5][Stage 3:=======================>                                   (2 + 3) / 5][Stage 3:===============================================>           (4 + 1) / 5]                                                                                [I 2025-02-04 14:26:46.254 ServerApp] Saving file at /YJ/youtube_preprocessing2.ipynb
[Stage 3:>                                                          (0 + 4) / 5][Stage 3:===========>                                               (1 + 4) / 5][Stage 3:=======================>                                   (2 + 3) / 5][Stage 3:===================================>                       (3 + 2) / 5][Stage 3:===============================================>           (4 + 1) / 5]                                                                                [I 2025-02-04 14:28:47.266 ServerApp] Saving file at /YJ/youtube_preprocessing2.ipynb
[I 2025-02-04 14:29:32.229 ServerApp] Kernel restarted: 2f11043f-dcd9-4b2d-9f80-fd8dce8b8d77
[I 2025-02-04 14:29:32.264 ServerApp] Starting buffering for 2f11043f-dcd9-4b2d-9f80-fd8dce8b8d77:53c63dd5-b387-422a-acbb-79bf05f1012e
[I 2025-02-04 14:29:32.300 ServerApp] Connecting to kernel 2f11043f-dcd9-4b2d-9f80-fd8dce8b8d77.
[I 2025-02-04 14:29:32.300 ServerApp] Restoring connection for 2f11043f-dcd9-4b2d-9f80-fd8dce8b8d77:53c63dd5-b387-422a-acbb-79bf05f1012e
[I 2025-02-04 14:30:47.389 ServerApp] Saving file at /YJ/youtube_preprocessing2.ipynb
25/02/04 14:48:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 3:>                                                          (0 + 4) / 5][Stage 3:=======================>                                   (2 + 3) / 5][Stage 3:===================================>                       (3 + 2) / 5][Stage 3:===============================================>           (4 + 1) / 5]                                                                                [I 2025-02-04 14:49:25.236 ServerApp] Saving file at /YJ/youtube_preprocessing2.ipynb
[I 2025-02-04 14:55:09.351 ServerApp] Saving file at /YJ/youtube_preprocessing.py
[I 2025-02-04 14:57:03.914 ServerApp] Saving file at /YJ/youtube_preprocessing.py
[I 2025-02-04 14:58:02.203 ServerApp] Saving file at /YJ/youtube_preprocessing.py
[Stage 3:>                                                          (0 + 4) / 5][Stage 3:=======================>                                   (2 + 3) / 5][Stage 3:===================================>                       (3 + 2) / 5][Stage 3:===============================================>           (4 + 1) / 5]                                                                                [I 2025-02-04 14:59:30.222 ServerApp] Saving file at /YJ/youtube_preprocessing2.ipynb
[I 2025-02-04 15:07:20.407 ServerApp] Kernel restarted: 2f11043f-dcd9-4b2d-9f80-fd8dce8b8d77
[I 2025-02-04 15:07:20.436 ServerApp] Starting buffering for 2f11043f-dcd9-4b2d-9f80-fd8dce8b8d77:53c63dd5-b387-422a-acbb-79bf05f1012e
[I 2025-02-04 15:07:20.469 ServerApp] Connecting to kernel 2f11043f-dcd9-4b2d-9f80-fd8dce8b8d77.
[I 2025-02-04 15:07:20.469 ServerApp] Restoring connection for 2f11043f-dcd9-4b2d-9f80-fd8dce8b8d77:53c63dd5-b387-422a-acbb-79bf05f1012e
[W 2025-02-04 15:09:30.045 ServerApp] delete /YJ/YJ
[I 2025-02-04 15:09:34.166 ServerApp] Creating new file in /YJ
[I 2025-02-04 15:09:40.234 ServerApp] Connecting to kernel 2f11043f-dcd9-4b2d-9f80-fd8dce8b8d77.
[I 2025-02-04 15:09:40.303 ServerApp] Connecting to kernel db722577-241e-4d99-9e7e-a995cd7cb2b6.
[I 2025-02-04 15:09:40.375 ServerApp] Connecting to kernel 98b723d9-cc74-4ff7-a126-c3d12fd657dc.
[I 2025-02-04 15:09:40.442 ServerApp] Connecting to kernel be463339-194a-4453-818c-81b854117143.
[I 2025-02-04 15:09:40.539 ServerApp] Starting buffering for be463339-194a-4453-818c-81b854117143:c025e6d3-0395-4af6-9941-0e6f748e5bf5
[I 2025-02-04 15:09:41.483 ServerApp] Saving file at /YJ/test.oy
[I 2025-02-04 15:09:43.955 ServerApp] Saving file at /YJ/test.oy
[I 2025-02-04 15:09:57.155 ServerApp] Saving file at /YJ/test.oy
[I 2025-02-04 15:10:22.394 ServerApp] Connecting to kernel 2f11043f-dcd9-4b2d-9f80-fd8dce8b8d77.
[I 2025-02-04 15:10:22.458 ServerApp] Connecting to kernel db722577-241e-4d99-9e7e-a995cd7cb2b6.
[I 2025-02-04 15:10:22.531 ServerApp] Connecting to kernel 98b723d9-cc74-4ff7-a126-c3d12fd657dc.
[I 2025-02-04 15:10:22.611 ServerApp] Connecting to kernel be463339-194a-4453-818c-81b854117143.
[I 2025-02-04 15:10:22.726 ServerApp] Starting buffering for be463339-194a-4453-818c-81b854117143:9b78a688-3ec5-4e8c-a10c-a64092ede77c
[I 2025-02-04 15:10:26.737 ServerApp] Saving file at /YJ/test.py
[I 2025-02-04 15:10:43.483 ServerApp] Connecting to kernel 2f11043f-dcd9-4b2d-9f80-fd8dce8b8d77.
[I 2025-02-04 15:10:43.545 ServerApp] Connecting to kernel db722577-241e-4d99-9e7e-a995cd7cb2b6.
[I 2025-02-04 15:10:43.614 ServerApp] Connecting to kernel 98b723d9-cc74-4ff7-a126-c3d12fd657dc.
[I 2025-02-04 15:10:43.693 ServerApp] Connecting to kernel be463339-194a-4453-818c-81b854117143.
[I 2025-02-04 15:10:43.804 ServerApp] Starting buffering for be463339-194a-4453-818c-81b854117143:05843cf4-563a-4b29-9924-b6f517d94a27
[I 2025-02-04 15:10:49.892 ServerApp] Creating new file in /YJ
[I 2025-02-04 15:10:55.099 ServerApp] Connecting to kernel 2f11043f-dcd9-4b2d-9f80-fd8dce8b8d77.
[I 2025-02-04 15:10:55.197 ServerApp] Connecting to kernel db722577-241e-4d99-9e7e-a995cd7cb2b6.
[I 2025-02-04 15:10:55.266 ServerApp] Connecting to kernel 98b723d9-cc74-4ff7-a126-c3d12fd657dc.
[I 2025-02-04 15:10:55.339 ServerApp] Connecting to kernel be463339-194a-4453-818c-81b854117143.
[I 2025-02-04 15:10:55.433 ServerApp] Starting buffering for be463339-194a-4453-818c-81b854117143:13d3f925-0c96-448d-aa34-884f618c1ae7
[I 2025-02-04 15:10:56.423 ServerApp] Saving file at /YJ/test2.py
[I 2025-02-04 15:11:18.071 ServerApp] Connecting to kernel 2f11043f-dcd9-4b2d-9f80-fd8dce8b8d77.
[I 2025-02-04 15:11:18.149 ServerApp] Connecting to kernel db722577-241e-4d99-9e7e-a995cd7cb2b6.
[I 2025-02-04 15:11:18.217 ServerApp] Connecting to kernel 98b723d9-cc74-4ff7-a126-c3d12fd657dc.
[I 2025-02-04 15:11:18.287 ServerApp] Connecting to kernel be463339-194a-4453-818c-81b854117143.
[I 2025-02-04 15:11:18.382 ServerApp] Starting buffering for be463339-194a-4453-818c-81b854117143:dec36219-353b-4e25-b4cd-eb1d0d56a508
[I 2025-02-04 15:11:33.155 ServerApp] Saving file at /YJ/test2.py
[I 2025-02-04 15:13:29.737 ServerApp] Saving file at /YJ/test2.py
[I 2025-02-04 15:14:42.065 ServerApp] Saving file at /YJ/test2.py
[I 2025-02-04 15:15:08.910 ServerApp] Saving file at /YJ/test2.py
[I 2025-02-04 15:17:09.182 ServerApp] Saving file at /YJ/test2.py
[I 2025-02-04 15:30:14.619 ServerApp] Saving file at /YJ/test2.py
[I 2025-02-04 16:06:35.594 ServerApp] Starting buffering for 2f11043f-dcd9-4b2d-9f80-fd8dce8b8d77:53c63dd5-b387-422a-acbb-79bf05f1012e
[I 2025-02-04 16:06:35.606 ServerApp] Starting buffering for db722577-241e-4d99-9e7e-a995cd7cb2b6:a5014fc8-5c16-4a5c-b9eb-4bff61fed096
[I 2025-02-04 16:06:35.617 ServerApp] Starting buffering for 98b723d9-cc74-4ff7-a126-c3d12fd657dc:147d7787-af5c-4106-9e1a-b269f5494e52
[C 2025-02-04 18:54:49.774 ServerApp] received signal 15, stopping
[I 2025-02-04 18:54:49.793 ServerApp] Shutting down 5 extensions
[I 2025-02-04 18:54:49.794 ServerApp] Shutting down 4 kernels
[I 2025-02-04 18:54:49.794 ServerApp] Kernel shutdown: 98b723d9-cc74-4ff7-a126-c3d12fd657dc
[I 2025-02-04 18:54:49.795 ServerApp] Kernel shutdown: db722577-241e-4d99-9e7e-a995cd7cb2b6
[I 2025-02-04 18:54:49.843 ServerApp] Kernel shutdown: 2f11043f-dcd9-4b2d-9f80-fd8dce8b8d77
[I 2025-02-04 18:54:49.844 ServerApp] Kernel shutdown: be463339-194a-4453-818c-81b854117143
[I 2025-02-05 09:23:16.319 ServerApp] jupyter_lsp | extension was successfully linked.
[I 2025-02-05 09:23:16.325 ServerApp] jupyter_server_terminals | extension was successfully linked.
[I 2025-02-05 09:23:16.329 ServerApp] jupyterlab | extension was successfully linked.
[W 2025-02-05 09:23:16.332 JupyterNotebookApp] 'password' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-05 09:23:16.335 ServerApp] ServerApp.password config is deprecated in 2.0. Use PasswordIdentityProvider.hashed_password.
[I 2025-02-05 09:23:16.335 ServerApp] notebook | extension was successfully linked.
[I 2025-02-05 09:23:16.858 ServerApp] notebook_shim | extension was successfully linked.
[I 2025-02-05 09:23:16.956 ServerApp] notebook_shim | extension was successfully loaded.
[I 2025-02-05 09:23:16.958 ServerApp] jupyter_lsp | extension was successfully loaded.
[I 2025-02-05 09:23:16.959 ServerApp] jupyter_server_terminals | extension was successfully loaded.
[I 2025-02-05 09:23:16.973 LabApp] JupyterLab extension loaded from /home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyterlab
[I 2025-02-05 09:23:16.973 LabApp] JupyterLab application directory is /home/ubuntu/anaconda3/envs/Project/share/jupyter/lab
[I 2025-02-05 09:23:16.973 LabApp] Extension Manager is 'pypi'.
[I 2025-02-05 09:23:17.031 ServerApp] jupyterlab | extension was successfully loaded.
[I 2025-02-05 09:23:17.035 ServerApp] notebook | extension was successfully loaded.
[I 2025-02-05 09:23:17.035 ServerApp] Serving notebooks from local directory: /home/lab13/project
[I 2025-02-05 09:23:17.035 ServerApp] Jupyter Server 2.14.2 is running at:
[I 2025-02-05 09:23:17.035 ServerApp] http://ip-172-31-13-81:8917/tree
[I 2025-02-05 09:23:17.035 ServerApp]     http://127.0.0.1:8917/tree
[I 2025-02-05 09:23:17.035 ServerApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[I 2025-02-05 09:23:17.055 ServerApp] Skipped non-installed server(s): bash-language-server, dockerfile-language-server-nodejs, javascript-typescript-langserver, jedi-language-server, julia-language-server, pyright, python-language-server, python-lsp-server, r-languageserver, sql-language-server, texlab, typescript-language-server, unified-language-server, vscode-css-languageserver-bin, vscode-html-languageserver-bin, vscode-json-languageserver-bin, yaml-language-server
[I 2025-02-05 09:23:37.091 ServerApp] 302 GET / (@125.129.250.60) 0.50ms
[I 2025-02-05 09:23:37.124 JupyterNotebookApp] 302 GET /tree? (@125.129.250.60) 0.62ms
[I 2025-02-05 09:23:42.992 ServerApp] User d5a2526841e2479cbfd1197f97234a6f logged in.
[I 2025-02-05 09:23:42.992 ServerApp] 302 POST /login?next=%2Ftree%3F (d5a2526841e2479cbfd1197f97234a6f@125.129.250.60) 55.53ms
[W 2025-02-05 09:23:48.286 ServerApp] Notebook YJ/youtube_preprocessing.ipynb is not trusted
[I 2025-02-05 09:25:09.057 ServerApp] Kernel started: 1f7d14fb-69ae-4638-884e-321cec2f975d
[I 2025-02-05 09:25:09.607 ServerApp] Connecting to kernel 1f7d14fb-69ae-4638-884e-321cec2f975d.
[I 2025-02-05 09:25:09.696 ServerApp] Connecting to kernel 1f7d14fb-69ae-4638-884e-321cec2f975d.
[I 2025-02-05 09:25:09.769 ServerApp] Connecting to kernel 1f7d14fb-69ae-4638-884e-321cec2f975d.
[I 2025-02-05 09:25:12.288 ServerApp] Starting buffering for 1f7d14fb-69ae-4638-884e-321cec2f975d:4c1a4aee-b37e-4491-99cd-b5b95c831be0
[I 2025-02-05 09:25:17.076 ServerApp] Connecting to kernel 1f7d14fb-69ae-4638-884e-321cec2f975d.
[I 2025-02-05 09:25:17.302 ServerApp] Starting buffering for 1f7d14fb-69ae-4638-884e-321cec2f975d:31473ffc-d9e7-4d83-8a02-c8e7e39b1926
[I 2025-02-05 09:25:21.833 ServerApp] Connecting to kernel 1f7d14fb-69ae-4638-884e-321cec2f975d.
[I 2025-02-05 09:25:22.010 ServerApp] Starting buffering for 1f7d14fb-69ae-4638-884e-321cec2f975d:ef99a05b-e944-4b15-8bdd-ceee24515a67
[I 2025-02-05 09:25:29.467 ServerApp] Connecting to kernel 1f7d14fb-69ae-4638-884e-321cec2f975d.
[I 2025-02-05 09:25:29.562 ServerApp] Starting buffering for 1f7d14fb-69ae-4638-884e-321cec2f975d:465d451c-b6f7-4924-8fb6-166e93e50692
[W 2025-02-05 09:25:34.137 ServerApp] delete /YJ/youtube_preprocessing.py
[I 2025-02-05 09:30:56.385 ServerApp] Connecting to kernel 1f7d14fb-69ae-4638-884e-321cec2f975d.
[I 2025-02-05 09:30:56.571 ServerApp] Starting buffering for 1f7d14fb-69ae-4638-884e-321cec2f975d:20bb1378-8391-4d95-babf-9bcf51ea0e96
[I 2025-02-05 09:32:35.413 ServerApp] Connecting to kernel 1f7d14fb-69ae-4638-884e-321cec2f975d.
[I 2025-02-05 09:32:35.594 ServerApp] Starting buffering for 1f7d14fb-69ae-4638-884e-321cec2f975d:6e52e78d-6d1d-4bba-90fc-96ad764bc571
[I 2025-02-05 09:32:39.415 ServerApp] Saving file at /YJ/test.py
[I 2025-02-05 09:32:40.694 ServerApp] Saving file at /YJ/test.py
[I 2025-02-05 09:42:04.749 ServerApp] Saving file at /YJ/youtube_preprocessing.py
[I 2025-02-05 09:43:03.231 ServerApp] Saving file at /YJ/youtube_preprocessing.py
[I 2025-02-05 11:41:35.322 ServerApp] Connecting to kernel 1f7d14fb-69ae-4638-884e-321cec2f975d.
[I 2025-02-05 11:41:35.575 ServerApp] Starting buffering for 1f7d14fb-69ae-4638-884e-321cec2f975d:55a023a6-e895-4e45-aa94-1501cbffcc74
[I 2025-02-05 11:41:35.758 ServerApp] Kernel started: b5908e22-fed1-45b7-9b39-3bdc0cb34699
[I 2025-02-05 11:41:36.216 ServerApp] Connecting to kernel b5908e22-fed1-45b7-9b39-3bdc0cb34699.
[I 2025-02-05 11:41:36.810 ServerApp] Starting buffering for b5908e22-fed1-45b7-9b39-3bdc0cb34699:f952f840-7f50-462b-a688-4b92ce34a31d
[W 2025-02-05 11:41:38.030 ServerApp] Notebook YJ/Untitled.ipynb is not trusted
[I 2025-02-05 11:41:39.556 ServerApp] Connecting to kernel 1f7d14fb-69ae-4638-884e-321cec2f975d.
[I 2025-02-05 11:41:39.653 ServerApp] Connecting to kernel b5908e22-fed1-45b7-9b39-3bdc0cb34699.
[W 2025-02-05 11:41:39.661 ServerApp] Notebook YJ/Untitled.ipynb is not trusted
[I 2025-02-05 11:41:39.842 ServerApp] Starting buffering for b5908e22-fed1-45b7-9b39-3bdc0cb34699:9a5c3dfc-7cea-45f8-9007-f878dae1004a
[I 2025-02-05 11:41:39.845 ServerApp] Starting buffering for 1f7d14fb-69ae-4638-884e-321cec2f975d:1629dab6-8937-40d1-848c-b8413624a62d
[I 2025-02-05 11:41:39.959 ServerApp] Kernel started: 153bcb25-8880-4d43-bcd2-f03f3bd7138b
[I 2025-02-05 11:41:40.428 ServerApp] Connecting to kernel 153bcb25-8880-4d43-bcd2-f03f3bd7138b.
[I 2025-02-05 11:41:43.068 ServerApp] Starting buffering for 153bcb25-8880-4d43-bcd2-f03f3bd7138b:a4ebfb80-86ba-438a-9ed0-5c33a24deaea
[I 2025-02-05 11:41:58.183 ServerApp] Connecting to kernel 1f7d14fb-69ae-4638-884e-321cec2f975d.
[I 2025-02-05 11:41:58.272 ServerApp] Connecting to kernel b5908e22-fed1-45b7-9b39-3bdc0cb34699.
[I 2025-02-05 11:41:58.349 ServerApp] Connecting to kernel 153bcb25-8880-4d43-bcd2-f03f3bd7138b.
[I 2025-02-05 11:41:58.433 ServerApp] Starting buffering for 1f7d14fb-69ae-4638-884e-321cec2f975d:778c69c8-5e20-401a-ae0e-22b0da2245bd
[I 2025-02-05 11:41:58.434 ServerApp] Starting buffering for b5908e22-fed1-45b7-9b39-3bdc0cb34699:112f2a08-2975-4277-bfe1-99e964b05255
[I 2025-02-05 11:41:58.525 ServerApp] Starting buffering for 153bcb25-8880-4d43-bcd2-f03f3bd7138b:2a634770-efbc-453c-8db1-907e2be2d80a
[I 2025-02-05 11:41:58.564 ServerApp] Connecting to kernel b5908e22-fed1-45b7-9b39-3bdc0cb34699.
[I 2025-02-05 11:43:58.987 ServerApp] Saving file at /YJ/Untitled1.ipynb
[C 2025-02-05 11:50:59.613 ServerApp] received signal 15, stopping
[I 2025-02-05 11:50:59.614 ServerApp] Shutting down 5 extensions
[I 2025-02-05 11:50:59.615 ServerApp] Shutting down 3 kernels
[I 2025-02-05 11:50:59.616 ServerApp] Kernel shutdown: 1f7d14fb-69ae-4638-884e-321cec2f975d
[I 2025-02-05 11:50:59.616 ServerApp] Kernel shutdown: 153bcb25-8880-4d43-bcd2-f03f3bd7138b
[I 2025-02-05 11:50:59.616 ServerApp] Kernel shutdown: b5908e22-fed1-45b7-9b39-3bdc0cb34699
[I 2025-02-05 13:37:05.650 ServerApp] jupyter_lsp | extension was successfully linked.
[I 2025-02-05 13:37:05.656 ServerApp] jupyter_server_terminals | extension was successfully linked.
[I 2025-02-05 13:37:05.661 ServerApp] jupyterlab | extension was successfully linked.
[W 2025-02-05 13:37:05.663 JupyterNotebookApp] 'password' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-05 13:37:05.666 ServerApp] ServerApp.password config is deprecated in 2.0. Use PasswordIdentityProvider.hashed_password.
[I 2025-02-05 13:37:05.666 ServerApp] notebook | extension was successfully linked.
[I 2025-02-05 13:37:06.203 ServerApp] notebook_shim | extension was successfully linked.
[I 2025-02-05 13:37:06.302 ServerApp] notebook_shim | extension was successfully loaded.
[I 2025-02-05 13:37:06.304 ServerApp] jupyter_lsp | extension was successfully loaded.
[I 2025-02-05 13:37:06.305 ServerApp] jupyter_server_terminals | extension was successfully loaded.
[I 2025-02-05 13:37:06.321 LabApp] JupyterLab extension loaded from /home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyterlab
[I 2025-02-05 13:37:06.321 LabApp] JupyterLab application directory is /home/ubuntu/anaconda3/envs/Project/share/jupyter/lab
[I 2025-02-05 13:37:06.321 LabApp] Extension Manager is 'pypi'.
[I 2025-02-05 13:37:06.381 ServerApp] jupyterlab | extension was successfully loaded.
[I 2025-02-05 13:37:06.385 ServerApp] notebook | extension was successfully loaded.
[I 2025-02-05 13:37:06.385 ServerApp] Serving notebooks from local directory: /home/lab13/project
[I 2025-02-05 13:37:06.385 ServerApp] Jupyter Server 2.14.2 is running at:
[I 2025-02-05 13:37:06.385 ServerApp] http://ip-172-31-13-81:8917/tree
[I 2025-02-05 13:37:06.385 ServerApp]     http://127.0.0.1:8917/tree
[I 2025-02-05 13:37:06.385 ServerApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[I 2025-02-05 13:37:06.405 ServerApp] Skipped non-installed server(s): bash-language-server, dockerfile-language-server-nodejs, javascript-typescript-langserver, jedi-language-server, julia-language-server, pyright, python-language-server, python-lsp-server, r-languageserver, sql-language-server, texlab, typescript-language-server, unified-language-server, vscode-css-languageserver-bin, vscode-html-languageserver-bin, vscode-json-languageserver-bin, yaml-language-server
[I 2025-02-05 13:37:10.652 ServerApp] Creating new notebook in /YJ
[I 2025-02-05 13:37:11.111 ServerApp] Saving file at /YJ/Untitled2.ipynb
[I 2025-02-05 13:37:11.217 ServerApp] Kernel started: a584f394-569e-42d6-9a06-852cf79a6f65
[I 2025-02-05 13:37:11.806 ServerApp] Connecting to kernel a584f394-569e-42d6-9a06-852cf79a6f65.
[I 2025-02-05 13:37:11.899 ServerApp] Connecting to kernel a584f394-569e-42d6-9a06-852cf79a6f65.
[I 2025-02-05 13:37:12.606 ServerApp] Connecting to kernel a584f394-569e-42d6-9a06-852cf79a6f65.
[I 2025-02-05 13:37:12.952 ServerApp] Connecting to kernel a584f394-569e-42d6-9a06-852cf79a6f65.
[W 2025-02-05 13:37:19.818 ServerApp] 404 GET /api/kernels/b5908e22-fed1-45b7-9b39-3bdc0cb34699?1738730238520 (125.129.250.60): Kernel does not exist: b5908e22-fed1-45b7-9b39-3bdc0cb34699
[W 2025-02-05 13:37:19.819 ServerApp] wrote error: 'Kernel does not exist: b5908e22-fed1-45b7-9b39-3bdc0cb34699'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_server/services/kernels/handlers.py", line 75, in get
        model = await ensure_async(km.kernel_model(kernel_id))
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_server/services/kernels/kernelmanager.py", line 506, in kernel_model
        self._check_kernel_id(kernel_id)
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_server/services/kernels/kernelmanager.py", line 537, in _check_kernel_id
        raise web.HTTPError(404, "Kernel does not exist: %s" % kernel_id)
    tornado.web.HTTPError: HTTP 404: Not Found (Kernel does not exist: b5908e22-fed1-45b7-9b39-3bdc0cb34699)
[W 2025-02-05 13:37:19.825 ServerApp] 404 GET /api/kernels/b5908e22-fed1-45b7-9b39-3bdc0cb34699?1738730238520 (d5a2526841e2479cbfd1197f97234a6f@125.129.250.60) 7.27ms referer=http://15.168.221.131:8917/notebooks/YJ/Untitled1.ipynb
[W 2025-02-05 13:37:20.844 ServerApp] 404 GET /api/kernels/b5908e22-fed1-45b7-9b39-3bdc0cb34699/channels?session_id=db246c77-6b84-4299-b258-84001c56cf90 (125.129.250.60): Kernel does not exist: b5908e22-fed1-45b7-9b39-3bdc0cb34699
[W 2025-02-05 13:37:20.907 ServerApp] 404 GET /api/kernels/b5908e22-fed1-45b7-9b39-3bdc0cb34699/channels?session_id=db246c77-6b84-4299-b258-84001c56cf90 (d5a2526841e2479cbfd1197f97234a6f@125.129.250.60) 63.28ms referer=None
[W 2025-02-05 13:37:20.934 ServerApp] 404 GET /api/kernels/b5908e22-fed1-45b7-9b39-3bdc0cb34699?1738730239637 (125.129.250.60): Kernel does not exist: b5908e22-fed1-45b7-9b39-3bdc0cb34699
[W 2025-02-05 13:37:20.934 ServerApp] wrote error: 'Kernel does not exist: b5908e22-fed1-45b7-9b39-3bdc0cb34699'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_server/services/kernels/handlers.py", line 75, in get
        model = await ensure_async(km.kernel_model(kernel_id))
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_server/services/kernels/kernelmanager.py", line 506, in kernel_model
        self._check_kernel_id(kernel_id)
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_server/services/kernels/kernelmanager.py", line 537, in _check_kernel_id
        raise web.HTTPError(404, "Kernel does not exist: %s" % kernel_id)
    tornado.web.HTTPError: HTTP 404: Not Found (Kernel does not exist: b5908e22-fed1-45b7-9b39-3bdc0cb34699)
[W 2025-02-05 13:37:20.935 ServerApp] 404 GET /api/kernels/b5908e22-fed1-45b7-9b39-3bdc0cb34699?1738730239637 (d5a2526841e2479cbfd1197f97234a6f@125.129.250.60) 0.98ms referer=http://15.168.221.131:8917/notebooks/YJ/Untitled1.ipynb
[W 2025-02-05 13:37:21.851 ServerApp] 404 GET /api/kernels/b5908e22-fed1-45b7-9b39-3bdc0cb34699/channels?session_id=db246c77-6b84-4299-b258-84001c56cf90 (125.129.250.60): Kernel does not exist: b5908e22-fed1-45b7-9b39-3bdc0cb34699
[W 2025-02-05 13:37:21.851 ServerApp] 404 GET /api/kernels/b5908e22-fed1-45b7-9b39-3bdc0cb34699/channels?session_id=db246c77-6b84-4299-b258-84001c56cf90 (d5a2526841e2479cbfd1197f97234a6f@125.129.250.60) 1.13ms referer=None
[W 2025-02-05 13:37:21.884 ServerApp] 404 GET /api/kernels/b5908e22-fed1-45b7-9b39-3bdc0cb34699?1738730240587 (125.129.250.60): Kernel does not exist: b5908e22-fed1-45b7-9b39-3bdc0cb34699
[W 2025-02-05 13:37:21.884 ServerApp] wrote error: 'Kernel does not exist: b5908e22-fed1-45b7-9b39-3bdc0cb34699'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_server/services/kernels/handlers.py", line 75, in get
        model = await ensure_async(km.kernel_model(kernel_id))
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_server/services/kernels/kernelmanager.py", line 506, in kernel_model
        self._check_kernel_id(kernel_id)
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_server/services/kernels/kernelmanager.py", line 537, in _check_kernel_id
        raise web.HTTPError(404, "Kernel does not exist: %s" % kernel_id)
    tornado.web.HTTPError: HTTP 404: Not Found (Kernel does not exist: b5908e22-fed1-45b7-9b39-3bdc0cb34699)
[W 2025-02-05 13:37:21.885 ServerApp] 404 GET /api/kernels/b5908e22-fed1-45b7-9b39-3bdc0cb34699?1738730240587 (d5a2526841e2479cbfd1197f97234a6f@125.129.250.60) 0.90ms referer=http://15.168.221.131:8917/notebooks/YJ/Untitled1.ipynb
[W 2025-02-05 13:37:24.849 ServerApp] 404 GET /api/kernels/b5908e22-fed1-45b7-9b39-3bdc0cb34699/channels?session_id=db246c77-6b84-4299-b258-84001c56cf90 (125.129.250.60): Kernel does not exist: b5908e22-fed1-45b7-9b39-3bdc0cb34699
[W 2025-02-05 13:37:24.849 ServerApp] 404 GET /api/kernels/b5908e22-fed1-45b7-9b39-3bdc0cb34699/channels?session_id=db246c77-6b84-4299-b258-84001c56cf90 (d5a2526841e2479cbfd1197f97234a6f@125.129.250.60) 1.38ms referer=None
[W 2025-02-05 13:37:24.882 ServerApp] 404 GET /api/kernels/b5908e22-fed1-45b7-9b39-3bdc0cb34699?1738730243585 (125.129.250.60): Kernel does not exist: b5908e22-fed1-45b7-9b39-3bdc0cb34699
[W 2025-02-05 13:37:24.882 ServerApp] wrote error: 'Kernel does not exist: b5908e22-fed1-45b7-9b39-3bdc0cb34699'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_server/services/kernels/handlers.py", line 75, in get
        model = await ensure_async(km.kernel_model(kernel_id))
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_server/services/kernels/kernelmanager.py", line 506, in kernel_model
        self._check_kernel_id(kernel_id)
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_server/services/kernels/kernelmanager.py", line 537, in _check_kernel_id
        raise web.HTTPError(404, "Kernel does not exist: %s" % kernel_id)
    tornado.web.HTTPError: HTTP 404: Not Found (Kernel does not exist: b5908e22-fed1-45b7-9b39-3bdc0cb34699)
[W 2025-02-05 13:37:24.882 ServerApp] 404 GET /api/kernels/b5908e22-fed1-45b7-9b39-3bdc0cb34699?1738730243585 (d5a2526841e2479cbfd1197f97234a6f@125.129.250.60) 1.06ms referer=http://15.168.221.131:8917/notebooks/YJ/Untitled1.ipynb
[W 2025-02-05 13:37:33.854 ServerApp] 404 GET /api/kernels/b5908e22-fed1-45b7-9b39-3bdc0cb34699/channels?session_id=db246c77-6b84-4299-b258-84001c56cf90 (125.129.250.60): Kernel does not exist: b5908e22-fed1-45b7-9b39-3bdc0cb34699
[W 2025-02-05 13:37:33.855 ServerApp] 404 GET /api/kernels/b5908e22-fed1-45b7-9b39-3bdc0cb34699/channels?session_id=db246c77-6b84-4299-b258-84001c56cf90 (d5a2526841e2479cbfd1197f97234a6f@125.129.250.60) 1.31ms referer=None
[W 2025-02-05 13:37:33.887 ServerApp] 404 GET /api/kernels/b5908e22-fed1-45b7-9b39-3bdc0cb34699?1738730252591 (125.129.250.60): Kernel does not exist: b5908e22-fed1-45b7-9b39-3bdc0cb34699
[W 2025-02-05 13:37:33.887 ServerApp] wrote error: 'Kernel does not exist: b5908e22-fed1-45b7-9b39-3bdc0cb34699'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_server/services/kernels/handlers.py", line 75, in get
        model = await ensure_async(km.kernel_model(kernel_id))
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_server/services/kernels/kernelmanager.py", line 506, in kernel_model
        self._check_kernel_id(kernel_id)
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_server/services/kernels/kernelmanager.py", line 537, in _check_kernel_id
        raise web.HTTPError(404, "Kernel does not exist: %s" % kernel_id)
    tornado.web.HTTPError: HTTP 404: Not Found (Kernel does not exist: b5908e22-fed1-45b7-9b39-3bdc0cb34699)
[W 2025-02-05 13:37:33.888 ServerApp] 404 GET /api/kernels/b5908e22-fed1-45b7-9b39-3bdc0cb34699?1738730252591 (d5a2526841e2479cbfd1197f97234a6f@125.129.250.60) 1.13ms referer=http://15.168.221.131:8917/notebooks/YJ/Untitled1.ipynb
[W 2025-02-05 13:37:43.840 ServerApp] 404 GET /api/kernels/b5908e22-fed1-45b7-9b39-3bdc0cb34699/channels?session_id=db246c77-6b84-4299-b258-84001c56cf90 (125.129.250.60): Kernel does not exist: b5908e22-fed1-45b7-9b39-3bdc0cb34699
[W 2025-02-05 13:37:43.841 ServerApp] 404 GET /api/kernels/b5908e22-fed1-45b7-9b39-3bdc0cb34699/channels?session_id=db246c77-6b84-4299-b258-84001c56cf90 (d5a2526841e2479cbfd1197f97234a6f@125.129.250.60) 1.32ms referer=None
[W 2025-02-05 13:37:43.873 ServerApp] 404 GET /api/kernels/b5908e22-fed1-45b7-9b39-3bdc0cb34699?1738730262577 (125.129.250.60): Kernel does not exist: b5908e22-fed1-45b7-9b39-3bdc0cb34699
[W 2025-02-05 13:37:43.873 ServerApp] wrote error: 'Kernel does not exist: b5908e22-fed1-45b7-9b39-3bdc0cb34699'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_server/services/kernels/handlers.py", line 75, in get
        model = await ensure_async(km.kernel_model(kernel_id))
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_server/services/kernels/kernelmanager.py", line 506, in kernel_model
        self._check_kernel_id(kernel_id)
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_server/services/kernels/kernelmanager.py", line 537, in _check_kernel_id
        raise web.HTTPError(404, "Kernel does not exist: %s" % kernel_id)
    tornado.web.HTTPError: HTTP 404: Not Found (Kernel does not exist: b5908e22-fed1-45b7-9b39-3bdc0cb34699)
[W 2025-02-05 13:37:43.874 ServerApp] 404 GET /api/kernels/b5908e22-fed1-45b7-9b39-3bdc0cb34699?1738730262577 (d5a2526841e2479cbfd1197f97234a6f@125.129.250.60) 1.03ms referer=http://15.168.221.131:8917/notebooks/YJ/Untitled1.ipynb
[W 2025-02-05 13:38:44.850 ServerApp] 404 GET /api/kernels/b5908e22-fed1-45b7-9b39-3bdc0cb34699/channels?session_id=db246c77-6b84-4299-b258-84001c56cf90 (125.129.250.60): Kernel does not exist: b5908e22-fed1-45b7-9b39-3bdc0cb34699
[W 2025-02-05 13:38:44.851 ServerApp] 404 GET /api/kernels/b5908e22-fed1-45b7-9b39-3bdc0cb34699/channels?session_id=db246c77-6b84-4299-b258-84001c56cf90 (d5a2526841e2479cbfd1197f97234a6f@125.129.250.60) 1.30ms referer=None
[W 2025-02-05 13:38:44.883 ServerApp] 404 GET /api/kernels/b5908e22-fed1-45b7-9b39-3bdc0cb34699?1738730323588 (125.129.250.60): Kernel does not exist: b5908e22-fed1-45b7-9b39-3bdc0cb34699
[W 2025-02-05 13:38:44.884 ServerApp] wrote error: 'Kernel does not exist: b5908e22-fed1-45b7-9b39-3bdc0cb34699'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_server/services/kernels/handlers.py", line 75, in get
        model = await ensure_async(km.kernel_model(kernel_id))
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_server/services/kernels/kernelmanager.py", line 506, in kernel_model
        self._check_kernel_id(kernel_id)
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_server/services/kernels/kernelmanager.py", line 537, in _check_kernel_id
        raise web.HTTPError(404, "Kernel does not exist: %s" % kernel_id)
    tornado.web.HTTPError: HTTP 404: Not Found (Kernel does not exist: b5908e22-fed1-45b7-9b39-3bdc0cb34699)
[W 2025-02-05 13:38:44.884 ServerApp] 404 GET /api/kernels/b5908e22-fed1-45b7-9b39-3bdc0cb34699?1738730323588 (d5a2526841e2479cbfd1197f97234a6f@125.129.250.60) 1.02ms referer=http://15.168.221.131:8917/notebooks/YJ/Untitled1.ipynb
[I 2025-02-05 13:39:12.802 ServerApp] Saving file at /YJ/Untitled2.ipynb
[I 2025-02-05 13:41:44.012 ServerApp] Connecting to kernel a584f394-569e-42d6-9a06-852cf79a6f65.
[I 2025-02-05 13:41:47.908 ServerApp] Connecting to kernel a584f394-569e-42d6-9a06-852cf79a6f65.
[I 2025-02-05 13:44:42.243 ServerApp] Connecting to kernel a584f394-569e-42d6-9a06-852cf79a6f65.
[I 2025-02-05 13:44:42.583 ServerApp] Connecting to kernel a584f394-569e-42d6-9a06-852cf79a6f65.
[I 2025-02-05 13:44:47.029 ServerApp] Kernel started: 4c92c4dd-75fc-4889-9cba-54c431e1a36c
[I 2025-02-05 13:44:47.030 ServerApp] Kernel shutdown: a584f394-569e-42d6-9a06-852cf79a6f65
[I 2025-02-05 13:44:47.622 ServerApp] Connecting to kernel 4c92c4dd-75fc-4889-9cba-54c431e1a36c.
[I 2025-02-05 13:44:47.683 ServerApp] Connecting to kernel 4c92c4dd-75fc-4889-9cba-54c431e1a36c.
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: a6fbb616-d85f-4001-87d2-5adb2349c1a8
[I 2025-02-05 13:46:42.836 ServerApp] Saving file at /YJ/Untitled2.ipynb
[I 2025-02-05 13:48:42.955 ServerApp] Saving file at /YJ/Untitled2.ipynb
[I 2025-02-05 13:50:43.829 ServerApp] Saving file at /YJ/Untitled2.ipynb
[I 2025-02-05 13:54:47.240 ServerApp] Starting buffering for 4c92c4dd-75fc-4889-9cba-54c431e1a36c:688ce441-ed97-44a7-a45c-bcf29c3802a9
[I 2025-02-05 13:54:48.602 ServerApp] Connecting to kernel 4c92c4dd-75fc-4889-9cba-54c431e1a36c.
[I 2025-02-05 13:54:48.859 ServerApp] Starting buffering for 4c92c4dd-75fc-4889-9cba-54c431e1a36c:de880a46-1801-4bec-9d6a-c2f7634bc548
[I 2025-02-05 13:54:48.977 ServerApp] Connecting to kernel 4c92c4dd-75fc-4889-9cba-54c431e1a36c.
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: 9d50e5ee-5f28-49c4-a5a5-6438b5c15b6d
[I 2025-02-05 13:54:52.127 ServerApp] Kernel started: d7a62dfa-cae8-4506-b71e-c49c72c856e4
[I 2025-02-05 13:54:52.128 ServerApp] Kernel shutdown: 4c92c4dd-75fc-4889-9cba-54c431e1a36c
[I 2025-02-05 13:54:53.109 ServerApp] Connecting to kernel d7a62dfa-cae8-4506-b71e-c49c72c856e4.
[I 2025-02-05 13:54:53.177 ServerApp] Connecting to kernel d7a62dfa-cae8-4506-b71e-c49c72c856e4.
[I 2025-02-05 13:56:48.831 ServerApp] Saving file at /YJ/Untitled2.ipynb
[I 2025-02-05 13:58:49.819 ServerApp] Saving file at /YJ/Untitled2.ipynb
[I 2025-02-05 14:02:50.827 ServerApp] Saving file at /YJ/Untitled2.ipynb
[I 2025-02-05 14:06:50.945 ServerApp] Saving file at /YJ/Untitled2.ipynb
[I 2025-02-05 14:08:51.279 ServerApp] Saving file at /YJ/Untitled2.ipynb
[I 2025-02-05 14:10:51.817 ServerApp] Saving file at /YJ/Untitled2.ipynb
[I 2025-02-05 14:12:51.943 ServerApp] Saving file at /YJ/Untitled2.ipynb
[I 2025-02-05 14:16:52.055 ServerApp] Saving file at /YJ/Untitled2.ipynb
[I 2025-02-05 14:18:52.169 ServerApp] Saving file at /YJ/Untitled2.ipynb
[I 2025-02-05 14:21:25.218 ServerApp] Saving file at /YJ/Untitled2.ipynb
[I 2025-02-05 14:40:28.779 ServerApp] Connecting to kernel d7a62dfa-cae8-4506-b71e-c49c72c856e4.
[I 2025-02-05 14:40:35.924 ServerApp] Saving file at /YJ/youtube_preprocessing.py
[I 2025-02-05 14:40:38.924 ServerApp] Connecting to kernel d7a62dfa-cae8-4506-b71e-c49c72c856e4.
[I 2025-02-05 14:40:38.992 ServerApp] Connecting to kernel d7a62dfa-cae8-4506-b71e-c49c72c856e4.
[I 2025-02-05 15:45:50.423 ServerApp] Connecting to kernel d7a62dfa-cae8-4506-b71e-c49c72c856e4.
[I 2025-02-05 17:18:46.018 ServerApp] Creating new directory in /YJ
[I 2025-02-05 17:18:58.664 ServerApp] Creating new notebook in /YJ/analytics
[I 2025-02-05 17:18:58.855 ServerApp] Saving file at /YJ/analytics/Untitled.ipynb
[I 2025-02-05 17:18:58.918 ServerApp] Kernel started: 87df68ce-2e98-4a7a-8de2-d302ecc3212b
[I 2025-02-05 17:18:59.549 ServerApp] Connecting to kernel 87df68ce-2e98-4a7a-8de2-d302ecc3212b.
[I 2025-02-05 17:19:00.371 ServerApp] Connecting to kernel d7a62dfa-cae8-4506-b71e-c49c72c856e4.
[I 2025-02-05 17:19:00.434 ServerApp] Connecting to kernel 87df68ce-2e98-4a7a-8de2-d302ecc3212b.
[I 2025-02-05 17:19:00.714 ServerApp] Connecting to kernel 87df68ce-2e98-4a7a-8de2-d302ecc3212b.
[W 2025-02-05 17:19:09.121 ServerApp] Notebook YJ/youtube_preprocessing.ipynb is not trusted
[I 2025-02-05 17:19:10.430 ServerApp] Connecting to kernel d7a62dfa-cae8-4506-b71e-c49c72c856e4.
[I 2025-02-05 17:19:10.532 ServerApp] Connecting to kernel 87df68ce-2e98-4a7a-8de2-d302ecc3212b.
[W 2025-02-05 17:19:10.570 ServerApp] Notebook YJ/youtube_preprocessing.ipynb is not trusted
[I 2025-02-05 17:19:10.892 ServerApp] Kernel started: d3200e36-9336-41f6-857a-e94c1a673a51
[I 2025-02-05 17:19:11.382 ServerApp] Connecting to kernel d3200e36-9336-41f6-857a-e94c1a673a51.
[I 2025-02-05 17:19:43.282 ServerApp] Connecting to kernel d7a62dfa-cae8-4506-b71e-c49c72c856e4.
[I 2025-02-05 17:19:43.375 ServerApp] Connecting to kernel 87df68ce-2e98-4a7a-8de2-d302ecc3212b.
[I 2025-02-05 17:19:43.448 ServerApp] Connecting to kernel d3200e36-9336-41f6-857a-e94c1a673a51.
[I 2025-02-05 17:19:43.655 ServerApp] Kernel started: 67306476-de9d-472c-b0c4-a7f47624df98
[I 2025-02-05 17:19:44.139 ServerApp] Connecting to kernel 67306476-de9d-472c-b0c4-a7f47624df98.
[I 2025-02-05 17:19:53.510 ServerApp] Starting buffering for d3200e36-9336-41f6-857a-e94c1a673a51:161eba07-8bf8-4993-9611-7fa62db8ebe9
25/02/05 17:20:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[I 2025-02-05 17:21:00.570 ServerApp] Saving file at /YJ/analytics/Untitled.ipynb
[I 2025-02-05 17:23:00.678 ServerApp] Saving file at /YJ/analytics/Untitled.ipynb
[I 2025-02-05 17:31:12.471 ServerApp] Connecting to kernel 67306476-de9d-472c-b0c4-a7f47624df98.
[C 2025-02-05 19:00:01.280 ServerApp] received signal 15, stopping
[I 2025-02-05 19:00:01.280 ServerApp] Shutting down 5 extensions
[I 2025-02-05 19:00:01.281 ServerApp] Shutting down 4 kernels
[I 2025-02-05 19:00:01.282 ServerApp] Kernel shutdown: 87df68ce-2e98-4a7a-8de2-d302ecc3212b
[I 2025-02-05 19:00:01.282 ServerApp] Kernel shutdown: d7a62dfa-cae8-4506-b71e-c49c72c856e4
[I 2025-02-05 19:00:01.282 ServerApp] Kernel shutdown: d3200e36-9336-41f6-857a-e94c1a673a51
[I 2025-02-05 19:00:01.283 ServerApp] Kernel shutdown: 67306476-de9d-472c-b0c4-a7f47624df98
[I 2025-02-06 15:09:12.294 ServerApp] jupyter_lsp | extension was successfully linked.
[I 2025-02-06 15:09:12.298 ServerApp] jupyter_server_terminals | extension was successfully linked.
[I 2025-02-06 15:09:12.303 ServerApp] jupyterlab | extension was successfully linked.
[W 2025-02-06 15:09:12.305 JupyterNotebookApp] 'password' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-06 15:09:12.308 ServerApp] ServerApp.password config is deprecated in 2.0. Use PasswordIdentityProvider.hashed_password.
[I 2025-02-06 15:09:12.308 ServerApp] notebook | extension was successfully linked.
[I 2025-02-06 15:09:12.507 ServerApp] notebook_shim | extension was successfully linked.
[I 2025-02-06 15:09:12.545 ServerApp] notebook_shim | extension was successfully loaded.
[I 2025-02-06 15:09:12.547 ServerApp] jupyter_lsp | extension was successfully loaded.
[I 2025-02-06 15:09:12.548 ServerApp] jupyter_server_terminals | extension was successfully loaded.
[I 2025-02-06 15:09:12.550 LabApp] JupyterLab extension loaded from /home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyterlab
[I 2025-02-06 15:09:12.550 LabApp] JupyterLab application directory is /home/ubuntu/anaconda3/envs/Project/share/jupyter/lab
[I 2025-02-06 15:09:12.550 LabApp] Extension Manager is 'pypi'.
[I 2025-02-06 15:09:12.577 ServerApp] jupyterlab | extension was successfully loaded.
[I 2025-02-06 15:09:12.581 ServerApp] notebook | extension was successfully loaded.
[I 2025-02-06 15:09:12.581 ServerApp] Serving notebooks from local directory: /home/lab13/project
[I 2025-02-06 15:09:12.581 ServerApp] Jupyter Server 2.14.2 is running at:
[I 2025-02-06 15:09:12.581 ServerApp] http://ip-172-31-13-81:8917/tree
[I 2025-02-06 15:09:12.581 ServerApp]     http://127.0.0.1:8917/tree
[I 2025-02-06 15:09:12.581 ServerApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[I 2025-02-06 15:09:12.599 ServerApp] Skipped non-installed server(s): bash-language-server, dockerfile-language-server-nodejs, javascript-typescript-langserver, jedi-language-server, julia-language-server, pyright, python-language-server, python-lsp-server, r-languageserver, sql-language-server, texlab, typescript-language-server, unified-language-server, vscode-css-languageserver-bin, vscode-html-languageserver-bin, vscode-json-languageserver-bin, yaml-language-server
[I 2025-02-06 15:10:09.443 ServerApp] 302 GET / (@125.129.250.60) 0.47ms
[I 2025-02-06 15:10:09.475 JupyterNotebookApp] 302 GET /tree? (@125.129.250.60) 0.52ms
[I 2025-02-06 15:10:13.391 ServerApp] User 8c1b3224a2404a088fde4e8bb099b22e logged in.
[I 2025-02-06 15:10:13.392 ServerApp] 302 POST /login?next=%2Ftree%3F (8c1b3224a2404a088fde4e8bb099b22e@125.129.250.60) 37.70ms
[W 2025-02-06 15:10:17.704 ServerApp] Notebook YJ/Untitled.ipynb is not trusted
[W 2025-02-06 15:10:20.541 ServerApp] Notebook YJ/youtube_preprocessing.ipynb is not trusted
[W 2025-02-06 15:10:22.092 ServerApp] Notebook YJ/youtube_preprocessing.ipynb is not trusted
[I 2025-02-06 15:10:22.501 ServerApp] Kernel started: 54599486-28f9-4652-bdb2-a979ce71c285
[I 2025-02-06 15:10:23.009 ServerApp] Connecting to kernel 54599486-28f9-4652-bdb2-a979ce71c285.
[I 2025-02-06 15:10:23.081 ServerApp] Connecting to kernel 54599486-28f9-4652-bdb2-a979ce71c285.
[I 2025-02-06 15:10:23.142 ServerApp] Connecting to kernel 54599486-28f9-4652-bdb2-a979ce71c285.
[I 2025-02-06 15:10:25.711 ServerApp] Connecting to kernel 54599486-28f9-4652-bdb2-a979ce71c285.
25/02/06 15:10:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 4:>                                                          (0 + 4) / 5][Stage 4:===========>                                               (1 + 4) / 5][Stage 4:===============================================>           (4 + 1) / 5]                                                                                [Stage 6:>                                                          (0 + 4) / 5][Stage 6:===========>                                               (1 + 4) / 5][Stage 7:=======================>                                (84 + 4) / 200][Stage 7:==================================>                    (125 + 4) / 200][Stage 7:==============================================>        (168 + 4) / 200]                                                                                [I 2025-02-06 15:12:22.316 ServerApp] Saving file at /YJ/youtube_preprocessing.ipynb
[I 2025-02-06 15:12:51.340 ServerApp] Saving file at /YJ/youtube_preprocessing.ipynb
[I 2025-02-06 15:19:46.042 ServerApp] Saving file at /YJ/youtube_preprocessing.ipynb
[I 2025-02-06 15:19:46.976 ServerApp] Starting buffering for 54599486-28f9-4652-bdb2-a979ce71c285:6cbab958-4ef6-4449-843e-67ad561929de
[I 2025-02-06 15:19:54.023 ServerApp] Connecting to kernel 54599486-28f9-4652-bdb2-a979ce71c285.
[I 2025-02-06 15:19:54.264 ServerApp] Starting buffering for 54599486-28f9-4652-bdb2-a979ce71c285:e3b165eb-f44e-4162-a5bb-8b57b1338af7
[I 2025-02-06 15:19:54.424 ServerApp] Kernel started: 077eb05d-22c8-4133-ab21-92b4631a5e18
[I 2025-02-06 15:19:54.886 ServerApp] Connecting to kernel 077eb05d-22c8-4133-ab21-92b4631a5e18.
[I 2025-02-06 15:20:10.555 ServerApp] Connecting to kernel 54599486-28f9-4652-bdb2-a979ce71c285.
[I 2025-02-06 15:20:10.660 ServerApp] Connecting to kernel 077eb05d-22c8-4133-ab21-92b4631a5e18.
[I 2025-02-06 15:20:10.816 ServerApp] Starting buffering for 54599486-28f9-4652-bdb2-a979ce71c285:3ecdbeea-13f2-4675-8936-633a0dbdf916
[I 2025-02-06 15:20:11.093 ServerApp] Connecting to kernel 54599486-28f9-4652-bdb2-a979ce71c285.
[I 2025-02-06 15:20:20.325 ServerApp] Saving file at /YJ/youtube_preprocessing.ipynb
25/02/06 15:20:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[I 2025-02-06 15:21:54.322 ServerApp] Saving file at /YJ/analytics/read_mysql.ipynb
[I 2025-02-06 15:22:11.669 ServerApp] Saving file at /YJ/youtube_preprocessing.ipynb
[I 2025-02-06 15:23:54.424 ServerApp] Saving file at /YJ/analytics/read_mysql.ipynb
[I 2025-02-06 15:29:42.026 ServerApp] Connecting to kernel 54599486-28f9-4652-bdb2-a979ce71c285.
[I 2025-02-06 15:29:42.115 ServerApp] Connecting to kernel 077eb05d-22c8-4133-ab21-92b4631a5e18.
[I 2025-02-06 15:29:54.556 ServerApp] Saving file at /YJ/analytics/read_mysql.ipynb
[I 2025-02-06 15:30:19.054 ServerApp] Kernel restarted: 077eb05d-22c8-4133-ab21-92b4631a5e18
[I 2025-02-06 15:30:19.090 ServerApp] Starting buffering for 077eb05d-22c8-4133-ab21-92b4631a5e18:5cd12b90-1af4-4e2c-a34e-269db9eea263
[I 2025-02-06 15:30:19.124 ServerApp] Connecting to kernel 077eb05d-22c8-4133-ab21-92b4631a5e18.
[I 2025-02-06 15:30:19.124 ServerApp] Restoring connection for 077eb05d-22c8-4133-ab21-92b4631a5e18:5cd12b90-1af4-4e2c-a34e-269db9eea263
25/02/06 15:30:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [I 2025-02-06 15:31:54.676 ServerApp] Saving file at /YJ/analytics/read_mysql.ipynb
[I 2025-02-06 15:33:54.783 ServerApp] Saving file at /YJ/analytics/read_mysql.ipynb
[I 2025-02-06 15:35:54.883 ServerApp] Saving file at /YJ/analytics/read_mysql.ipynb
[Stage 10:>                                                         (0 + 1) / 1][Stage 11:>                                                         (0 + 1) / 1]                                                                                [Stage 13:>                                                         (0 + 1) / 1]                                                                                25/02/06 15:36:33 WARN DAGScheduler: Broadcasting large task binary with size 3.3 MiB
25/02/06 15:36:48 WARN DAGScheduler: Broadcasting large task binary with size 3.3 MiB
25/02/06 15:36:53 WARN DAGScheduler: Broadcasting large task binary with size 3.3 MiB
[Stage 17:>                                                         (0 + 1) / 1][I 2025-02-06 15:37:54.997 ServerApp] Saving file at /YJ/analytics/read_mysql.ipynb
                                                                                25/02/06 15:37:59 WARN DAGScheduler: Broadcasting large task binary with size 3.3 MiB
[Stage 21:>                                                         (0 + 1) / 1]                                                                                25/02/06 15:38:06 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:38:12 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:38:40 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
[Stage 24:>                                                         (0 + 1) / 1]                                                                                25/02/06 15:38:47 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:38:47 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
[Stage 26:>                                                         (0 + 1) / 1]                                                                                25/02/06 15:38:48 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:38:48 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:38:49 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:38:49 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:38:49 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
25/02/06 15:38:49 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
25/02/06 15:38:50 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:38:50 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:38:51 WARN DAGScheduler: Broadcasting large task binary with size 11.4 MiB
[Stage 38:>                                                         (0 + 1) / 1]25/02/06 15:38:54 WARN DAGScheduler: Broadcasting large task binary with size 11.4 MiB
[Stage 39:>                                                       (0 + 4) / 200][Stage 39:=>                                                      (5 + 5) / 200][Stage 39:===>                                                   (11 + 4) / 200][Stage 39:===>                                                   (13 + 4) / 200][Stage 39:====>                                                  (17 + 4) / 200][Stage 39:=====>                                                 (21 + 4) / 200][Stage 39:======>                                                (25 + 4) / 200][Stage 39:=======>                                               (29 + 4) / 200][Stage 39:=========>                                             (33 + 4) / 200][Stage 39:==========>                                            (38 + 4) / 200][Stage 39:===========>                                           (42 + 4) / 200][Stage 39:============>                                          (46 + 4) / 200][Stage 39:=============>                                         (50 + 4) / 200][Stage 39:==============>                                        (54 + 4) / 200][Stage 39:===============>                                       (58 + 4) / 200][Stage 39:=================>                                     (63 + 4) / 200][Stage 39:=================>                                     (65 + 4) / 200][Stage 39:==================>                                    (69 + 4) / 200][Stage 39:====================>                                  (74 + 4) / 200][Stage 39:======================>                                (80 + 4) / 200][Stage 39:=======================>                               (85 + 4) / 200][Stage 39:========================>                              (90 + 4) / 200][Stage 39:=========================>                             (93 + 4) / 200][Stage 39:==========================>                            (98 + 4) / 200][Stage 39:===========================>                          (102 + 4) / 200][Stage 39:=============================>                        (108 + 5) / 200][Stage 39:==============================>                       (113 + 4) / 200][Stage 39:===============================>                      (118 + 4) / 200][Stage 39:================================>                     (122 + 4) / 200][Stage 39:==================================>                   (126 + 4) / 200][Stage 39:===================================>                  (130 + 4) / 200][Stage 39:====================================>                 (134 + 4) / 200][Stage 39:=====================================>                (140 + 4) / 200][Stage 39:=======================================>              (146 + 4) / 200][Stage 39:=======================================>              (147 + 4) / 200][Stage 39:=========================================>            (154 + 4) / 200][Stage 39:==========================================>           (158 + 4) / 200][Stage 39:===========================================>          (162 + 4) / 200][Stage 39:============================================>         (165 + 4) / 200][Stage 39:=============================================>        (169 + 4) / 200][Stage 39:==============================================>       (171 + 4) / 200][Stage 39:===============================================>      (175 + 5) / 200][Stage 39:================================================>     (180 + 4) / 200][Stage 39:=================================================>    (184 + 4) / 200][Stage 39:===================================================>  (189 + 5) / 200][Stage 39:====================================================> (194 + 4) / 200]                                                                                25/02/06 15:39:09 WARN DAGScheduler: Broadcasting large task binary with size 11.4 MiB
25/02/06 15:39:37 WARN DAGScheduler: Broadcasting large task binary with size 11.4 MiB
[Stage 41:>                                                         (0 + 1) / 1]25/02/06 15:39:41 WARN DAGScheduler: Broadcasting large task binary with size 11.4 MiB
                                                                                25/02/06 15:39:41 WARN DAGScheduler: Broadcasting large task binary with size 11.4 MiB
25/02/06 15:39:41 WARN DAGScheduler: Broadcasting large task binary with size 11.4 MiB
[Stage 46:===========>                                             (4 + 4) / 20][Stage 46:======================>                                  (8 + 4) / 20][Stage 46:=================================>                      (12 + 4) / 20][Stage 46:===============================================>        (17 + 3) / 20]                                                                                25/02/06 15:39:43 WARN DAGScheduler: Broadcasting large task binary with size 11.4 MiB
[Stage 48:==>                                                     (4 + 4) / 100][Stage 48:====>                                                   (8 + 4) / 100][Stage 48:=======>                                               (13 + 4) / 100][Stage 48:=========>                                             (17 + 4) / 100][Stage 48:===========>                                           (21 + 4) / 100][Stage 48:=============>                                         (25 + 4) / 100][Stage 48:===============>                                       (29 + 4) / 100][Stage 48:==================>                                    (33 + 4) / 100][Stage 48:====================>                                  (37 + 5) / 100][Stage 48:=======================>                               (43 + 4) / 100][Stage 48:==========================>                            (48 + 4) / 100][Stage 48:============================>                          (52 + 4) / 100][Stage 48:==============================>                        (56 + 4) / 100][Stage 48:=================================>                     (60 + 4) / 100][Stage 48:===================================>                   (64 + 4) / 100][Stage 48:=====================================>                 (69 + 4) / 100][Stage 48:========================================>              (73 + 4) / 100][Stage 48:=========================================>             (75 + 4) / 100][Stage 48:============================================>          (81 + 4) / 100][Stage 48:==============================================>        (85 + 4) / 100][Stage 48:=================================================>     (90 + 4) / 100][Stage 48:====================================================>  (95 + 4) / 100]                                                                                25/02/06 15:39:50 WARN DAGScheduler: Broadcasting large task binary with size 11.4 MiB
[Stage 50:======>                                                  (8 + 4) / 75][Stage 50:==========>                                             (14 + 4) / 75][Stage 50:=============>                                          (18 + 4) / 75][Stage 50:================>                                       (22 + 4) / 75][Stage 50:====================>                                   (27 + 4) / 75][Stage 50:=======================>                                (32 + 4) / 75][Stage 50:========================>                               (33 + 4) / 75][Stage 50:============================>                           (38 + 4) / 75][Stage 50:=================================>                      (45 + 4) / 75][Stage 50:====================================>                   (49 + 4) / 75][Stage 50:======================================>                 (51 + 4) / 75][Stage 50:=========================================>              (55 + 4) / 75][I 2025-02-06 15:39:55.150 ServerApp] Saving file at /YJ/analytics/read_mysql.ipynb
[Stage 50:==========================================>             (57 + 4) / 75][Stage 50:===============================================>        (63 + 4) / 75][Stage 50:==================================================>     (67 + 4) / 75][Stage 50:=====================================================>  (72 + 3) / 75]                                                                                25/02/06 15:39:56 WARN DAGScheduler: Broadcasting large task binary with size 11.4 MiB
25/02/06 15:39:57 WARN DAGScheduler: Broadcasting large task binary with size 11.4 MiB
[Stage 52:>                                                         (0 + 1) / 1]                                                                                25/02/06 15:40:02 WARN DAGScheduler: Broadcasting large task binary with size 11.4 MiB
[Stage 53:>                                                         (0 + 1) / 1]                                                                                25/02/06 15:40:54 WARN DAGScheduler: Broadcasting large task binary with size 11.4 MiB
25/02/06 15:41:12 WARN DAGScheduler: Broadcasting large task binary with size 11.4 MiB
25/02/06 15:41:27 WARN DAGScheduler: Broadcasting large task binary with size 11.4 MiB
[I 2025-02-06 15:41:55.413 ServerApp] Saving file at /YJ/analytics/read_mysql.ipynb
25/02/06 15:42:05 WARN DAGScheduler: Broadcasting large task binary with size 11.4 MiB
[Stage 57:>                                                         (0 + 1) / 1]                                                                                25/02/06 15:42:15 WARN DAGScheduler: Broadcasting large task binary with size 11.4 MiB
[Stage 58:>                                                         (0 + 1) / 1]                                                                                25/02/06 15:43:04 WARN DAGScheduler: Broadcasting large task binary with size 11.4 MiB
25/02/06 15:43:40 ERROR Instrumentation: java.lang.IllegalArgumentException: tfidf_features does not exist. Available: id, video_id, title, publish_date, channel_name, comment, like_count, comment_publish_date, inserted_at
	at org.apache.spark.sql.types.StructType.$anonfun$apply$1(StructType.scala:278)
	at scala.collection.MapLike.getOrElse(MapLike.scala:131)
	at scala.collection.MapLike.getOrElse$(MapLike.scala:129)
	at scala.collection.AbstractMap.getOrElse(Map.scala:63)
	at org.apache.spark.sql.types.StructType.apply(StructType.scala:277)
	at org.apache.spark.ml.util.SchemaUtils$.checkColumnTypes(SchemaUtils.scala:59)
	at org.apache.spark.ml.util.SchemaUtils$.validateVectorCompatibleColumn(SchemaUtils.scala:205)
	at org.apache.spark.ml.clustering.KMeansParams.validateAndTransformSchema(KMeans.scala:98)
	at org.apache.spark.ml.clustering.KMeansParams.validateAndTransformSchema$(KMeans.scala:97)
	at org.apache.spark.ml.clustering.KMeans.validateAndTransformSchema(KMeans.scala:272)
	at org.apache.spark.ml.clustering.KMeans.transformSchema(KMeans.scala:372)
	at org.apache.spark.ml.PipelineStage.transformSchema(Pipeline.scala:71)
	at org.apache.spark.ml.clustering.KMeans.$anonfun$fit$1(KMeans.scala:330)
	at org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)
	at org.apache.spark.ml.clustering.KMeans.fit(KMeans.scala:329)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:750)

25/02/06 15:43:54 ERROR Instrumentation: java.lang.IllegalArgumentException: requirement failed: Column cluster already exists.
	at scala.Predef$.require(Predef.scala:281)
	at org.apache.spark.ml.util.SchemaUtils$.appendColumn(SchemaUtils.scala:106)
	at org.apache.spark.ml.util.SchemaUtils$.appendColumn(SchemaUtils.scala:96)
	at org.apache.spark.ml.clustering.KMeansParams.validateAndTransformSchema(KMeans.scala:99)
	at org.apache.spark.ml.clustering.KMeansParams.validateAndTransformSchema$(KMeans.scala:97)
	at org.apache.spark.ml.clustering.KMeans.validateAndTransformSchema(KMeans.scala:272)
	at org.apache.spark.ml.clustering.KMeans.transformSchema(KMeans.scala:372)
	at org.apache.spark.ml.PipelineStage.transformSchema(Pipeline.scala:71)
	at org.apache.spark.ml.clustering.KMeans.$anonfun$fit$1(KMeans.scala:330)
	at org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)
	at org.apache.spark.ml.clustering.KMeans.fit(KMeans.scala:329)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:750)

[I 2025-02-06 15:43:55.663 ServerApp] Saving file at /YJ/analytics/read_mysql.ipynb
25/02/06 15:45:06 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
[Stage 60:>                                                         (0 + 1) / 1]                                                                                25/02/06 15:45:11 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:45:12 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:45:12 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:45:12 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:45:12 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:45:13 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:45:13 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:45:13 WARN BlockManager: Asked to remove block broadcast_74, which does not exist
25/02/06 15:45:13 WARN BlockManager: Asked to remove block broadcast_74_piece0, which does not exist
25/02/06 15:45:13 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:45:13 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:45:14 WARN DAGScheduler: Broadcasting large task binary with size 9.8 MiB
[Stage 74:>                                                         (0 + 1) / 1]25/02/06 15:45:17 WARN DAGScheduler: Broadcasting large task binary with size 9.8 MiB
[Stage 75:=>                                                      (4 + 4) / 200][Stage 75:==>                                                     (8 + 4) / 200][Stage 75:====>                                                  (16 + 4) / 200][Stage 75:=====>                                                 (20 + 4) / 200][Stage 75:======>                                                (25 + 4) / 200][Stage 75:========>                                              (30 + 4) / 200][Stage 75:=========>                                             (34 + 4) / 200][Stage 75:==========>                                            (38 + 4) / 200][Stage 75:===========>                                           (43 + 4) / 200][Stage 75:============>                                          (45 + 4) / 200][Stage 75:=============>                                         (49 + 4) / 200][Stage 75:===============>                                       (55 + 4) / 200][Stage 75:================>                                      (60 + 4) / 200][Stage 75:=================>                                     (64 + 4) / 200][Stage 75:==================>                                    (69 + 4) / 200][Stage 75:====================>                                  (75 + 4) / 200][Stage 75:======================>                                (80 + 4) / 200][Stage 75:======================>                                (83 + 4) / 200][Stage 75:========================>                              (88 + 4) / 200][Stage 75:=========================>                             (93 + 4) / 200][Stage 75:===========================>                           (99 + 4) / 200][Stage 75:============================>                         (104 + 4) / 200][Stage 75:=============================>                        (110 + 4) / 200][Stage 75:===============================>                      (116 + 4) / 200][Stage 75:================================>                     (119 + 4) / 200][Stage 75:=================================>                    (124 + 4) / 200][Stage 75:==================================>                   (129 + 4) / 200][Stage 75:====================================>                 (135 + 4) / 200][Stage 75:====================================>                 (137 + 4) / 200][Stage 75:======================================>               (141 + 4) / 200][Stage 75:=======================================>              (146 + 4) / 200][Stage 75:=========================================>            (152 + 4) / 200][Stage 75:==========================================>           (157 + 4) / 200][Stage 75:===========================================>          (162 + 4) / 200][Stage 75:=============================================>        (167 + 4) / 200][Stage 75:=============================================>        (170 + 4) / 200][Stage 75:===============================================>      (175 + 4) / 200][Stage 75:================================================>     (179 + 4) / 200][Stage 75:=================================================>    (184 + 4) / 200][Stage 75:===================================================>  (189 + 4) / 200][Stage 75:====================================================> (195 + 4) / 200]                                                                                25/02/06 15:45:29 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
[Stage 76:>                                                         (0 + 1) / 1]                                                                                25/02/06 15:45:34 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:45:34 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:45:35 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:45:35 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:45:35 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:45:35 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:45:36 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:45:36 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:45:36 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:45:36 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:45:37 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:45:37 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:45:37 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:45:38 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:45:38 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:45:38 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:45:38 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:45:39 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:45:39 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:45:39 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:45:39 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:45:40 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:45:40 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:45:40 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:45:41 WARN DAGScheduler: Broadcasting large task binary with size 11.4 MiB
[Stage 138:>                                                        (0 + 1) / 1]25/02/06 15:45:43 WARN DAGScheduler: Broadcasting large task binary with size 11.4 MiB
[Stage 139:=>                                                     (7 + 4) / 200][Stage 139:==>                                                   (11 + 4) / 200][Stage 139:===>                                                  (14 + 4) / 200][Stage 139:====>                                                 (18 + 4) / 200][Stage 139:=====>                                                (22 + 4) / 200][Stage 139:=======>                                              (26 + 4) / 200][Stage 139:========>                                             (31 + 4) / 200][Stage 139:=========>                                            (36 + 4) / 200][Stage 139:==========>                                           (40 + 4) / 200][Stage 139:===========>                                          (44 + 4) / 200][Stage 139:============>                                         (48 + 4) / 200][Stage 139:==============>                                       (53 + 4) / 200][Stage 139:===============>                                      (57 + 4) / 200][Stage 139:================>                                     (62 + 4) / 200][Stage 139:=================>                                    (66 + 4) / 200][Stage 139:==================>                                   (67 + 4) / 200][Stage 139:===================>                                  (71 + 4) / 200][Stage 139:=====================>                                (78 + 4) / 200][Stage 139:=====================>                                (81 + 4) / 200][Stage 139:======================>                               (85 + 4) / 200][Stage 139:========================>                             (91 + 4) / 200][Stage 139:=========================>                            (96 + 4) / 200][Stage 139:==========================>                          (100 + 4) / 200][Stage 139:===========================>                         (104 + 4) / 200][Stage 139:=============================>                       (110 + 4) / 200][Stage 139:==============================>                      (114 + 4) / 200][Stage 139:==============================>                      (115 + 4) / 200][Stage 139:================================>                    (121 + 4) / 200][Stage 139:=================================>                   (126 + 4) / 200][Stage 139:==================================>                  (130 + 4) / 200][Stage 139:====================================>                (136 + 4) / 200][Stage 139:====================================>                (139 + 4) / 200][Stage 139:=====================================>               (140 + 4) / 200][Stage 139:======================================>              (144 + 4) / 200][Stage 139:=======================================>             (149 + 4) / 200][Stage 139:=========================================>           (156 + 4) / 200][Stage 139:==========================================>          (160 + 4) / 200][I 2025-02-06 15:45:55.859 ServerApp] Saving file at /YJ/analytics/read_mysql.ipynb
[Stage 139:===========================================>         (164 + 4) / 200][Stage 139:============================================>        (167 + 4) / 200][Stage 139:=============================================>       (172 + 4) / 200][Stage 139:==============================================>      (177 + 4) / 200][Stage 139:================================================>    (182 + 4) / 200][Stage 139:=================================================>   (186 + 4) / 200][Stage 139:==================================================>  (191 + 4) / 200][Stage 139:===================================================> (194 + 4) / 200]                                                                                25/02/06 15:45:58 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
[Stage 140:>                                                        (0 + 1) / 1]                                                                                25/02/06 15:46:03 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:46:03 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:46:04 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:46:04 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:46:04 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:46:05 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:46:05 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:46:05 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:46:06 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:46:06 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:46:06 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:46:06 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:46:07 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:46:07 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:46:07 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:46:08 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:46:08 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:46:08 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:46:08 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:46:09 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:46:09 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:46:09 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:46:10 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:46:10 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:46:10 WARN DAGScheduler: Broadcasting large task binary with size 13.0 MiB
[Stage 202:>                                                        (0 + 1) / 1]25/02/06 15:46:13 WARN DAGScheduler: Broadcasting large task binary with size 13.0 MiB
[Stage 203:=>                                                     (6 + 4) / 200][Stage 203:==>                                                    (8 + 4) / 200][Stage 203:===>                                                  (12 + 4) / 200][Stage 203:====>                                                 (16 + 4) / 200][Stage 203:=====>                                                (20 + 4) / 200][Stage 203:======>                                               (24 + 4) / 200][Stage 203:=======>                                              (28 + 4) / 200][Stage 203:========>                                             (32 + 4) / 200][Stage 203:==========>                                           (38 + 4) / 200][Stage 203:===========>                                          (41 + 5) / 200][Stage 203:============>                                         (46 + 4) / 200][Stage 203:=============>                                        (49 + 4) / 200][Stage 203:==============>                                       (54 + 4) / 200][Stage 203:===============>                                      (59 + 4) / 200][Stage 203:=================>                                    (64 + 4) / 200][Stage 203:==================>                                   (67 + 4) / 200][Stage 203:==================>                                   (68 + 5) / 200][Stage 203:===================>                                  (72 + 4) / 200][Stage 203:====================>                                 (76 + 4) / 200][Stage 203:=====================>                                (81 + 4) / 200][Stage 203:======================>                               (84 + 4) / 200][Stage 203:=======================>                              (86 + 4) / 200][Stage 203:========================>                             (90 + 4) / 200][Stage 203:=========================>                            (93 + 4) / 200][Stage 203:=========================>                            (96 + 4) / 200][Stage 203:===========================>                         (102 + 4) / 200][Stage 203:============================>                        (106 + 4) / 200][Stage 203:============================>                        (107 + 4) / 200][Stage 203:=============================>                       (111 + 4) / 200][Stage 203:===============================>                     (117 + 4) / 200][Stage 203:================================>                    (122 + 4) / 200][Stage 203:=================================>                   (126 + 4) / 200][Stage 203:=================================>                   (128 + 4) / 200][Stage 203:===================================>                 (133 + 4) / 200][Stage 203:====================================>                (137 + 4) / 200][Stage 203:=====================================>               (142 + 4) / 200][Stage 203:======================================>              (147 + 4) / 200][Stage 203:=======================================>             (148 + 4) / 200][Stage 203:=========================================>           (155 + 4) / 200][Stage 203:==========================================>          (159 + 4) / 200][Stage 203:===========================================>         (163 + 4) / 200][Stage 203:============================================>        (167 + 4) / 200][Stage 203:=============================================>       (171 + 4) / 200][Stage 203:==============================================>      (175 + 4) / 200][Stage 203:===============================================>     (180 + 4) / 200][Stage 203:================================================>    (184 + 4) / 200][Stage 203:=================================================>   (188 + 4) / 200][Stage 203:===================================================> (193 + 4) / 200]                                                                                25/02/06 15:46:31 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
[Stage 204:>                                                        (0 + 1) / 1]                                                                                25/02/06 15:46:36 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:46:36 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:46:37 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:46:37 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:46:37 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:46:37 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:46:38 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:46:38 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:46:39 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:46:39 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:46:39 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:46:40 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:46:40 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:46:40 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:46:40 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:46:41 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:46:41 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:46:41 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:46:42 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:46:42 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:46:42 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:46:43 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:46:43 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:46:43 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:46:44 WARN DAGScheduler: Broadcasting large task binary with size 14.6 MiB
[Stage 266:>                                                        (0 + 1) / 1]25/02/06 15:46:47 WARN DAGScheduler: Broadcasting large task binary with size 14.6 MiB
[Stage 267:=>                                                     (4 + 4) / 200][Stage 267:==>                                                    (9 + 4) / 200][Stage 267:===>                                                  (13 + 4) / 200][Stage 267:====>                                                 (17 + 4) / 200][Stage 267:=====>                                                (21 + 4) / 200][Stage 267:======>                                               (25 + 4) / 200][Stage 267:=======>                                              (29 + 4) / 200][Stage 267:========>                                             (33 + 4) / 200][Stage 267:=========>                                            (37 + 4) / 200][Stage 267:===========>                                          (42 + 4) / 200][Stage 267:============>                                         (46 + 4) / 200][Stage 267:=============>                                        (51 + 4) / 200][Stage 267:==============>                                       (52 + 4) / 200][Stage 267:===============>                                      (58 + 4) / 200][Stage 267:================>                                     (62 + 4) / 200][Stage 267:==================>                                   (67 + 4) / 200][Stage 267:==================>                                   (69 + 4) / 200][Stage 267:===================>                                  (72 + 4) / 200][Stage 267:=====================>                                (78 + 4) / 200][Stage 267:======================>                               (82 + 4) / 200][Stage 267:=======================>                              (88 + 4) / 200][Stage 267:========================>                             (92 + 4) / 200][Stage 267:==========================>                           (99 + 4) / 200][Stage 267:===========================>                         (103 + 4) / 200][Stage 267:============================>                        (107 + 4) / 200][Stage 267:=============================>                       (111 + 4) / 200][Stage 267:=============================>                       (112 + 4) / 200][Stage 267:===============================>                     (117 + 4) / 200][Stage 267:===============================>                     (120 + 4) / 200][Stage 267:================================>                    (124 + 4) / 200][Stage 267:=================================>                   (127 + 4) / 200][Stage 267:==================================>                  (131 + 4) / 200][Stage 267:===================================>                 (135 + 4) / 200][Stage 267:====================================>                (136 + 4) / 200][Stage 267:====================================>                (139 + 4) / 200][Stage 267:======================================>              (144 + 4) / 200][Stage 267:=======================================>             (150 + 4) / 200][Stage 267:========================================>            (154 + 4) / 200][Stage 267:==========================================>          (159 + 4) / 200][Stage 267:===========================================>         (163 + 4) / 200][Stage 267:============================================>        (167 + 4) / 200][Stage 267:=============================================>       (172 + 4) / 200][Stage 267:=============================================>       (173 + 4) / 200][Stage 267:==============================================>      (177 + 4) / 200][Stage 267:================================================>    (184 + 4) / 200][Stage 267:=================================================>   (188 + 5) / 200][Stage 267:==================================================>  (192 + 4) / 200][Stage 267:===================================================> (194 + 4) / 200]                                                                                25/02/06 15:47:05 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
[Stage 268:>                                                        (0 + 1) / 1]                                                                                25/02/06 15:47:10 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:47:10 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:47:11 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:47:11 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:47:11 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:47:12 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:47:12 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:47:12 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:47:13 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:47:13 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:47:13 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:47:14 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:47:14 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:47:14 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:47:15 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:47:15 WARN DAGScheduler: Broadcasting large task binary with size 16.2 MiB
[Stage 303:>                                                        (0 + 1) / 1]25/02/06 15:47:18 WARN DAGScheduler: Broadcasting large task binary with size 16.2 MiB
[Stage 304:=>                                                     (4 + 4) / 200][Stage 304:==>                                                    (8 + 4) / 200][Stage 304:===>                                                  (12 + 4) / 200][Stage 304:====>                                                 (16 + 4) / 200][Stage 304:=====>                                                (20 + 4) / 200][Stage 304:======>                                               (24 + 4) / 200][Stage 304:=======>                                              (28 + 4) / 200][Stage 304:========>                                             (31 + 5) / 200][Stage 304:=========>                                            (35 + 4) / 200][Stage 304:==========>                                           (40 + 4) / 200][Stage 304:===========>                                          (44 + 4) / 200][Stage 304:============>                                         (48 + 4) / 200][Stage 304:==============>                                       (52 + 4) / 200][Stage 304:===============>                                      (57 + 4) / 200][Stage 304:================>                                     (61 + 4) / 200][Stage 304:=================>                                    (65 + 4) / 200][Stage 304:==================>                                   (69 + 4) / 200][Stage 304:====================>                                 (75 + 4) / 200][Stage 304:=====================>                                (80 + 4) / 200][Stage 304:======================>                               (84 + 4) / 200][Stage 304:=======================>                              (88 + 4) / 200][Stage 304:========================>                             (91 + 5) / 200][Stage 304:=========================>                            (96 + 4) / 200][Stage 304:==========================>                           (97 + 4) / 200][Stage 304:==========================>                          (101 + 5) / 200][Stage 304:============================>                        (106 + 4) / 200][Stage 304:=============================>                       (110 + 4) / 200][Stage 304:=============================>                       (112 + 4) / 200][Stage 304:==============================>                      (116 + 4) / 200][Stage 304:===============================>                     (120 + 4) / 200][Stage 304:=================================>                   (125 + 4) / 200][Stage 304:==================================>                  (131 + 4) / 200][Stage 304:====================================>                (136 + 4) / 200][Stage 304:=====================================>               (140 + 4) / 200][Stage 304:======================================>              (144 + 4) / 200][Stage 304:=======================================>             (148 + 4) / 200][Stage 304:========================================>            (152 + 4) / 200][Stage 304:=========================================>           (156 + 4) / 200][Stage 304:==========================================>          (159 + 4) / 200][Stage 304:===========================================>         (164 + 4) / 200][Stage 304:============================================>        (168 + 4) / 200][Stage 304:=============================================>       (172 + 4) / 200][Stage 304:==============================================>      (176 + 4) / 200][Stage 304:==============================================>      (177 + 4) / 200][Stage 304:================================================>    (182 + 4) / 200][Stage 304:=================================================>   (186 + 4) / 200][Stage 304:==================================================>  (191 + 4) / 200][Stage 304:==================================================>  (192 + 4) / 200][Stage 304:===================================================> (196 + 4) / 200]                                                                                25/02/06 15:47:37 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
[Stage 305:>                                                        (0 + 1) / 1]                                                                                25/02/06 15:47:42 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:47:42 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:47:43 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:47:43 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:47:43 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:47:43 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:47:44 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:47:45 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:47:45 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:47:45 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:47:46 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:47:46 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:47:46 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:47:47 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:47:47 WARN DAGScheduler: Broadcasting large task binary with size 17.8 MiB
[Stage 337:>                                                        (0 + 1) / 1]25/02/06 15:47:50 WARN DAGScheduler: Broadcasting large task binary with size 17.8 MiB
[Stage 338:>                                                      (0 + 4) / 200][Stage 338:=>                                                     (4 + 4) / 200][Stage 338:==>                                                    (8 + 4) / 200][Stage 338:==>                                                   (10 + 4) / 200][Stage 338:===>                                                  (13 + 4) / 200][Stage 338:====>                                                 (18 + 4) / 200][Stage 338:=====>                                                (20 + 4) / 200][Stage 338:======>                                               (23 + 4) / 200][Stage 338:=======>                                              (27 + 4) / 200][Stage 338:========>                                             (31 + 4) / 200][Stage 338:=========>                                            (35 + 4) / 200][Stage 338:==========>                                           (39 + 4) / 200][Stage 338:===========>                                          (43 + 4) / 200][Stage 338:============>                                         (47 + 4) / 200][Stage 338:=============>                                        (51 + 4) / 200][Stage 338:==============>                                       (54 + 4) / 200][Stage 338:===============>                                      (57 + 4) / 200][Stage 338:================>                                     (61 + 4) / 200][Stage 338:=================>                                    (65 + 4) / 200][Stage 338:==================>                                   (69 + 4) / 200][Stage 338:===================>                                  (72 + 4) / 200][Stage 338:===================>                                  (73 + 4) / 200][Stage 338:====================>                                 (77 + 4) / 200][Stage 338:=====================>                                (80 + 4) / 200][Stage 338:======================>                               (83 + 4) / 200][Stage 338:=======================>                              (86 + 4) / 200][Stage 338:========================>                             (90 + 4) / 200][Stage 338:=========================>                            (93 + 4) / 200][Stage 338:=========================>                            (95 + 4) / 200][Stage 338:==========================>                           (99 + 4) / 200][Stage 338:===========================>                         (103 + 4) / 200][Stage 338:============================>                        (107 + 4) / 200][Stage 338:=============================>                       (110 + 4) / 200][Stage 338:==============================>                      (114 + 4) / 200][Stage 338:==============================>                      (115 + 4) / 200][Stage 338:===============================>                     (119 + 4) / 200][Stage 338:================================>                    (122 + 4) / 200][Stage 338:=================================>                   (125 + 4) / 200][Stage 338:=================================>                   (128 + 4) / 200][Stage 338:==================================>                  (132 + 4) / 200][Stage 338:====================================>                (137 + 4) / 200][Stage 338:=====================================>               (141 + 4) / 200][Stage 338:======================================>              (144 + 4) / 200][Stage 338:=======================================>             (148 + 4) / 200][Stage 338:========================================>            (152 + 4) / 200][Stage 338:=========================================>           (155 + 4) / 200][Stage 338:=========================================>           (157 + 4) / 200][Stage 338:==========================================>          (161 + 4) / 200][Stage 338:===========================================>         (164 + 4) / 200][Stage 338:============================================>        (168 + 4) / 200][Stage 338:=============================================>       (172 + 4) / 200][Stage 338:==============================================>      (176 + 4) / 200][Stage 338:==============================================>      (177 + 4) / 200][Stage 338:===============================================>     (178 + 4) / 200][Stage 338:================================================>    (183 + 4) / 200][Stage 338:=================================================>   (186 + 4) / 200][Stage 338:=================================================>   (188 + 4) / 200][Stage 338:==================================================>  (191 + 4) / 200][Stage 338:===================================================> (194 + 4) / 200][Stage 338:====================================================>(198 + 2) / 200]                                                                                25/02/06 15:48:13 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
[Stage 339:>                                                        (0 + 1) / 1]                                                                                25/02/06 15:48:18 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:48:18 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:48:19 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:48:19 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:48:19 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:48:20 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:48:21 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:48:21 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:48:21 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:48:22 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:48:22 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:48:23 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:48:23 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:48:23 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:48:24 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:48:24 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:48:24 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:48:25 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:48:25 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:48:25 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:48:26 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:48:26 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:48:27 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:48:27 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:48:28 WARN DAGScheduler: Broadcasting large task binary with size 19.4 MiB
[Stage 401:>                                                        (0 + 1) / 1]25/02/06 15:48:31 WARN DAGScheduler: Broadcasting large task binary with size 19.4 MiB
[Stage 402:=>                                                     (4 + 4) / 200][Stage 402:=>                                                     (7 + 4) / 200][Stage 402:==>                                                    (8 + 4) / 200][Stage 402:===>                                                  (13 + 4) / 200][Stage 402:===>                                                  (14 + 4) / 200][Stage 402:====>                                                 (17 + 4) / 200][Stage 402:=====>                                                (21 + 4) / 200][Stage 402:======>                                               (25 + 4) / 200][Stage 402:=======>                                              (27 + 4) / 200][Stage 402:=======>                                              (28 + 4) / 200][Stage 402:=======>                                              (29 + 4) / 200][Stage 402:========>                                             (33 + 4) / 200][Stage 402:=========>                                            (37 + 4) / 200][Stage 402:===========>                                          (42 + 4) / 200][Stage 402:===========>                                          (44 + 4) / 200][Stage 402:============>                                         (45 + 4) / 200][Stage 402:=============>                                        (49 + 4) / 200][Stage 402:==============>                                       (52 + 5) / 200][Stage 402:===============>                                      (57 + 4) / 200][Stage 402:===============>                                      (58 + 4) / 200][Stage 402:================>                                     (61 + 4) / 200][Stage 402:=================>                                    (65 + 4) / 200][Stage 402:==================>                                   (69 + 4) / 200][Stage 402:===================>                                  (73 + 4) / 200][Stage 402:=====================>                                (78 + 4) / 200][Stage 402:======================>                               (82 + 4) / 200][Stage 402:=======================>                              (86 + 4) / 200][Stage 402:========================>                             (90 + 4) / 200][Stage 402:=========================>                            (94 + 4) / 200][Stage 402:=========================>                            (95 + 4) / 200][Stage 402:==========================>                           (99 + 4) / 200][Stage 402:===========================>                         (103 + 4) / 200][Stage 402:============================>                        (107 + 4) / 200][Stage 402:=============================>                       (111 + 4) / 200][Stage 402:==============================>                      (115 + 4) / 200][Stage 402:===============================>                     (119 + 4) / 200][Stage 402:================================>                    (122 + 4) / 200][Stage 402:=================================>                   (127 + 4) / 200][Stage 402:==================================>                  (131 + 4) / 200][Stage 402:===================================>                 (135 + 4) / 200][Stage 402:====================================>                (139 + 4) / 200][Stage 402:======================================>              (144 + 4) / 200][Stage 402:=======================================>             (148 + 4) / 200][Stage 402:========================================>            (152 + 4) / 200][Stage 402:========================================>            (153 + 5) / 200][Stage 402:=========================================>           (158 + 4) / 200][Stage 402:===========================================>         (163 + 4) / 200][Stage 402:============================================>        (167 + 4) / 200][Stage 402:============================================>        (168 + 4) / 200][Stage 402:=============================================>       (172 + 4) / 200][Stage 402:==============================================>      (176 + 4) / 200][Stage 402:===============================================>     (180 + 4) / 200][Stage 402:================================================>    (184 + 4) / 200][Stage 402:=================================================>   (187 + 4) / 200][Stage 402:==================================================>  (192 + 4) / 200][Stage 402:===================================================> (195 + 4) / 200]                                                                                25/02/06 15:48:53 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
[Stage 403:>                                                        (0 + 1) / 1]                                                                                25/02/06 15:48:57 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:48:57 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:48:58 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:48:58 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:48:59 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:48:59 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:49:00 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:49:00 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:49:01 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:49:01 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:49:01 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:49:02 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:49:02 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:49:03 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:49:03 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:49:03 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:49:04 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:49:04 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:49:04 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:49:05 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:49:05 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:49:06 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:49:06 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:49:06 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:49:07 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:49:07 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:49:08 WARN DAGScheduler: Broadcasting large task binary with size 21.0 MiB
[Stage 471:>                                                        (0 + 1) / 1]25/02/06 15:49:11 WARN DAGScheduler: Broadcasting large task binary with size 21.0 MiB
[Stage 472:=>                                                     (4 + 4) / 200][Stage 472:==>                                                    (8 + 4) / 200][Stage 472:===>                                                  (12 + 4) / 200][Stage 472:====>                                                 (16 + 4) / 200][Stage 472:====>                                                 (18 + 4) / 200][Stage 472:=====>                                                (19 + 4) / 200][Stage 472:=====>                                                (20 + 4) / 200][Stage 472:======>                                               (24 + 4) / 200][Stage 472:=======>                                              (28 + 4) / 200][Stage 472:========>                                             (32 + 4) / 200][Stage 472:=========>                                            (36 + 4) / 200][Stage 472:==========>                                           (39 + 4) / 200][Stage 472:===========>                                          (41 + 4) / 200][Stage 472:============>                                         (45 + 4) / 200][Stage 472:=============>                                        (49 + 4) / 200][Stage 472:==============>                                       (52 + 4) / 200][Stage 472:===============>                                      (56 + 5) / 200][Stage 472:================>                                     (60 + 4) / 200][Stage 472:=================>                                    (64 + 4) / 200][Stage 472:==================>                                   (68 + 4) / 200][Stage 472:==================>                                   (69 + 4) / 200][Stage 472:===================>                                  (73 + 4) / 200][Stage 472:====================>                                 (77 + 4) / 200][Stage 472:=====================>                                (79 + 4) / 200][Stage 472:======================>                               (83 + 4) / 200][Stage 472:======================>                               (85 + 4) / 200][Stage 472:========================>                             (89 + 4) / 200][Stage 472:=========================>                            (93 + 4) / 200][Stage 472:==========================>                           (97 + 4) / 200][Stage 472:==========================>                          (100 + 4) / 200][Stage 472:===========================>                         (104 + 4) / 200][Stage 472:============================>                        (109 + 4) / 200][Stage 472:=============================>                       (111 + 4) / 200][Stage 472:==============================>                      (114 + 4) / 200][Stage 472:===============================>                     (118 + 4) / 200][Stage 472:================================>                    (121 + 4) / 200][Stage 472:=================================>                   (125 + 4) / 200][Stage 472:==================================>                  (129 + 4) / 200][Stage 472:===================================>                 (133 + 4) / 200][Stage 472:====================================>                (137 + 4) / 200][Stage 472:=====================================>               (141 + 4) / 200][Stage 472:======================================>              (145 + 4) / 200][Stage 472:=======================================>             (148 + 4) / 200][Stage 472:========================================>            (152 + 4) / 200][Stage 472:=========================================>           (156 + 4) / 200][Stage 472:=========================================>           (157 + 4) / 200][Stage 472:==========================================>          (161 + 4) / 200][Stage 472:===========================================>         (165 + 4) / 200][Stage 472:============================================>        (169 + 4) / 200][Stage 472:=============================================>       (173 + 4) / 200][Stage 472:==============================================>      (177 + 4) / 200][Stage 472:===============================================>     (181 + 4) / 200][Stage 472:=================================================>   (185 + 4) / 200][Stage 472:==================================================>  (189 + 4) / 200][Stage 472:===================================================> (193 + 4) / 200][Stage 472:===================================================> (196 + 4) / 200]                                                                                [I 2025-02-06 15:49:56.087 ServerApp] Saving file at /YJ/analytics/read_mysql.ipynb
[Stage 473:>                                                        (0 + 1) / 1]                                                                                25/02/06 15:50:26 WARN DAGScheduler: Broadcasting large task binary with size 3.3 MiB
[Stage 477:>                                                        (0 + 1) / 1]                                                                                25/02/06 15:50:32 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:50:36 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
[Stage 479:>                                                        (0 + 1) / 1]                                                                                25/02/06 15:50:41 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:50:41 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:50:41 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:50:41 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:50:42 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:50:42 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:50:42 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:50:43 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:50:43 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 15:50:43 WARN DAGScheduler: Broadcasting large task binary with size 9.8 MiB
[Stage 493:>                                                        (0 + 1) / 1]25/02/06 15:50:46 WARN DAGScheduler: Broadcasting large task binary with size 9.8 MiB
[Stage 494:>                                                      (0 + 4) / 200][Stage 494:==>                                                    (8 + 4) / 200][Stage 494:==>                                                   (10 + 5) / 200][Stage 494:====>                                                 (15 + 4) / 200][Stage 494:=====>                                                (19 + 4) / 200][Stage 494:======>                                               (23 + 4) / 200][Stage 494:=======>                                              (27 + 4) / 200][Stage 494:========>                                             (31 + 4) / 200][Stage 494:=========>                                            (35 + 4) / 200][Stage 494:==========>                                           (39 + 4) / 200][Stage 494:===========>                                          (44 + 4) / 200][Stage 494:============>                                         (48 + 4) / 200][Stage 494:==============>                                       (53 + 4) / 200][Stage 494:===============>                                      (58 + 4) / 200][Stage 494:=================>                                    (63 + 4) / 200][Stage 494:==================>                                   (67 + 4) / 200][Stage 494:===================>                                  (71 + 4) / 200][Stage 494:====================>                                 (76 + 4) / 200][Stage 494:=====================>                                (78 + 4) / 200][Stage 494:======================>                               (82 + 4) / 200][Stage 494:=======================>                              (86 + 4) / 200][Stage 494:========================>                             (91 + 4) / 200][Stage 494:=========================>                            (95 + 4) / 200][Stage 494:==========================>                           (98 + 4) / 200][Stage 494:===========================>                         (102 + 4) / 200][Stage 494:============================>                        (106 + 4) / 200][Stage 494:=============================>                       (112 + 4) / 200][Stage 494:===============================>                     (117 + 4) / 200][Stage 494:================================>                    (121 + 4) / 200][Stage 494:=================================>                   (125 + 4) / 200][Stage 494:==================================>                  (129 + 4) / 200][Stage 494:====================================>                (136 + 4) / 200][Stage 494:=====================================>               (141 + 4) / 200][Stage 494:======================================>              (145 + 4) / 200][Stage 494:=======================================>             (150 + 4) / 200][Stage 494:=========================================>           (156 + 4) / 200][Stage 494:==========================================>          (161 + 4) / 200][Stage 494:===========================================>         (165 + 4) / 200][Stage 494:============================================>        (169 + 4) / 200][Stage 494:==============================================>      (176 + 5) / 200][Stage 494:===============================================>     (181 + 4) / 200][Stage 494:=================================================>   (185 + 4) / 200][Stage 494:==================================================>  (189 + 4) / 200][Stage 494:===================================================> (193 + 4) / 200][Stage 494:====================================================>(197 + 3) / 200]                                                                                25/02/06 15:51:02 WARN DAGScheduler: Broadcasting large task binary with size 9.8 MiB
25/02/06 15:51:05 WARN DAGScheduler: Broadcasting large task binary with size 9.8 MiB
[Stage 496:>                                                        (0 + 1) / 1]25/02/06 15:51:08 WARN DAGScheduler: Broadcasting large task binary with size 9.8 MiB
                                                                                25/02/06 15:51:08 WARN DAGScheduler: Broadcasting large task binary with size 9.8 MiB
25/02/06 15:51:09 WARN DAGScheduler: Broadcasting large task binary with size 9.8 MiB
[Stage 501:===========>                                            (4 + 4) / 20][Stage 501:======================>                                 (8 + 4) / 20][Stage 501:=================================>                     (12 + 4) / 20][Stage 501:=========================================>             (15 + 4) / 20]                                                                                25/02/06 15:51:11 WARN DAGScheduler: Broadcasting large task binary with size 9.8 MiB
[Stage 503:>                                                      (0 + 4) / 100][Stage 503:==>                                                    (5 + 4) / 100][Stage 503:=====>                                                (10 + 4) / 100][Stage 503:========>                                             (15 + 4) / 100][Stage 503:==========>                                           (19 + 4) / 100][Stage 503:============>                                         (24 + 4) / 100][Stage 503:===============>                                      (28 + 4) / 100][Stage 503:=================>                                    (32 + 4) / 100][Stage 503:===================>                                  (36 + 4) / 100][Stage 503:=====================>                                (40 + 4) / 100][Stage 503:=========================>                            (47 + 4) / 100][Stage 503:===========================>                          (50 + 4) / 100][Stage 503:==============================>                       (56 + 4) / 100][Stage 503:===============================>                      (58 + 4) / 100][Stage 503:================================>                     (61 + 4) / 100][Stage 503:==================================>                   (64 + 4) / 100][Stage 503:====================================>                 (68 + 4) / 100][Stage 503:=======================================>              (74 + 4) / 100][Stage 503:===========================================>          (80 + 4) / 100][Stage 503:============================================>         (83 + 4) / 100][Stage 503:================================================>     (89 + 4) / 100][Stage 503:==================================================>   (93 + 4) / 100]                                                                                25/02/06 15:51:18 WARN DAGScheduler: Broadcasting large task binary with size 9.8 MiB
[Stage 505:=====>                                                  (8 + 4) / 75][Stage 505:=========>                                             (13 + 4) / 75][Stage 505:=============>                                         (18 + 4) / 75][Stage 505:=================>                                     (24 + 4) / 75][Stage 505:====================>                                  (28 + 4) / 75][Stage 505:=========================>                             (35 + 4) / 75][Stage 505:============================>                          (39 + 4) / 75][Stage 505:===============================>                       (43 + 4) / 75][Stage 505:==================================>                    (47 + 4) / 75][Stage 505:======================================>                (53 + 4) / 75][Stage 505:==========================================>            (58 + 4) / 75][Stage 505:==============================================>        (63 + 4) / 75][Stage 505:=================================================>     (68 + 4) / 75][Stage 505:====================================================>  (72 + 3) / 75]                                                                                25/02/06 15:51:23 WARN DAGScheduler: Broadcasting large task binary with size 9.8 MiB
[Stage 506:>                                                        (0 + 1) / 1]                                                                                25/02/06 15:51:24 WARN DAGScheduler: Broadcasting large task binary with size 9.8 MiB
[Stage 507:>                                                        (0 + 1) / 1]                                                                                25/02/06 15:51:27 WARN DAGScheduler: Broadcasting large task binary with size 9.8 MiB
[Stage 508:>                                                        (0 + 1) / 1]                                                                                25/02/06 15:51:46 WARN DAGScheduler: Broadcasting large task binary with size 9.8 MiB
25/02/06 15:51:53 WARN DAGScheduler: Broadcasting large task binary with size 9.8 MiB
[Stage 510:>                                                        (0 + 1) / 1]                                                                                [I 2025-02-06 15:51:56.235 ServerApp] Saving file at /YJ/analytics/read_mysql.ipynb
25/02/06 15:52:22 WARN DAGScheduler: Broadcasting large task binary with size 9.8 MiB
25/02/06 15:52:29 WARN DAGScheduler: Broadcasting large task binary with size 9.8 MiB
[Stage 512:>                                                        (0 + 1) / 1]                                                                                25/02/06 15:52:43 WARN DAGScheduler: Broadcasting large task binary with size 9.8 MiB
[Stage 513:>                                                        (0 + 1) / 1]                                                                                [I 2025-02-06 15:53:56.380 ServerApp] Saving file at /YJ/analytics/read_mysql.ipynb
[I 2025-02-06 15:55:56.534 ServerApp] Saving file at /YJ/analytics/read_mysql.ipynb
[I 2025-02-06 16:01:10.789 ServerApp] Saving file at /YJ/analytics/read_mysql.ipynb
[I 2025-02-06 16:01:21.061 ServerApp] Creating new notebook in /YJ
[I 2025-02-06 16:01:21.255 ServerApp] Saving file at /YJ/Untitled3.ipynb
[I 2025-02-06 16:01:21.283 ServerApp] Kernel started: a9205a99-d47d-4d7f-b954-eb91ebd81499
[I 2025-02-06 16:01:21.761 ServerApp] Connecting to kernel a9205a99-d47d-4d7f-b954-eb91ebd81499.
[I 2025-02-06 16:01:22.693 ServerApp] Connecting to kernel 54599486-28f9-4652-bdb2-a979ce71c285.
[I 2025-02-06 16:01:22.794 ServerApp] Connecting to kernel 077eb05d-22c8-4133-ab21-92b4631a5e18.
[I 2025-02-06 16:01:22.860 ServerApp] Connecting to kernel a9205a99-d47d-4d7f-b954-eb91ebd81499.
[I 2025-02-06 16:01:23.049 ServerApp] Connecting to kernel a9205a99-d47d-4d7f-b954-eb91ebd81499.
[I 2025-02-06 16:03:22.908 ServerApp] Saving file at /YJ/Untitled3.ipynb
[I 2025-02-06 16:05:23.618 ServerApp] Saving file at /YJ/Untitled3.ipynb
[I 2025-02-06 16:27:53.636 ServerApp] Kernel started: 40f07ade-5d1a-4a52-b472-4bd4bbd6abaa
[I 2025-02-06 16:27:53.637 ServerApp] Kernel shutdown: 077eb05d-22c8-4133-ab21-92b4631a5e18
[I 2025-02-06 16:27:55.466 ServerApp] Starting buffering for 077eb05d-22c8-4133-ab21-92b4631a5e18:5cd12b90-1af4-4e2c-a34e-269db9eea263
[I 2025-02-06 16:27:55.504 ServerApp] Connecting to kernel 40f07ade-5d1a-4a52-b472-4bd4bbd6abaa.
[I 2025-02-06 16:29:11.675 ServerApp] Saving file at /YJ/analytics/read_mysql.ipynb
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
25/02/06 16:30:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 3:>                                                          (0 + 1) / 1]                                                                                25/02/06 16:30:51 WARN DAGScheduler: Broadcasting large task binary with size 3.3 MiB
[Stage 4:>                                                          (0 + 1) / 1]                                                                                [I 2025-02-06 16:31:11.855 ServerApp] Saving file at /YJ/analytics/read_mysql.ipynb
25/02/06 16:31:25 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
[Stage 5:>                                                          (0 + 1) / 1]25/02/06 16:31:41 ERROR Executor: Exception in task 0.0 in stage 5.0 (TID 4)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 473, in main
    raise Exception(("Python in worker has different version %s than that in " +
Exception: Python in worker has different version 3.8 than that in driver 3.9, PySpark cannot run with different minor versions. Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:517)
	at org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:84)
	at org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:67)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:470)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:489)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:345)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
25/02/06 16:31:41 WARN TaskSetManager: Lost task 0.0 in stage 5.0 (TID 4) (ip-172-31-13-81.ap-northeast-3.compute.internal executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 473, in main
    raise Exception(("Python in worker has different version %s than that in " +
Exception: Python in worker has different version 3.8 than that in driver 3.9, PySpark cannot run with different minor versions. Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:517)
	at org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:84)
	at org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:67)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:470)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:489)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:345)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

25/02/06 16:31:41 ERROR TaskSetManager: Task 0 in stage 5.0 failed 1 times; aborting job
25/02/06 16:32:18 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 16:32:18 ERROR Executor: Exception in task 0.0 in stage 6.0 (TID 5)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 473, in main
    raise Exception(("Python in worker has different version %s than that in " +
Exception: Python in worker has different version 3.8 than that in driver 3.9, PySpark cannot run with different minor versions. Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:517)
	at org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:84)
	at org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:67)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:470)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:489)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:345)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
25/02/06 16:32:18 WARN TaskSetManager: Lost task 0.0 in stage 6.0 (TID 5) (ip-172-31-13-81.ap-northeast-3.compute.internal executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 473, in main
    raise Exception(("Python in worker has different version %s than that in " +
Exception: Python in worker has different version 3.8 than that in driver 3.9, PySpark cannot run with different minor versions. Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:517)
	at org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:84)
	at org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:67)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:470)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:489)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:345)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

25/02/06 16:32:18 ERROR TaskSetManager: Task 0 in stage 6.0 failed 1 times; aborting job
25/02/06 16:32:36 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
25/02/06 16:32:36 ERROR Executor: Exception in task 0.0 in stage 7.0 (TID 6)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 473, in main
    raise Exception(("Python in worker has different version %s than that in " +
Exception: Python in worker has different version 3.8 than that in driver 3.9, PySpark cannot run with different minor versions. Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:517)
	at org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:84)
	at org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:67)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:470)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:489)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:345)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
25/02/06 16:32:36 WARN TaskSetManager: Lost task 0.0 in stage 7.0 (TID 6) (ip-172-31-13-81.ap-northeast-3.compute.internal executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 473, in main
    raise Exception(("Python in worker has different version %s than that in " +
Exception: Python in worker has different version 3.8 than that in driver 3.9, PySpark cannot run with different minor versions. Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:517)
	at org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:84)
	at org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:67)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:470)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:489)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:345)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

25/02/06 16:32:36 ERROR TaskSetManager: Task 0 in stage 7.0 failed 1 times; aborting job
[I 2025-02-06 16:33:12.056 ServerApp] Saving file at /YJ/analytics/read_mysql.ipynb
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
25/02/06 16:33:47 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /tmp/spark-51ac7da5-205f-4497-9a5e-21e936ff9b72. Falling back to Java IO way
java.io.IOException: Failed to delete: /tmp/spark-51ac7da5-205f-4497-9a5e-21e936ff9b72
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:171)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:110)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1141)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1996)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
25/02/06 16:33:47 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /tmp/spark-51ac7da5-205f-4497-9a5e-21e936ff9b72/pyspark-555718cc-11a5-4102-b8ee-1546fffe11d2. Falling back to Java IO way
java.io.IOException: Failed to delete: /tmp/spark-51ac7da5-205f-4497-9a5e-21e936ff9b72/pyspark-555718cc-11a5-4102-b8ee-1546fffe11d2
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:171)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:110)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1141)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1996)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
[I 2025-02-06 16:33:50.049 ServerApp] Kernel restarted: 40f07ade-5d1a-4a52-b472-4bd4bbd6abaa
[I 2025-02-06 16:33:50.076 ServerApp] Starting buffering for 40f07ade-5d1a-4a52-b472-4bd4bbd6abaa:5cd12b90-1af4-4e2c-a34e-269db9eea263
[I 2025-02-06 16:33:50.111 ServerApp] Connecting to kernel 40f07ade-5d1a-4a52-b472-4bd4bbd6abaa.
[I 2025-02-06 16:33:50.111 ServerApp] Restoring connection for 40f07ade-5d1a-4a52-b472-4bd4bbd6abaa:5cd12b90-1af4-4e2c-a34e-269db9eea263
[I 2025-02-06 16:33:57.167 ServerApp] Kernel started: ad968cad-5d07-4b93-8567-fd574ee12f8f
[I 2025-02-06 16:33:57.168 ServerApp] Kernel shutdown: 40f07ade-5d1a-4a52-b472-4bd4bbd6abaa
[I 2025-02-06 16:33:57.632 ServerApp] Connecting to kernel ad968cad-5d07-4b93-8567-fd574ee12f8f.
[I 2025-02-06 16:34:08.653 ServerApp] Kernel started: 5099063b-fc86-4c42-865b-2a19dacce825
[I 2025-02-06 16:34:08.654 ServerApp] Kernel shutdown: ad968cad-5d07-4b93-8567-fd574ee12f8f
[I 2025-02-06 16:34:09.080 ServerApp] Connecting to kernel 5099063b-fc86-4c42-865b-2a19dacce825.
[I 2025-02-06 16:34:31.758 ServerApp] Kernel started: b8a5d084-ae63-42e0-830a-31b265730581
[I 2025-02-06 16:34:31.759 ServerApp] Kernel shutdown: 5099063b-fc86-4c42-865b-2a19dacce825
[I 2025-02-06 16:34:32.194 ServerApp] Connecting to kernel b8a5d084-ae63-42e0-830a-31b265730581.
[I 2025-02-06 16:35:12.194 ServerApp] Saving file at /YJ/analytics/read_mysql.ipynb
[I 2025-02-06 16:36:28.915 ServerApp] Kernel restarted: b8a5d084-ae63-42e0-830a-31b265730581
[I 2025-02-06 16:36:28.949 ServerApp] Starting buffering for b8a5d084-ae63-42e0-830a-31b265730581:5cd12b90-1af4-4e2c-a34e-269db9eea263
[I 2025-02-06 16:36:28.983 ServerApp] Connecting to kernel b8a5d084-ae63-42e0-830a-31b265730581.
[I 2025-02-06 16:36:28.983 ServerApp] Restoring connection for b8a5d084-ae63-42e0-830a-31b265730581:5cd12b90-1af4-4e2c-a34e-269db9eea263
25/02/06 16:36:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:>                                                          (0 + 1) / 1][Stage 1:>                                                          (0 + 1) / 1]                                                                                25/02/06 16:36:50 WARN DAGScheduler: Broadcasting large task binary with size 3.3 MiB
[Stage 4:>                                                          (0 + 1) / 1]                                                                                [I 2025-02-06 16:37:12.355 ServerApp] Saving file at /YJ/analytics/read_mysql.ipynb
25/02/06 16:37:24 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB
[Stage 5:>                                                          (0 + 1) / 1][Stage 5:>                                                          (0 + 1) / 1][I 2025-02-06 16:39:12.518 ServerApp] Saving file at /YJ/analytics/read_mysql.ipynb
[Stage 5:>                                                          (0 + 1) / 1][Stage 5:>                                                          (0 + 1) / 1][Stage 5:>                                                          (0 + 1) / 1][Stage 5:>                                                          (0 + 1) / 1][Stage 5:>                                                          (0 + 1) / 1][Stage 5:>                                                          (0 + 1) / 1][Stage 5:>                                                          (0 + 1) / 1][Stage 5:>                                                          (0 + 1) / 1]                                                                                [I 2025-02-06 16:47:12.716 ServerApp] Saving file at /YJ/analytics/read_mysql.ipynb
[Stage 6:>                                                          (0 + 1) / 1][I 2025-02-06 16:49:12.901 ServerApp] Saving file at /YJ/analytics/read_mysql.ipynb
[Stage 6:>                                                          (0 + 1) / 1][Stage 6:>                                                          (0 + 1) / 1][Stage 6:>                                                          (0 + 1) / 1][Stage 6:>                                                          (0 + 1) / 1][Stage 6:>                                                          (0 + 1) / 1][Stage 6:>                                                          (0 + 1) / 1][Stage 6:>                                                          (0 + 1) / 1][Stage 6:>                                                          (0 + 1) / 1][Stage 6:>                                                          (0 + 1) / 1][Stage 6:>                                                          (0 + 1) / 1][Stage 6:>                                                          (0 + 1) / 1][Stage 6:>                                                          (0 + 1) / 1][Stage 6:>                                                          (0 + 1) / 1][I 2025-02-06 17:02:30.901 ServerApp] Saving file at /YJ/analytics/read_mysql.ipynb
[Stage 6:>                                                          (0 + 1) / 1][W 2025-02-06 17:03:42.726 ServerApp] Notebook YJ/Untitled.ipynb is not trusted
[Stage 6:>                                                          (0 + 1) / 1][I 2025-02-06 17:03:44.113 ServerApp] Connecting to kernel 54599486-28f9-4652-bdb2-a979ce71c285.
[I 2025-02-06 17:03:44.262 ServerApp] Connecting to kernel b8a5d084-ae63-42e0-830a-31b265730581.
[W 2025-02-06 17:03:44.339 ServerApp] Notebook YJ/Untitled.ipynb is not trusted
[I 2025-02-06 17:03:44.357 ServerApp] Connecting to kernel a9205a99-d47d-4d7f-b954-eb91ebd81499.
[I 2025-02-06 17:03:44.695 ServerApp] Kernel started: 33045868-4bb9-4453-944a-211674109b40
[E 2025-02-06 17:03:45.847 ServerApp] Uncaught exception GET /api/kernels/33045868-4bb9-4453-944a-211674109b40/channels?session_id=b072547f-c62f-4381-9066-e6019e4b6db8 (125.129.250.60)
    HTTPServerRequest(protocol='http', host='15.168.221.131:8917', method='GET', uri='/api/kernels/33045868-4bb9-4453-944a-211674109b40/channels?session_id=b072547f-c62f-4381-9066-e6019e4b6db8', version='HTTP/1.1', remote_ip='125.129.250.60')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_server/services/kernels/websocket.py", line 66, in get
        await super().get(kernel_id=kernel_id)
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/tornado/websocket.py", line 273, in get
        await self.ws_connection.accept_connection(self)
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/tornado/websocket.py", line 863, in accept_connection
        await self._accept_connection(handler)
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/tornado/websocket.py", line 903, in _accept_connection
        self.selected_subprotocol = handler.select_subprotocol(subprotocols)
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_server/services/kernels/websocket.py", line 88, in select_subprotocol
        preferred_protocol = self.connection.kernel_ws_protocol
    AttributeError: 'NoneType' object has no attribute 'kernel_ws_protocol'
[E 2025-02-06 17:03:45.860 ServerApp] {
      "Host": "15.168.221.131:8917",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/132.0.0.0 Safari/537.36"
    }
[E 2025-02-06 17:03:45.860 ServerApp] 500 GET /api/kernels/33045868-4bb9-4453-944a-211674109b40/channels?session_id=b072547f-c62f-4381-9066-e6019e4b6db8 (8c1b3224a2404a088fde4e8bb099b22e@125.129.250.60) 1025.87ms referer=None
[I 2025-02-06 17:03:47.954 ServerApp] Connecting to kernel 54599486-28f9-4652-bdb2-a979ce71c285.
[I 2025-02-06 17:03:48.070 ServerApp] Connecting to kernel b8a5d084-ae63-42e0-830a-31b265730581.
[I 2025-02-06 17:03:48.157 ServerApp] Connecting to kernel a9205a99-d47d-4d7f-b954-eb91ebd81499.
[I 2025-02-06 17:03:48.290 ServerApp] Connecting to kernel 33045868-4bb9-4453-944a-211674109b40.
[I 2025-02-06 17:03:48.470 ServerApp] Kernel started: 0025ef2a-00de-402f-a7b9-2400d9466c1e
[I 2025-02-06 17:03:49.300 ServerApp] Connecting to kernel 0025ef2a-00de-402f-a7b9-2400d9466c1e.
[I 2025-02-06 17:03:49.321 ServerApp] Starting buffering for 0025ef2a-00de-402f-a7b9-2400d9466c1e:3d4564f0-d480-4153-b752-3036d7a7ecdf
[I 2025-02-06 17:03:51.810 ServerApp] Connecting to kernel 54599486-28f9-4652-bdb2-a979ce71c285.
[I 2025-02-06 17:03:51.920 ServerApp] Connecting to kernel b8a5d084-ae63-42e0-830a-31b265730581.
[I 2025-02-06 17:03:52.017 ServerApp] Connecting to kernel a9205a99-d47d-4d7f-b954-eb91ebd81499.
[I 2025-02-06 17:03:52.116 ServerApp] Connecting to kernel 33045868-4bb9-4453-944a-211674109b40.
[I 2025-02-06 17:03:52.202 ServerApp] Connecting to kernel 0025ef2a-00de-402f-a7b9-2400d9466c1e.
[I 2025-02-06 17:03:52.202 ServerApp] Discarding 3 buffered messages for 0025ef2a-00de-402f-a7b9-2400d9466c1e:3d4564f0-d480-4153-b752-3036d7a7ecdf
[I 2025-02-06 17:03:52.320 ServerApp] Kernel started: 1d366c0a-a55c-4981-8557-becf905d2ff1
[I 2025-02-06 17:03:52.333 ServerApp] Starting buffering for 0025ef2a-00de-402f-a7b9-2400d9466c1e:316f190f-b070-46e0-b700-64ece6ad0e7a
[I 2025-02-06 17:03:53.306 ServerApp] Connecting to kernel 1d366c0a-a55c-4981-8557-becf905d2ff1.
[I 2025-02-06 17:03:53.387 ServerApp] Connecting to kernel 1d366c0a-a55c-4981-8557-becf905d2ff1.
[W 2025-02-06 17:03:53.406 ServerApp] Got events for closed stream <zmq.eventloop.zmqstream.ZMQStream object at 0x7f051b0c9460>
[I 2025-02-06 17:03:53.468 ServerApp] Connecting to kernel 1d366c0a-a55c-4981-8557-becf905d2ff1.
[I 2025-02-06 17:03:54.783 ServerApp] Connecting to kernel 1d366c0a-a55c-4981-8557-becf905d2ff1.
[I 2025-02-06 17:04:04.341 ServerApp] Starting buffering for 1d366c0a-a55c-4981-8557-becf905d2ff1:3f10431c-ee6c-436b-8251-e44de5b2e78e
[I 2025-02-06 17:04:04.402 ServerApp] Connecting to kernel 1d366c0a-a55c-4981-8557-becf905d2ff1.
[I 2025-02-06 17:04:04.480 ServerApp] Starting buffering for 1d366c0a-a55c-4981-8557-becf905d2ff1:b768b312-1d39-4b27-bea4-bc63e8a35658
[I 2025-02-06 17:04:06.096 ServerApp] Saving file at /YJ/analytics/read_mysql.ipynb
[Stage 6:>                                                          (0 + 1) / 1]                                                                                [I 2025-02-06 17:06:06.318 ServerApp] Saving file at /YJ/analytics/read_mysql.ipynb
[I 2025-02-06 17:08:06.561 ServerApp] Saving file at /YJ/analytics/read_mysql.ipynb
[Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][I 2025-02-06 17:10:06.809 ServerApp] Saving file at /YJ/analytics/read_mysql.ipynb
[Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][I 2025-02-06 17:14:07.084 ServerApp] Saving file at /YJ/analytics/read_mysql.ipynb
[Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][I 2025-02-06 17:18:07.302 ServerApp] Saving file at /YJ/analytics/read_mysql.ipynb
[Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][I 2025-02-06 17:20:07.522 ServerApp] Saving file at /YJ/analytics/read_mysql.ipynb
[Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][I 2025-02-06 17:34:07.723 ServerApp] Saving file at /YJ/analytics/read_mysql.ipynb
[Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][I 2025-02-06 18:35:39.452 ServerApp] Kernel interrupted: b8a5d084-ae63-42e0-830a-31b265730581
[I 2025-02-06 18:35:41.140 ServerApp] Saving file at /YJ/analytics/read_mysql.ipynb
[I 2025-02-06 18:35:42.673 ServerApp] Starting buffering for b8a5d084-ae63-42e0-830a-31b265730581:5cd12b90-1af4-4e2c-a34e-269db9eea263
[I 2025-02-06 18:35:42.687 ServerApp] Starting buffering for 54599486-28f9-4652-bdb2-a979ce71c285:31453074-9eb2-4d98-a4f9-7d1e175a1b67
[I 2025-02-06 18:35:42.708 ServerApp] Starting buffering for a9205a99-d47d-4d7f-b954-eb91ebd81499:9f507df1-ad31-42da-997a-71b4f46d9d1a
[Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1][Stage 7:>                                                          (0 + 1) / 1]                                                                                [C 2025-02-06 19:00:01.530 ServerApp] received signal 15, stopping
[I 2025-02-06 19:00:01.535 ServerApp] Shutting down 5 extensions
[I 2025-02-06 19:00:01.537 ServerApp] AsyncIOLoopKernelRestarter: restarting kernel (1/5), keep random ports
[I 2025-02-06 19:00:01.540 ServerApp] Shutting down 6 kernels
[I 2025-02-06 19:00:01.553 ServerApp] Discarding 18 buffered messages for b8a5d084-ae63-42e0-830a-31b265730581:5cd12b90-1af4-4e2c-a34e-269db9eea263
[I 2025-02-06 19:00:01.576 ServerApp] Kernel shutdown: b8a5d084-ae63-42e0-830a-31b265730581
[I 2025-02-06 19:00:01.577 ServerApp] Kernel shutdown: 54599486-28f9-4652-bdb2-a979ce71c285
[I 2025-02-06 19:00:01.577 ServerApp] Kernel shutdown: a9205a99-d47d-4d7f-b954-eb91ebd81499
[I 2025-02-06 19:00:01.577 ServerApp] Kernel shutdown: 1d366c0a-a55c-4981-8557-becf905d2ff1
[I 2025-02-06 19:00:01.578 ServerApp] Kernel shutdown: 0025ef2a-00de-402f-a7b9-2400d9466c1e
[I 2025-02-06 19:00:01.578 ServerApp] Kernel shutdown: 33045868-4bb9-4453-944a-211674109b40
[E 2025-02-06 19:00:01.619 ServerApp] Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f051c69b130>>, <Task finished name='Task-140886' coro=<ServerApp._stop() done, defined at /home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_server/serverapp.py:3123> exception=InvalidStateError('Exception is not set.')>)
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/tornado/ioloop.py", line 750, in _run_callback
        ret = callback()
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/tornado/ioloop.py", line 774, in _discard_future_result
        future.result()
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_server/serverapp.py", line 3125, in _stop
        await self._cleanup()
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_server/serverapp.py", line 3077, in _cleanup
        await self.cleanup_kernels()
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_server/serverapp.py", line 2778, in cleanup_kernels
        await ensure_async(self.kernel_manager.shutdown_all())
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_core/utils/__init__.py", line 198, in ensure_async
        result = await obj
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_client/multikernelmanager.py", line 370, in _async_shutdown_all
        await asyncio.gather(*futs)
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_server/services/kernels/kernelmanager.py", line 436, in _async_shutdown_kernel
        return await self.pinned_superclass._async_shutdown_kernel(
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_client/multikernelmanager.py", line 321, in _async_shutdown_kernel
        if not km.ready.cancelled() and km.ready.exception():
    asyncio.exceptions.InvalidStateError: Exception is not set.
[C 2025-02-07 09:11:32.381 ServerApp] Bad config encountered during initialization: The 'port' trait of a ServerApp instance expected an int, not the str '=8917'.
[I 2025-02-07 09:12:03.774 ServerApp] jupyter_lsp | extension was successfully linked.
[I 2025-02-07 09:12:03.778 ServerApp] jupyter_server_terminals | extension was successfully linked.
[I 2025-02-07 09:12:03.783 ServerApp] jupyterlab | extension was successfully linked.
[W 2025-02-07 09:12:03.786 JupyterNotebookApp] 'password' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-07 09:12:03.789 ServerApp] ServerApp.password config is deprecated in 2.0. Use PasswordIdentityProvider.hashed_password.
[I 2025-02-07 09:12:03.789 ServerApp] notebook | extension was successfully linked.
[I 2025-02-07 09:12:04.333 ServerApp] notebook_shim | extension was successfully linked.
[I 2025-02-07 09:12:04.436 ServerApp] notebook_shim | extension was successfully loaded.
[I 2025-02-07 09:12:04.438 ServerApp] jupyter_lsp | extension was successfully loaded.
[I 2025-02-07 09:12:04.439 ServerApp] jupyter_server_terminals | extension was successfully loaded.
[I 2025-02-07 09:12:04.456 LabApp] JupyterLab extension loaded from /home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyterlab
[I 2025-02-07 09:12:04.456 LabApp] JupyterLab application directory is /home/ubuntu/anaconda3/envs/Project/share/jupyter/lab
[I 2025-02-07 09:12:04.457 LabApp] Extension Manager is 'pypi'.
[I 2025-02-07 09:12:04.515 ServerApp] jupyterlab | extension was successfully loaded.
[I 2025-02-07 09:12:04.519 ServerApp] notebook | extension was successfully loaded.
[I 2025-02-07 09:12:04.519 ServerApp] Serving notebooks from local directory: /home/lab13/project
[I 2025-02-07 09:12:04.519 ServerApp] Jupyter Server 2.14.2 is running at:
[I 2025-02-07 09:12:04.519 ServerApp] http://ip-172-31-13-81:8917/tree
[I 2025-02-07 09:12:04.519 ServerApp]     http://127.0.0.1:8917/tree
[I 2025-02-07 09:12:04.519 ServerApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[I 2025-02-07 09:12:04.540 ServerApp] Skipped non-installed server(s): bash-language-server, dockerfile-language-server-nodejs, javascript-typescript-langserver, jedi-language-server, julia-language-server, pyright, python-language-server, python-lsp-server, r-languageserver, sql-language-server, texlab, typescript-language-server, unified-language-server, vscode-css-languageserver-bin, vscode-html-languageserver-bin, vscode-json-languageserver-bin, yaml-language-server
[I 2025-02-07 09:12:08.837 ServerApp] 302 GET / (@125.129.250.60) 0.52ms
[I 2025-02-07 09:12:08.870 JupyterNotebookApp] 302 GET /tree? (@125.129.250.60) 0.68ms
[I 2025-02-07 09:12:13.091 ServerApp] User b7117d130c0f4d4fadf10f88825a6616 logged in.
[I 2025-02-07 09:12:13.092 ServerApp] 302 POST /login?next=%2Ftree%3F (b7117d130c0f4d4fadf10f88825a6616@125.129.250.60) 57.68ms
[I 2025-02-07 09:13:12.287 ServerApp] Kernel started: 91762c4a-b023-4109-a1ed-a4e15c2dcdf8
[I 2025-02-07 09:13:13.585 ServerApp] Connecting to kernel 91762c4a-b023-4109-a1ed-a4e15c2dcdf8.
[I 2025-02-07 09:13:13.660 ServerApp] Connecting to kernel 91762c4a-b023-4109-a1ed-a4e15c2dcdf8.
[I 2025-02-07 09:13:13.728 ServerApp] Connecting to kernel 91762c4a-b023-4109-a1ed-a4e15c2dcdf8.
[I 2025-02-07 09:13:15.634 ServerApp] Connecting to kernel 91762c4a-b023-4109-a1ed-a4e15c2dcdf8.
[I 2025-02-07 09:13:19.659 ServerApp] Kernel started: e81baf26-c1c0-477a-bca8-88d78217683f
[I 2025-02-07 09:13:19.660 ServerApp] Kernel shutdown: 91762c4a-b023-4109-a1ed-a4e15c2dcdf8
[I 2025-02-07 09:13:20.151 ServerApp] Connecting to kernel e81baf26-c1c0-477a-bca8-88d78217683f.
25/02/07 09:13:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[I 2025-02-07 09:15:12.065 ServerApp] Saving file at /YJ/analytics/read_mysql.ipynb
[I 2025-02-07 09:25:14.679 ServerApp] Saving file at /YJ/analytics/read_mysql.ipynb
[I 2025-02-07 09:27:14.904 ServerApp] Saving file at /YJ/analytics/read_mysql.ipynb
[Stage 0:>                                                          (0 + 1) / 1][I 2025-02-07 09:29:15.066 ServerApp] Saving file at /YJ/analytics/read_mysql.ipynb
[Stage 0:>                                                          (0 + 1) / 1][Stage 0:>                                                          (0 + 1) / 1]                                                                                [I 2025-02-07 09:31:15.272 ServerApp] Saving file at /YJ/analytics/read_mysql.ipynb
[IPKernelApp] WARNING | Invalid Message:
Traceback (most recent call last):
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/ipykernel/kernelbase.py", line 1317, in _input_request
    rlist, _, xlist = zmq.select([self.stdin_socket], [], [self.stdin_socket], 0.01)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/zmq/sugar/poll.py", line 156, in select
    return_sockets = zmq_poll(sockets, timeout)
  File "_zmq.py", line 1576, in zmq.backend.cython._zmq.zmq_poll
  File "_zmq.py", line 1555, in zmq.backend.cython._zmq.zmq_poll
  File "_zmq.py", line 160, in zmq.backend.cython._zmq._check_rc
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/transformers/dynamic_module_utils.py", line 633, in _raise_timeout_error
    raise ValueError(
ValueError: Loading this model requires you to execute custom code contained in the model repository on your local machine. Please set the option `trust_remote_code=True` to permit loading of this model.
[I 2025-02-07 09:33:15.439 ServerApp] Saving file at /YJ/analytics/read_mysql.ipynb
[I 2025-02-07 09:38:20.151 ServerApp] Saving file at /YJ/analytics/read_mysql.ipynb
[I 2025-02-07 09:38:27.680 ServerApp] Connecting to kernel e81baf26-c1c0-477a-bca8-88d78217683f.
[I 2025-02-07 09:38:31.560 ServerApp] Creating new notebook in /YJ/dags
[I 2025-02-07 09:38:31.719 ServerApp] Saving file at /YJ/dags/Untitled.ipynb
[I 2025-02-07 09:38:31.784 ServerApp] Kernel started: a6a4c679-fbb7-4dca-bc49-7679b4ed8ce4
[I 2025-02-07 09:38:32.405 ServerApp] Connecting to kernel a6a4c679-fbb7-4dca-bc49-7679b4ed8ce4.
[I 2025-02-07 09:38:32.531 ServerApp] Connecting to kernel a6a4c679-fbb7-4dca-bc49-7679b4ed8ce4.
[I 2025-02-07 09:38:33.122 ServerApp] Connecting to kernel e81baf26-c1c0-477a-bca8-88d78217683f.
[I 2025-02-07 09:38:33.217 ServerApp] Connecting to kernel a6a4c679-fbb7-4dca-bc49-7679b4ed8ce4.
[I 2025-02-07 09:38:33.446 ServerApp] Connecting to kernel a6a4c679-fbb7-4dca-bc49-7679b4ed8ce4.
[I 2025-02-07 09:38:40.930 ServerApp] Kernel started: 3778f05b-f0aa-4031-8177-e401d3378f17
[I 2025-02-07 09:38:40.931 ServerApp] Kernel shutdown: a6a4c679-fbb7-4dca-bc49-7679b4ed8ce4
[I 2025-02-07 09:38:41.857 ServerApp] Connecting to kernel 3778f05b-f0aa-4031-8177-e401d3378f17.
[I 2025-02-07 09:38:41.931 ServerApp] Connecting to kernel 3778f05b-f0aa-4031-8177-e401d3378f17.
[I 2025-02-07 09:38:50.619 ServerApp] Connecting to kernel e81baf26-c1c0-477a-bca8-88d78217683f.
[I 2025-02-07 09:38:50.689 ServerApp] Connecting to kernel 3778f05b-f0aa-4031-8177-e401d3378f17.
[I 2025-02-07 09:39:00.584 ServerApp] Connecting to kernel 3778f05b-f0aa-4031-8177-e401d3378f17.
[I 2025-02-07 09:39:15.644 ServerApp] Saving file at /YJ/analytics/read_mysql.ipynb
[I 2025-02-07 09:40:33.575 ServerApp] Saving file at /YJ/dags/Untitled.ipynb
[I 2025-02-07 09:41:16.593 ServerApp] Saving file at /YJ/analytics/read_mysql.ipynb
[I 2025-02-07 09:42:33.698 ServerApp] Saving file at /YJ/dags/Untitled.ipynb
[I 2025-02-07 09:48:33.816 ServerApp] Saving file at /YJ/dags/Untitled.ipynb
[I 2025-02-07 09:50:33.924 ServerApp] Saving file at /YJ/dags/Untitled.ipynb
[I 2025-02-07 10:04:29.965 ServerApp] Saving file at /YJ/dags/Untitled.ipynb
[I 2025-02-07 10:36:52.288 ServerApp] Connecting to kernel 3778f05b-f0aa-4031-8177-e401d3378f17.
[I 2025-02-07 10:36:52.365 ServerApp] Connecting to kernel 3778f05b-f0aa-4031-8177-e401d3378f17.
[I 2025-02-07 11:28:01.607 ServerApp] Connecting to kernel e81baf26-c1c0-477a-bca8-88d78217683f.
[I 2025-02-07 11:28:01.670 ServerApp] Connecting to kernel 3778f05b-f0aa-4031-8177-e401d3378f17.
[I 2025-02-07 11:28:06.805 ServerApp] Connecting to kernel e81baf26-c1c0-477a-bca8-88d78217683f.
[I 2025-02-07 11:28:06.874 ServerApp] Connecting to kernel 3778f05b-f0aa-4031-8177-e401d3378f17.
[I 2025-02-07 11:29:39.159 ServerApp] Saving file at /YJ/15_final_project_crawling/test.py
[I 2025-02-07 11:31:04.111 ServerApp] Connecting to kernel e81baf26-c1c0-477a-bca8-88d78217683f.
[I 2025-02-07 11:31:04.180 ServerApp] Connecting to kernel 3778f05b-f0aa-4031-8177-e401d3378f17.
[I 2025-02-07 11:31:09.584 ServerApp] Saving file at /YJ/15_final_project_crawling/danawa_crawling.py
[I 2025-02-07 13:46:59.636 ServerApp] Saving file at /YJ/15_final_project_crawling/danawa_crawling.py
[I 2025-02-07 13:47:10.836 ServerApp] Uploading file to /YJ/15_final_project_crawling/danawa_review_S24+1.parquet
[I 2025-02-07 13:47:15.905 ServerApp] Connecting to kernel e81baf26-c1c0-477a-bca8-88d78217683f.
[I 2025-02-07 13:47:15.971 ServerApp] Connecting to kernel 3778f05b-f0aa-4031-8177-e401d3378f17.
[W 2025-02-07 13:47:21.114 ServerApp] Notebook YJ/15_final_project_crawling/test.ipynb is not trusted
[I 2025-02-07 13:47:21.701 ServerApp] Connecting to kernel e81baf26-c1c0-477a-bca8-88d78217683f.
[I 2025-02-07 13:47:21.805 ServerApp] Connecting to kernel 3778f05b-f0aa-4031-8177-e401d3378f17.
[W 2025-02-07 13:47:21.860 ServerApp] Notebook YJ/15_final_project_crawling/test.ipynb is not trusted
[I 2025-02-07 13:47:22.436 ServerApp] Kernel started: 081410ba-55e9-4769-86c3-b2f3d2f46fdd
[I 2025-02-07 13:47:22.914 ServerApp] Connecting to kernel 081410ba-55e9-4769-86c3-b2f3d2f46fdd.
[I 2025-02-07 13:47:22.999 ServerApp] Connecting to kernel 081410ba-55e9-4769-86c3-b2f3d2f46fdd.
[I 2025-02-07 13:47:23.067 ServerApp] Connecting to kernel 081410ba-55e9-4769-86c3-b2f3d2f46fdd.
[I 2025-02-07 13:47:24.247 ServerApp] Starting buffering for 081410ba-55e9-4769-86c3-b2f3d2f46fdd:f449b0e1-0a40-4387-a0bd-b1d89ad6d290
[I 2025-02-07 13:47:26.289 ServerApp] Connecting to kernel 081410ba-55e9-4769-86c3-b2f3d2f46fdd.
[I 2025-02-07 13:47:26.384 ServerApp] Starting buffering for 081410ba-55e9-4769-86c3-b2f3d2f46fdd:eb8e940b-f3f8-4f97-a95e-5c3f846434ae
[I 2025-02-07 13:47:26.431 ServerApp] Starting buffering for e81baf26-c1c0-477a-bca8-88d78217683f:eead2e71-b8f6-46b2-a2bf-253a63e8ec00
[I 2025-02-07 13:47:29.556 ServerApp] Creating new notebook in /YJ/15_final_project_crawling
[I 2025-02-07 13:47:29.728 ServerApp] Saving file at /YJ/15_final_project_crawling/Untitled.ipynb
[I 2025-02-07 13:47:29.796 ServerApp] Kernel started: 1cd16dca-c743-4616-9dec-4f9376f23e33
[I 2025-02-07 13:47:30.278 ServerApp] Connecting to kernel 1cd16dca-c743-4616-9dec-4f9376f23e33.
[I 2025-02-07 13:47:30.396 ServerApp] Connecting to kernel 1cd16dca-c743-4616-9dec-4f9376f23e33.
[I 2025-02-07 13:47:31.165 ServerApp] Connecting to kernel e81baf26-c1c0-477a-bca8-88d78217683f.
[I 2025-02-07 13:47:31.279 ServerApp] Connecting to kernel 3778f05b-f0aa-4031-8177-e401d3378f17.
[I 2025-02-07 13:47:31.350 ServerApp] Connecting to kernel 081410ba-55e9-4769-86c3-b2f3d2f46fdd.
[I 2025-02-07 13:47:31.433 ServerApp] Connecting to kernel 1cd16dca-c743-4616-9dec-4f9376f23e33.
[I 2025-02-07 13:47:31.444 ServerApp] Starting buffering for e81baf26-c1c0-477a-bca8-88d78217683f:d5d73791-ae3c-40b8-9a83-02b6209be51e
[I 2025-02-07 13:47:31.524 ServerApp] Starting buffering for 081410ba-55e9-4769-86c3-b2f3d2f46fdd:5a59da29-1b20-4222-b07d-52cfb39f2317
[I 2025-02-07 13:47:31.554 ServerApp] Connecting to kernel 1cd16dca-c743-4616-9dec-4f9376f23e33.
[I 2025-02-07 13:49:32.256 ServerApp] Saving file at /YJ/15_final_project_crawling/Untitled.ipynb
[I 2025-02-07 14:25:46.620 ServerApp] Connecting to kernel e81baf26-c1c0-477a-bca8-88d78217683f.
[I 2025-02-07 14:25:46.757 ServerApp] Connecting to kernel 3778f05b-f0aa-4031-8177-e401d3378f17.
[I 2025-02-07 14:25:46.828 ServerApp] Connecting to kernel 081410ba-55e9-4769-86c3-b2f3d2f46fdd.
[I 2025-02-07 14:25:46.895 ServerApp] Connecting to kernel 1cd16dca-c743-4616-9dec-4f9376f23e33.
[I 2025-02-07 14:25:46.910 ServerApp] Starting buffering for e81baf26-c1c0-477a-bca8-88d78217683f:30d19a9e-e248-4c65-8777-5ceb6e24e939
[I 2025-02-07 14:25:47.007 ServerApp] Starting buffering for 081410ba-55e9-4769-86c3-b2f3d2f46fdd:64b0c9af-4a6f-40a0-9321-e2057132948e
[I 2025-02-07 14:26:16.510 ServerApp] Connecting to kernel e81baf26-c1c0-477a-bca8-88d78217683f.
[I 2025-02-07 14:26:16.628 ServerApp] Connecting to kernel 3778f05b-f0aa-4031-8177-e401d3378f17.
[I 2025-02-07 14:26:16.707 ServerApp] Connecting to kernel 081410ba-55e9-4769-86c3-b2f3d2f46fdd.
[I 2025-02-07 14:26:16.778 ServerApp] Connecting to kernel 1cd16dca-c743-4616-9dec-4f9376f23e33.
[I 2025-02-07 14:26:16.819 ServerApp] Starting buffering for e81baf26-c1c0-477a-bca8-88d78217683f:9d816bf2-c468-4e56-b230-118b7fdf79b1
[I 2025-02-07 14:26:16.887 ServerApp] Starting buffering for 081410ba-55e9-4769-86c3-b2f3d2f46fdd:21670725-1dd0-4568-9eaa-90bf5905f18e
[I 2025-02-07 14:26:16.928 ServerApp] Kernel started: 30a13a1a-7fd3-49c9-a654-3cc1e85e8eb3
[I 2025-02-07 14:26:17.525 ServerApp] Connecting to kernel 30a13a1a-7fd3-49c9-a654-3cc1e85e8eb3.
[I 2025-02-07 14:26:17.816 ServerApp] Starting buffering for 30a13a1a-7fd3-49c9-a654-3cc1e85e8eb3:675da29b-2121-4cc9-ab6b-f2e180a73580
[I 2025-02-07 14:26:22.977 ServerApp] Connecting to kernel e81baf26-c1c0-477a-bca8-88d78217683f.
[I 2025-02-07 14:26:23.048 ServerApp] Connecting to kernel 3778f05b-f0aa-4031-8177-e401d3378f17.
[I 2025-02-07 14:26:23.155 ServerApp] Connecting to kernel 081410ba-55e9-4769-86c3-b2f3d2f46fdd.
[I 2025-02-07 14:26:23.234 ServerApp] Connecting to kernel 1cd16dca-c743-4616-9dec-4f9376f23e33.
[I 2025-02-07 14:26:23.269 ServerApp] Starting buffering for e81baf26-c1c0-477a-bca8-88d78217683f:fa71a6d9-ccf1-42b4-a2e9-47fcda38adb5
[I 2025-02-07 14:26:23.306 ServerApp] Connecting to kernel 30a13a1a-7fd3-49c9-a654-3cc1e85e8eb3.
[I 2025-02-07 14:26:23.436 ServerApp] Starting buffering for 081410ba-55e9-4769-86c3-b2f3d2f46fdd:3f15d882-1325-48f1-813a-d54ac4432ed3
[I 2025-02-07 14:26:23.499 ServerApp] Starting buffering for 30a13a1a-7fd3-49c9-a654-3cc1e85e8eb3:c6823187-5e43-411a-ab83-da67551f6363
[I 2025-02-07 14:26:23.499 ServerApp] Kernel started: 6c68b07b-8670-4aac-96eb-b4f79164503a
[I 2025-02-07 14:26:24.078 ServerApp] Connecting to kernel 6c68b07b-8670-4aac-96eb-b4f79164503a.
[I 2025-02-07 14:30:52.920 ServerApp] Connecting to kernel e81baf26-c1c0-477a-bca8-88d78217683f.
[I 2025-02-07 14:30:53.003 ServerApp] Connecting to kernel 3778f05b-f0aa-4031-8177-e401d3378f17.
[I 2025-02-07 14:30:53.072 ServerApp] Connecting to kernel 081410ba-55e9-4769-86c3-b2f3d2f46fdd.
[I 2025-02-07 14:30:53.147 ServerApp] Connecting to kernel 1cd16dca-c743-4616-9dec-4f9376f23e33.
[I 2025-02-07 14:30:53.149 ServerApp] Starting buffering for e81baf26-c1c0-477a-bca8-88d78217683f:787d382b-ff15-4f16-b27e-d0723b6203bd
[I 2025-02-07 14:30:53.181 ServerApp] Starting buffering for 081410ba-55e9-4769-86c3-b2f3d2f46fdd:c0662807-0936-443c-84c9-885a6215a70d
[I 2025-02-07 14:30:53.214 ServerApp] Connecting to kernel 30a13a1a-7fd3-49c9-a654-3cc1e85e8eb3.
[I 2025-02-07 14:30:53.283 ServerApp] Connecting to kernel 6c68b07b-8670-4aac-96eb-b4f79164503a.
[I 2025-02-07 14:30:53.306 ServerApp] Starting buffering for 30a13a1a-7fd3-49c9-a654-3cc1e85e8eb3:00892d62-986f-454c-8e0f-52e65d5a4ab7
[I 2025-02-07 14:31:02.575 ServerApp] Creating new notebook in /YJ
[I 2025-02-07 14:31:02.745 ServerApp] Saving file at /YJ/Untitled4.ipynb
[I 2025-02-07 14:31:02.811 ServerApp] Kernel started: 221c45b8-9f73-43f7-8b47-a93e74608977
[I 2025-02-07 14:31:03.881 ServerApp] Connecting to kernel 221c45b8-9f73-43f7-8b47-a93e74608977.
[I 2025-02-07 14:31:04.067 ServerApp] Connecting to kernel 221c45b8-9f73-43f7-8b47-a93e74608977.
[I 2025-02-07 14:31:04.263 ServerApp] Connecting to kernel e81baf26-c1c0-477a-bca8-88d78217683f.
[I 2025-02-07 14:31:04.338 ServerApp] Connecting to kernel 3778f05b-f0aa-4031-8177-e401d3378f17.
[I 2025-02-07 14:31:04.408 ServerApp] Connecting to kernel 081410ba-55e9-4769-86c3-b2f3d2f46fdd.
[I 2025-02-07 14:31:04.411 ServerApp] Starting buffering for e81baf26-c1c0-477a-bca8-88d78217683f:6aa962de-db09-4025-9575-06957cd4af86
[I 2025-02-07 14:31:04.479 ServerApp] Connecting to kernel 1cd16dca-c743-4616-9dec-4f9376f23e33.
[I 2025-02-07 14:31:04.513 ServerApp] Starting buffering for 081410ba-55e9-4769-86c3-b2f3d2f46fdd:58fe2856-d8cb-4935-90f2-6109fff081d2
[I 2025-02-07 14:31:04.543 ServerApp] Connecting to kernel 30a13a1a-7fd3-49c9-a654-3cc1e85e8eb3.
[I 2025-02-07 14:31:04.606 ServerApp] Connecting to kernel 6c68b07b-8670-4aac-96eb-b4f79164503a.
[I 2025-02-07 14:31:04.619 ServerApp] Starting buffering for 30a13a1a-7fd3-49c9-a654-3cc1e85e8eb3:c92e63b2-dcf6-4ab2-aa37-99d24c030f69
[I 2025-02-07 14:31:04.670 ServerApp] Connecting to kernel 221c45b8-9f73-43f7-8b47-a93e74608977.
[I 2025-02-07 14:31:04.733 ServerApp] Connecting to kernel 221c45b8-9f73-43f7-8b47-a93e74608977.
[I 2025-02-07 14:31:04.801 ServerApp] Connecting to kernel 221c45b8-9f73-43f7-8b47-a93e74608977.
[I 2025-02-07 14:33:04.345 ServerApp] Saving file at /YJ/Untitled4.ipynb
[I 2025-02-07 14:34:03.731 ServerApp] Creating new file in /YJ
[I 2025-02-07 14:34:10.470 ServerApp] Connecting to kernel e81baf26-c1c0-477a-bca8-88d78217683f.
[I 2025-02-07 14:34:10.533 ServerApp] Connecting to kernel 3778f05b-f0aa-4031-8177-e401d3378f17.
[I 2025-02-07 14:34:10.625 ServerApp] Connecting to kernel 081410ba-55e9-4769-86c3-b2f3d2f46fdd.
[I 2025-02-07 14:34:10.686 ServerApp] Connecting to kernel 1cd16dca-c743-4616-9dec-4f9376f23e33.
[I 2025-02-07 14:34:10.752 ServerApp] Connecting to kernel 30a13a1a-7fd3-49c9-a654-3cc1e85e8eb3.
[I 2025-02-07 14:34:10.798 ServerApp] Starting buffering for e81baf26-c1c0-477a-bca8-88d78217683f:17c31c8f-0ab0-47c1-a0c5-b78f5ef8699b
[I 2025-02-07 14:34:10.804 ServerApp] Starting buffering for 081410ba-55e9-4769-86c3-b2f3d2f46fdd:c8a7c303-016a-40c6-b959-0180b86cc68a
[I 2025-02-07 14:34:10.824 ServerApp] Connecting to kernel 6c68b07b-8670-4aac-96eb-b4f79164503a.
[I 2025-02-07 14:34:10.908 ServerApp] Connecting to kernel 221c45b8-9f73-43f7-8b47-a93e74608977.
[I 2025-02-07 14:34:10.926 ServerApp] Starting buffering for 30a13a1a-7fd3-49c9-a654-3cc1e85e8eb3:05eda41e-e827-45fb-bc85-e5d9f4a50e29
[I 2025-02-07 14:34:10.977 ServerApp] Connecting to kernel 221c45b8-9f73-43f7-8b47-a93e74608977.
[I 2025-02-07 14:34:14.903 ServerApp] Connecting to kernel e81baf26-c1c0-477a-bca8-88d78217683f.
[I 2025-02-07 14:34:14.976 ServerApp] Connecting to kernel 3778f05b-f0aa-4031-8177-e401d3378f17.
[I 2025-02-07 14:34:15.038 ServerApp] Connecting to kernel 081410ba-55e9-4769-86c3-b2f3d2f46fdd.
[I 2025-02-07 14:34:15.064 ServerApp] Starting buffering for e81baf26-c1c0-477a-bca8-88d78217683f:83d5916d-969b-4e85-8f77-764be15508a5
[I 2025-02-07 14:34:15.111 ServerApp] Connecting to kernel 1cd16dca-c743-4616-9dec-4f9376f23e33.
[I 2025-02-07 14:34:15.132 ServerApp] Starting buffering for 081410ba-55e9-4769-86c3-b2f3d2f46fdd:a6642249-8e91-4424-bb9a-94f5083bdf0d
[I 2025-02-07 14:34:15.175 ServerApp] Connecting to kernel 30a13a1a-7fd3-49c9-a654-3cc1e85e8eb3.
[I 2025-02-07 14:34:15.247 ServerApp] Connecting to kernel 221c45b8-9f73-43f7-8b47-a93e74608977.
[I 2025-02-07 14:34:15.250 ServerApp] Starting buffering for 30a13a1a-7fd3-49c9-a654-3cc1e85e8eb3:e69b55a5-dc81-47cf-bb9c-4edc7a74d8cb
[I 2025-02-07 14:34:15.320 ServerApp] Connecting to kernel 6c68b07b-8670-4aac-96eb-b4f79164503a.
[I 2025-02-07 14:34:16.165 ServerApp] Saving file at /YJ/testtest.py
[I 2025-02-07 14:34:44.867 ServerApp] Connecting to kernel 221c45b8-9f73-43f7-8b47-a93e74608977.
[I 2025-02-07 14:34:46.791 ServerApp] Starting buffering for 6c68b07b-8670-4aac-96eb-b4f79164503a:74b46f5e-b383-4c3c-9bde-d6deb330c69b
[I 2025-02-07 14:34:46.866 ServerApp] Connecting to kernel 221c45b8-9f73-43f7-8b47-a93e74608977.
[I 2025-02-07 14:34:55.780 ServerApp] Connecting to kernel e81baf26-c1c0-477a-bca8-88d78217683f.
[I 2025-02-07 14:34:55.886 ServerApp] Connecting to kernel 3778f05b-f0aa-4031-8177-e401d3378f17.
[I 2025-02-07 14:34:55.955 ServerApp] Connecting to kernel 081410ba-55e9-4769-86c3-b2f3d2f46fdd.
[I 2025-02-07 14:34:56.022 ServerApp] Connecting to kernel 1cd16dca-c743-4616-9dec-4f9376f23e33.
[I 2025-02-07 14:34:56.063 ServerApp] Starting buffering for e81baf26-c1c0-477a-bca8-88d78217683f:12d8fb17-6fb8-416b-8ed8-046aa5d50421
[I 2025-02-07 14:34:56.094 ServerApp] Connecting to kernel 30a13a1a-7fd3-49c9-a654-3cc1e85e8eb3.
[I 2025-02-07 14:34:56.104 ServerApp] Starting buffering for 081410ba-55e9-4769-86c3-b2f3d2f46fdd:9006d9b2-4f41-4f72-b735-bc05109c0129
[I 2025-02-07 14:34:56.154 ServerApp] Kernel started: 4c11896e-fd61-4d30-8ff9-750bc7a5e75e
[I 2025-02-07 14:34:56.166 ServerApp] Connecting to kernel 221c45b8-9f73-43f7-8b47-a93e74608977.
[I 2025-02-07 14:34:56.192 ServerApp] Starting buffering for 30a13a1a-7fd3-49c9-a654-3cc1e85e8eb3:d5750a9d-3df6-467d-bb84-2d0b5c4fef72
[I 2025-02-07 14:34:56.239 ServerApp] Connecting to kernel 6c68b07b-8670-4aac-96eb-b4f79164503a.
[I 2025-02-07 14:34:56.329 ServerApp] Starting buffering for 6c68b07b-8670-4aac-96eb-b4f79164503a:c80c914e-e4ac-49c4-9aed-8af09df8c730
[I 2025-02-07 14:34:56.648 ServerApp] Connecting to kernel 4c11896e-fd61-4d30-8ff9-750bc7a5e75e.
[I 2025-02-07 14:34:56.743 ServerApp] Starting buffering for 4c11896e-fd61-4d30-8ff9-750bc7a5e75e:096f0353-003e-4d24-9f27-8113213b4ee7
[W 2025-02-07 14:34:57.522 ServerApp] Notebook YJ/Untitled.ipynb is not trusted
[I 2025-02-07 14:34:58.855 ServerApp] Connecting to kernel e81baf26-c1c0-477a-bca8-88d78217683f.
[I 2025-02-07 14:34:58.959 ServerApp] Connecting to kernel 3778f05b-f0aa-4031-8177-e401d3378f17.
[W 2025-02-07 14:34:58.989 ServerApp] Notebook YJ/Untitled.ipynb is not trusted
[I 2025-02-07 14:34:59.031 ServerApp] Connecting to kernel 081410ba-55e9-4769-86c3-b2f3d2f46fdd.
[I 2025-02-07 14:34:59.100 ServerApp] Connecting to kernel 1cd16dca-c743-4616-9dec-4f9376f23e33.
[I 2025-02-07 14:34:59.102 ServerApp] Starting buffering for e81baf26-c1c0-477a-bca8-88d78217683f:0a49b73a-291b-45e3-a6f6-5dc44ed38b69
[I 2025-02-07 14:34:59.171 ServerApp] Connecting to kernel 30a13a1a-7fd3-49c9-a654-3cc1e85e8eb3.
[I 2025-02-07 14:34:59.229 ServerApp] Starting buffering for 081410ba-55e9-4769-86c3-b2f3d2f46fdd:f1897b4e-2bc6-4a84-afe2-018d138c9c8c
[I 2025-02-07 14:34:59.254 ServerApp] Connecting to kernel 6c68b07b-8670-4aac-96eb-b4f79164503a.
[I 2025-02-07 14:34:59.298 ServerApp] Kernel started: f7098582-a20c-41ea-be2e-8e96294dcba5
[I 2025-02-07 14:34:59.303 ServerApp] Starting buffering for 30a13a1a-7fd3-49c9-a654-3cc1e85e8eb3:894751b5-8046-46b9-8c5b-b4e9ed6ea1de
[I 2025-02-07 14:34:59.332 ServerApp] Connecting to kernel 221c45b8-9f73-43f7-8b47-a93e74608977.
[I 2025-02-07 14:34:59.347 ServerApp] Starting buffering for 6c68b07b-8670-4aac-96eb-b4f79164503a:74a25275-0c72-4125-a14f-4d30b54e7f9e
[I 2025-02-07 14:34:59.410 ServerApp] Connecting to kernel 4c11896e-fd61-4d30-8ff9-750bc7a5e75e.
[I 2025-02-07 14:34:59.411 ServerApp] Discarding 11 buffered messages for 4c11896e-fd61-4d30-8ff9-750bc7a5e75e:096f0353-003e-4d24-9f27-8113213b4ee7
[I 2025-02-07 14:34:59.511 ServerApp] Starting buffering for 4c11896e-fd61-4d30-8ff9-750bc7a5e75e:74dce1b4-44ee-4da1-8c70-758f7d7f0a43
[I 2025-02-07 14:34:59.796 ServerApp] Connecting to kernel f7098582-a20c-41ea-be2e-8e96294dcba5.
[I 2025-02-07 14:35:01.499 ServerApp] Starting buffering for f7098582-a20c-41ea-be2e-8e96294dcba5:9274f8d6-3d34-454b-a589-1c726d48d814
[I 2025-02-07 14:35:04.381 ServerApp] Connecting to kernel e81baf26-c1c0-477a-bca8-88d78217683f.
[I 2025-02-07 14:35:04.476 ServerApp] Connecting to kernel 3778f05b-f0aa-4031-8177-e401d3378f17.
[I 2025-02-07 14:35:04.546 ServerApp] Connecting to kernel 081410ba-55e9-4769-86c3-b2f3d2f46fdd.
[I 2025-02-07 14:35:04.614 ServerApp] Connecting to kernel 1cd16dca-c743-4616-9dec-4f9376f23e33.
[I 2025-02-07 14:35:04.641 ServerApp] Starting buffering for e81baf26-c1c0-477a-bca8-88d78217683f:8581cc3c-62ba-4504-b47f-eea35e092c25
[I 2025-02-07 14:35:04.700 ServerApp] Connecting to kernel 30a13a1a-7fd3-49c9-a654-3cc1e85e8eb3.
[I 2025-02-07 14:35:04.744 ServerApp] Starting buffering for 081410ba-55e9-4769-86c3-b2f3d2f46fdd:f0ec21db-2447-472f-beea-392f34ea6ff2
[I 2025-02-07 14:35:04.770 ServerApp] Connecting to kernel 6c68b07b-8670-4aac-96eb-b4f79164503a.
[I 2025-02-07 14:35:04.802 ServerApp] Starting buffering for 30a13a1a-7fd3-49c9-a654-3cc1e85e8eb3:01fbec44-1312-4730-80fc-e9088f3d4cce
[I 2025-02-07 14:35:04.842 ServerApp] Connecting to kernel 221c45b8-9f73-43f7-8b47-a93e74608977.
[I 2025-02-07 14:35:04.863 ServerApp] Starting buffering for 6c68b07b-8670-4aac-96eb-b4f79164503a:b804c3bc-1c76-4a29-9304-d3b5b307aa8e
[I 2025-02-07 14:35:04.905 ServerApp] Connecting to kernel 4c11896e-fd61-4d30-8ff9-750bc7a5e75e.
[I 2025-02-07 14:35:04.972 ServerApp] Connecting to kernel f7098582-a20c-41ea-be2e-8e96294dcba5.
[I 2025-02-07 14:35:05.004 ServerApp] Starting buffering for 4c11896e-fd61-4d30-8ff9-750bc7a5e75e:32b45605-9db7-43ba-876b-933568ef5207
[I 2025-02-07 14:35:05.036 ServerApp] Connecting to kernel 221c45b8-9f73-43f7-8b47-a93e74608977.
[I 2025-02-07 14:35:05.047 ServerApp] Starting buffering for f7098582-a20c-41ea-be2e-8e96294dcba5:62ed0a36-4e46-4d4e-9d93-ad42817be716
[I 2025-02-07 14:35:09.722 ServerApp] Connecting to kernel e81baf26-c1c0-477a-bca8-88d78217683f.
[I 2025-02-07 14:35:09.808 ServerApp] Connecting to kernel 3778f05b-f0aa-4031-8177-e401d3378f17.
[I 2025-02-07 14:35:09.883 ServerApp] Connecting to kernel 081410ba-55e9-4769-86c3-b2f3d2f46fdd.
[I 2025-02-07 14:35:09.949 ServerApp] Connecting to kernel 1cd16dca-c743-4616-9dec-4f9376f23e33.
[I 2025-02-07 14:35:09.966 ServerApp] Starting buffering for e81baf26-c1c0-477a-bca8-88d78217683f:6c923917-832e-4e0c-87a8-5ab70c49655b
[I 2025-02-07 14:35:10.022 ServerApp] Connecting to kernel 30a13a1a-7fd3-49c9-a654-3cc1e85e8eb3.
[I 2025-02-07 14:35:10.032 ServerApp] Starting buffering for 081410ba-55e9-4769-86c3-b2f3d2f46fdd:42afedfc-0475-49f2-b982-2c2961a322a8
[I 2025-02-07 14:35:10.105 ServerApp] Connecting to kernel 6c68b07b-8670-4aac-96eb-b4f79164503a.
[I 2025-02-07 14:35:10.116 ServerApp] Starting buffering for 30a13a1a-7fd3-49c9-a654-3cc1e85e8eb3:87c7a8c7-c98e-46e2-99be-0b22283bebac
[I 2025-02-07 14:35:10.182 ServerApp] Connecting to kernel 221c45b8-9f73-43f7-8b47-a93e74608977.
[I 2025-02-07 14:35:10.196 ServerApp] Starting buffering for 6c68b07b-8670-4aac-96eb-b4f79164503a:061e6231-941d-44e9-bd24-c49cf8ccb2f2
[I 2025-02-07 14:35:10.257 ServerApp] Connecting to kernel 4c11896e-fd61-4d30-8ff9-750bc7a5e75e.
[I 2025-02-07 14:35:10.333 ServerApp] Connecting to kernel f7098582-a20c-41ea-be2e-8e96294dcba5.
[I 2025-02-07 14:35:10.349 ServerApp] Starting buffering for 4c11896e-fd61-4d30-8ff9-750bc7a5e75e:7c1911ba-8afc-45aa-aecc-f3a924a1f327
[I 2025-02-07 14:35:10.405 ServerApp] Connecting to kernel 30a13a1a-7fd3-49c9-a654-3cc1e85e8eb3.
[I 2025-02-07 14:35:10.408 ServerApp] Starting buffering for f7098582-a20c-41ea-be2e-8e96294dcba5:4fbb72bf-32c2-4554-8c69-db05500b85b2
[I 2025-02-07 14:35:11.198 ServerApp] Starting buffering for 30a13a1a-7fd3-49c9-a654-3cc1e85e8eb3:0909562a-9029-4a2d-b2a3-a2fb87efad2b
[I 2025-02-07 14:35:59.645 ServerApp] Connecting to kernel e81baf26-c1c0-477a-bca8-88d78217683f.
[I 2025-02-07 14:35:59.741 ServerApp] Connecting to kernel 3778f05b-f0aa-4031-8177-e401d3378f17.
[I 2025-02-07 14:35:59.854 ServerApp] Connecting to kernel 081410ba-55e9-4769-86c3-b2f3d2f46fdd.
[I 2025-02-07 14:35:59.912 ServerApp] Starting buffering for e81baf26-c1c0-477a-bca8-88d78217683f:06608f65-93ce-49ab-b0f8-2e373347eeeb
[I 2025-02-07 14:35:59.920 ServerApp] Connecting to kernel 1cd16dca-c743-4616-9dec-4f9376f23e33.
[I 2025-02-07 14:35:59.974 ServerApp] Starting buffering for 081410ba-55e9-4769-86c3-b2f3d2f46fdd:7d3b0219-a72b-495b-845e-6657732f3ef5
[I 2025-02-07 14:35:59.984 ServerApp] Connecting to kernel 30a13a1a-7fd3-49c9-a654-3cc1e85e8eb3.
[I 2025-02-07 14:36:00.051 ServerApp] Connecting to kernel 6c68b07b-8670-4aac-96eb-b4f79164503a.
[I 2025-02-07 14:36:00.064 ServerApp] Starting buffering for 30a13a1a-7fd3-49c9-a654-3cc1e85e8eb3:abd941a1-e5b2-4b13-8e7e-003f561360e6
[I 2025-02-07 14:36:00.125 ServerApp] Connecting to kernel 221c45b8-9f73-43f7-8b47-a93e74608977.
[I 2025-02-07 14:36:00.222 ServerApp] Connecting to kernel 4c11896e-fd61-4d30-8ff9-750bc7a5e75e.
[I 2025-02-07 14:36:00.233 ServerApp] Starting buffering for 6c68b07b-8670-4aac-96eb-b4f79164503a:c15e361c-1429-4dab-bfae-3fd18fa6fae5
[I 2025-02-07 14:36:00.295 ServerApp] Connecting to kernel f7098582-a20c-41ea-be2e-8e96294dcba5.
[I 2025-02-07 14:36:00.317 ServerApp] Starting buffering for 4c11896e-fd61-4d30-8ff9-750bc7a5e75e:2b834aa5-bfa0-4fb8-a47c-d6e9cd13eb45
[I 2025-02-07 14:36:00.358 ServerApp] Connecting to kernel 221c45b8-9f73-43f7-8b47-a93e74608977.
[I 2025-02-07 14:36:00.377 ServerApp] Starting buffering for f7098582-a20c-41ea-be2e-8e96294dcba5:57119620-96e9-4751-9e26-e6109494d161
[I 2025-02-07 14:36:28.497 ServerApp] Connecting to kernel e81baf26-c1c0-477a-bca8-88d78217683f.
[I 2025-02-07 14:36:28.614 ServerApp] Connecting to kernel 3778f05b-f0aa-4031-8177-e401d3378f17.
[I 2025-02-07 14:36:28.693 ServerApp] Connecting to kernel 081410ba-55e9-4769-86c3-b2f3d2f46fdd.
[I 2025-02-07 14:36:28.774 ServerApp] Connecting to kernel 1cd16dca-c743-4616-9dec-4f9376f23e33.
[I 2025-02-07 14:36:28.817 ServerApp] Starting buffering for e81baf26-c1c0-477a-bca8-88d78217683f:42aeb704-4e2f-4f87-afde-190decda8a90
[I 2025-02-07 14:36:28.849 ServerApp] Connecting to kernel 30a13a1a-7fd3-49c9-a654-3cc1e85e8eb3.
[I 2025-02-07 14:36:28.903 ServerApp] Starting buffering for 081410ba-55e9-4769-86c3-b2f3d2f46fdd:30c52ee0-c39f-42c5-af5e-d6f25983b9a9
[I 2025-02-07 14:36:28.918 ServerApp] Connecting to kernel 6c68b07b-8670-4aac-96eb-b4f79164503a.
[I 2025-02-07 14:36:28.970 ServerApp] Starting buffering for 30a13a1a-7fd3-49c9-a654-3cc1e85e8eb3:452394f4-cac9-4f3b-9cdf-4882138bb7a1
[I 2025-02-07 14:36:28.988 ServerApp] Connecting to kernel 221c45b8-9f73-43f7-8b47-a93e74608977.
[I 2025-02-07 14:36:28.992 ServerApp] Starting buffering for 6c68b07b-8670-4aac-96eb-b4f79164503a:1747ae87-0496-40ab-b039-92be53fa20a8
[I 2025-02-07 14:36:29.065 ServerApp] Connecting to kernel 4c11896e-fd61-4d30-8ff9-750bc7a5e75e.
[I 2025-02-07 14:36:29.144 ServerApp] Connecting to kernel f7098582-a20c-41ea-be2e-8e96294dcba5.
[I 2025-02-07 14:36:29.156 ServerApp] Starting buffering for 4c11896e-fd61-4d30-8ff9-750bc7a5e75e:719eba5d-6b90-4b4c-be05-066a0d161c94
[I 2025-02-07 14:36:29.213 ServerApp] Connecting to kernel 1cd16dca-c743-4616-9dec-4f9376f23e33.
[I 2025-02-07 14:36:29.234 ServerApp] Starting buffering for f7098582-a20c-41ea-be2e-8e96294dcba5:8b4a60cf-11de-42a4-8623-ffac29578484
[W 2025-02-07 14:36:31.767 ServerApp] Notebook YJ/15_final_project_crawling/test.ipynb is not trusted
[I 2025-02-07 14:36:33.082 ServerApp] Connecting to kernel e81baf26-c1c0-477a-bca8-88d78217683f.
[I 2025-02-07 14:36:33.192 ServerApp] Connecting to kernel 3778f05b-f0aa-4031-8177-e401d3378f17.
[W 2025-02-07 14:36:33.205 ServerApp] Notebook YJ/15_final_project_crawling/test.ipynb is not trusted
[I 2025-02-07 14:36:33.263 ServerApp] Connecting to kernel 081410ba-55e9-4769-86c3-b2f3d2f46fdd.
[I 2025-02-07 14:36:33.338 ServerApp] Connecting to kernel 1cd16dca-c743-4616-9dec-4f9376f23e33.
[I 2025-02-07 14:36:33.394 ServerApp] Starting buffering for e81baf26-c1c0-477a-bca8-88d78217683f:80c57e40-1644-418d-af6a-a243d2a84d6c
[I 2025-02-07 14:36:33.427 ServerApp] Connecting to kernel 6c68b07b-8670-4aac-96eb-b4f79164503a.
[I 2025-02-07 14:36:33.501 ServerApp] Connecting to kernel 30a13a1a-7fd3-49c9-a654-3cc1e85e8eb3.
[I 2025-02-07 14:36:33.528 ServerApp] Starting buffering for 081410ba-55e9-4769-86c3-b2f3d2f46fdd:01938481-ad03-4eb9-bc0e-7b2a1e65618c
[I 2025-02-07 14:36:33.575 ServerApp] Connecting to kernel 221c45b8-9f73-43f7-8b47-a93e74608977.
[I 2025-02-07 14:36:33.649 ServerApp] Connecting to kernel 4c11896e-fd61-4d30-8ff9-750bc7a5e75e.
[I 2025-02-07 14:36:33.714 ServerApp] Connecting to kernel f7098582-a20c-41ea-be2e-8e96294dcba5.
[I 2025-02-07 14:36:33.736 ServerApp] Starting buffering for 30a13a1a-7fd3-49c9-a654-3cc1e85e8eb3:dff98b6d-ec99-4730-94e3-6adf37191634
[I 2025-02-07 14:36:33.765 ServerApp] Starting buffering for 6c68b07b-8670-4aac-96eb-b4f79164503a:c7265668-12ae-4070-95ff-d4948b5a0bd5
[I 2025-02-07 14:36:33.768 ServerApp] Starting buffering for 4c11896e-fd61-4d30-8ff9-750bc7a5e75e:25354dc7-2f54-47bd-9a60-3899719f29df
[I 2025-02-07 14:36:33.785 ServerApp] Connecting to kernel 081410ba-55e9-4769-86c3-b2f3d2f46fdd.
[I 2025-02-07 14:36:33.822 ServerApp] Starting buffering for f7098582-a20c-41ea-be2e-8e96294dcba5:3bb6e2c9-e7cb-4b65-a5d0-41011a585af6
[I 2025-02-07 14:37:12.203 ServerApp] Saving file at /YJ/15_final_project_crawling/danawa_crawling.py
[I 2025-02-07 14:37:22.518 ServerApp] Connecting to kernel e81baf26-c1c0-477a-bca8-88d78217683f.
[I 2025-02-07 14:37:22.598 ServerApp] Connecting to kernel 3778f05b-f0aa-4031-8177-e401d3378f17.
[I 2025-02-07 14:37:22.664 ServerApp] Connecting to kernel 081410ba-55e9-4769-86c3-b2f3d2f46fdd.
[I 2025-02-07 14:37:22.726 ServerApp] Connecting to kernel 1cd16dca-c743-4616-9dec-4f9376f23e33.
[I 2025-02-07 14:37:22.729 ServerApp] Starting buffering for e81baf26-c1c0-477a-bca8-88d78217683f:6c061243-4e8d-4b5c-a4fb-c51d4c676d86
[I 2025-02-07 14:37:22.797 ServerApp] Connecting to kernel 30a13a1a-7fd3-49c9-a654-3cc1e85e8eb3.
[I 2025-02-07 14:37:22.873 ServerApp] Connecting to kernel 6c68b07b-8670-4aac-96eb-b4f79164503a.
[I 2025-02-07 14:37:22.888 ServerApp] Starting buffering for 30a13a1a-7fd3-49c9-a654-3cc1e85e8eb3:b5eb31eb-e425-4b71-b44a-8c7f4b93d2f0
[I 2025-02-07 14:37:22.949 ServerApp] Connecting to kernel 221c45b8-9f73-43f7-8b47-a93e74608977.
[I 2025-02-07 14:37:22.965 ServerApp] Starting buffering for 6c68b07b-8670-4aac-96eb-b4f79164503a:992e5645-d881-4a4c-951a-4f05172e1c3f
[I 2025-02-07 14:37:23.023 ServerApp] Connecting to kernel 4c11896e-fd61-4d30-8ff9-750bc7a5e75e.
[I 2025-02-07 14:37:23.091 ServerApp] Connecting to kernel f7098582-a20c-41ea-be2e-8e96294dcba5.
[I 2025-02-07 14:37:23.114 ServerApp] Starting buffering for 4c11896e-fd61-4d30-8ff9-750bc7a5e75e:57b2d255-4948-4927-b505-05b841f4caa7
[I 2025-02-07 14:37:23.163 ServerApp] Starting buffering for f7098582-a20c-41ea-be2e-8e96294dcba5:db0b9d68-cdc6-4157-818c-67ca8e11d92d
[I 2025-02-07 14:37:29.263 ServerApp] Saving file at /YJ/testtest.py
[I 2025-02-07 14:38:34.254 ServerApp] Saving file at /YJ/15_final_project_crawling/test.ipynb
[W 2025-02-07 14:38:34.254 ServerApp] Notebook YJ/15_final_project_crawling/test.ipynb is not trusted
[I 2025-02-07 14:45:17.398 ServerApp] Connecting to kernel e81baf26-c1c0-477a-bca8-88d78217683f.
[I 2025-02-07 14:45:17.471 ServerApp] Connecting to kernel 3778f05b-f0aa-4031-8177-e401d3378f17.
[I 2025-02-07 14:45:17.580 ServerApp] Connecting to kernel 081410ba-55e9-4769-86c3-b2f3d2f46fdd.
[I 2025-02-07 14:45:17.661 ServerApp] Connecting to kernel 1cd16dca-c743-4616-9dec-4f9376f23e33.
[I 2025-02-07 14:45:17.694 ServerApp] Starting buffering for e81baf26-c1c0-477a-bca8-88d78217683f:925943e7-7214-4495-8a01-28542af02ceb
[I 2025-02-07 14:45:17.730 ServerApp] Connecting to kernel 30a13a1a-7fd3-49c9-a654-3cc1e85e8eb3.
[I 2025-02-07 14:45:17.801 ServerApp] Connecting to kernel 4c11896e-fd61-4d30-8ff9-750bc7a5e75e.
[I 2025-02-07 14:45:17.864 ServerApp] Connecting to kernel 6c68b07b-8670-4aac-96eb-b4f79164503a.
[I 2025-02-07 14:45:17.890 ServerApp] Starting buffering for 30a13a1a-7fd3-49c9-a654-3cc1e85e8eb3:96e0ac18-15c9-4a7c-a4c9-036b618df1eb
[I 2025-02-07 14:45:17.928 ServerApp] Connecting to kernel 221c45b8-9f73-43f7-8b47-a93e74608977.
[I 2025-02-07 14:45:17.961 ServerApp] Starting buffering for 6c68b07b-8670-4aac-96eb-b4f79164503a:31c8e9ed-faea-408b-90bc-f46f23ac4cac
[I 2025-02-07 14:45:17.962 ServerApp] Starting buffering for 4c11896e-fd61-4d30-8ff9-750bc7a5e75e:59ca2d41-4d38-4a3f-a1e2-627eacdffa88
[I 2025-02-07 14:45:17.997 ServerApp] Connecting to kernel f7098582-a20c-41ea-be2e-8e96294dcba5.
[I 2025-02-07 14:45:18.073 ServerApp] Connecting to kernel e81baf26-c1c0-477a-bca8-88d78217683f.
[I 2025-02-07 14:45:18.107 ServerApp] Starting buffering for f7098582-a20c-41ea-be2e-8e96294dcba5:e5555d2a-8a2b-4197-8c38-c2184dd6ecc8
[I 2025-02-07 15:27:22.118 ServerApp] Connecting to kernel e81baf26-c1c0-477a-bca8-88d78217683f.
[I 2025-02-07 15:27:22.186 ServerApp] Connecting to kernel 3778f05b-f0aa-4031-8177-e401d3378f17.
[I 2025-02-07 15:27:22.270 ServerApp] Connecting to kernel 081410ba-55e9-4769-86c3-b2f3d2f46fdd.
[I 2025-02-07 15:27:22.340 ServerApp] Connecting to kernel 1cd16dca-c743-4616-9dec-4f9376f23e33.
[I 2025-02-07 15:27:22.410 ServerApp] Connecting to kernel 30a13a1a-7fd3-49c9-a654-3cc1e85e8eb3.
[I 2025-02-07 15:27:22.476 ServerApp] Connecting to kernel 6c68b07b-8670-4aac-96eb-b4f79164503a.
[I 2025-02-07 15:27:22.551 ServerApp] Connecting to kernel 221c45b8-9f73-43f7-8b47-a93e74608977.
[I 2025-02-07 15:27:22.565 ServerApp] Starting buffering for 30a13a1a-7fd3-49c9-a654-3cc1e85e8eb3:d9afbbea-2f05-43a3-9fcb-8fabbfbaa7b3
[I 2025-02-07 15:27:22.592 ServerApp] Starting buffering for 6c68b07b-8670-4aac-96eb-b4f79164503a:1e4d5889-5a60-4356-8bb4-6f94ff6885eb
[I 2025-02-07 15:27:22.626 ServerApp] Connecting to kernel 4c11896e-fd61-4d30-8ff9-750bc7a5e75e.
[I 2025-02-07 15:27:22.698 ServerApp] Connecting to kernel f7098582-a20c-41ea-be2e-8e96294dcba5.
[I 2025-02-07 15:27:22.702 ServerApp] Starting buffering for 4c11896e-fd61-4d30-8ff9-750bc7a5e75e:1cee9ab5-0561-4eb0-8c75-9f12104aec57
[I 2025-02-07 15:27:22.766 ServerApp] Connecting to kernel 221c45b8-9f73-43f7-8b47-a93e74608977.
[I 2025-02-07 15:27:22.789 ServerApp] Starting buffering for f7098582-a20c-41ea-be2e-8e96294dcba5:e5ca70dc-8a18-41d2-936c-d3c86586ebda
[I 2025-02-07 15:28:42.586 ServerApp] Connecting to kernel e81baf26-c1c0-477a-bca8-88d78217683f.
[I 2025-02-07 15:28:42.653 ServerApp] Connecting to kernel 3778f05b-f0aa-4031-8177-e401d3378f17.
[I 2025-02-07 15:28:42.725 ServerApp] Connecting to kernel 081410ba-55e9-4769-86c3-b2f3d2f46fdd.
[I 2025-02-07 15:28:42.794 ServerApp] Connecting to kernel 1cd16dca-c743-4616-9dec-4f9376f23e33.
[I 2025-02-07 15:28:42.861 ServerApp] Connecting to kernel 30a13a1a-7fd3-49c9-a654-3cc1e85e8eb3.
[I 2025-02-07 15:28:42.929 ServerApp] Connecting to kernel 6c68b07b-8670-4aac-96eb-b4f79164503a.
[I 2025-02-07 15:28:42.938 ServerApp] Starting buffering for 30a13a1a-7fd3-49c9-a654-3cc1e85e8eb3:d533a852-7096-4426-8900-5c3e11a7293d
[I 2025-02-07 15:28:43.000 ServerApp] Connecting to kernel 221c45b8-9f73-43f7-8b47-a93e74608977.
[I 2025-02-07 15:28:43.022 ServerApp] Starting buffering for 6c68b07b-8670-4aac-96eb-b4f79164503a:ef5dbf92-0b4f-4d5e-a8f7-ed262f653d54
[I 2025-02-07 15:28:43.073 ServerApp] Connecting to kernel 4c11896e-fd61-4d30-8ff9-750bc7a5e75e.
[I 2025-02-07 15:28:43.149 ServerApp] Connecting to kernel f7098582-a20c-41ea-be2e-8e96294dcba5.
[I 2025-02-07 15:28:43.165 ServerApp] Starting buffering for 4c11896e-fd61-4d30-8ff9-750bc7a5e75e:54eb6570-d61a-4b1e-81ea-2066e46865ac
[I 2025-02-07 15:28:43.242 ServerApp] Starting buffering for f7098582-a20c-41ea-be2e-8e96294dcba5:2e9a0b34-079f-4b92-9d1a-0923495aaa18
[I 2025-02-07 15:28:50.858 ServerApp] Saving file at /YJ/15_final_project_crawling/danawa_crawling.py
[I 2025-02-07 15:32:34.543 ServerApp] Saving file at /YJ/15_final_project_crawling/danawa_crawling.py
[I 2025-02-07 15:32:59.748 ServerApp] Saving file at /YJ/15_final_project_crawling/danawa_crawling.py
[I 2025-02-07 15:33:05.142 ServerApp] Saving file at /YJ/15_final_project_crawling/danawa_crawling.py
[I 2025-02-07 15:33:27.305 ServerApp] Starting buffering for 081410ba-55e9-4769-86c3-b2f3d2f46fdd:4d27b32d-e5ca-4bf5-acd8-4588da759b03
[I 2025-02-07 15:33:27.683 ServerApp] Connecting to kernel e81baf26-c1c0-477a-bca8-88d78217683f.
[I 2025-02-07 15:33:27.752 ServerApp] Connecting to kernel 3778f05b-f0aa-4031-8177-e401d3378f17.
[I 2025-02-07 15:33:27.822 ServerApp] Connecting to kernel 081410ba-55e9-4769-86c3-b2f3d2f46fdd.
[I 2025-02-07 15:33:27.891 ServerApp] Connecting to kernel 1cd16dca-c743-4616-9dec-4f9376f23e33.
[I 2025-02-07 15:33:27.963 ServerApp] Connecting to kernel 30a13a1a-7fd3-49c9-a654-3cc1e85e8eb3.
[I 2025-02-07 15:33:28.017 ServerApp] Starting buffering for 081410ba-55e9-4769-86c3-b2f3d2f46fdd:ab909932-cd9d-44f7-ac37-644283081da4
[I 2025-02-07 15:33:28.038 ServerApp] Connecting to kernel 6c68b07b-8670-4aac-96eb-b4f79164503a.
[I 2025-02-07 15:33:28.074 ServerApp] Starting buffering for 30a13a1a-7fd3-49c9-a654-3cc1e85e8eb3:a3489f5f-6e56-432d-8ebf-24bdaedd1e48
[I 2025-02-07 15:33:28.116 ServerApp] Connecting to kernel 221c45b8-9f73-43f7-8b47-a93e74608977.
[I 2025-02-07 15:33:28.156 ServerApp] Starting buffering for 6c68b07b-8670-4aac-96eb-b4f79164503a:1053e187-8086-49f8-b50a-ac295d694b2a
[I 2025-02-07 15:33:28.193 ServerApp] Connecting to kernel 4c11896e-fd61-4d30-8ff9-750bc7a5e75e.
[I 2025-02-07 15:33:28.269 ServerApp] Connecting to kernel f7098582-a20c-41ea-be2e-8e96294dcba5.
[I 2025-02-07 15:33:28.289 ServerApp] Starting buffering for 4c11896e-fd61-4d30-8ff9-750bc7a5e75e:6c4a2798-96e8-4cff-a5a7-138cc0825ba8
[I 2025-02-07 15:33:28.296 ServerApp] Starting buffering for e81baf26-c1c0-477a-bca8-88d78217683f:1fa1e6f0-ea49-4e92-851e-2168d85e3cd3
[I 2025-02-07 15:33:28.346 ServerApp] Connecting to kernel 1cd16dca-c743-4616-9dec-4f9376f23e33.
[I 2025-02-07 15:33:28.389 ServerApp] Starting buffering for f7098582-a20c-41ea-be2e-8e96294dcba5:81c76678-ebbb-43aa-910a-6e32a9e6c861
[I 2025-02-07 15:33:29.160 ServerApp] Starting buffering for 3778f05b-f0aa-4031-8177-e401d3378f17:a4fc5a39-fe9f-4075-9a89-1dd0f7d81516
[I 2025-02-07 15:33:48.333 ServerApp] Saving file at /YJ/15_final_project_crawling/danawa_crawling.py
[I 2025-02-07 15:34:02.457 ServerApp] Kernel started: f31622da-23e2-461e-a2f4-9ec49d175c26
[I 2025-02-07 15:34:02.458 ServerApp] Kernel shutdown: 1cd16dca-c743-4616-9dec-4f9376f23e33
[I 2025-02-07 15:34:02.954 ServerApp] Connecting to kernel f31622da-23e2-461e-a2f4-9ec49d175c26.
[I 2025-02-07 15:35:27.994 ServerApp] Saving file at /YJ/15_final_project_crawling/Untitled.ipynb
[I 2025-02-07 15:43:28.100 ServerApp] Starting buffering for 221c45b8-9f73-43f7-8b47-a93e74608977:a8e9d6b3-e47d-496c-9e52-9a411e16e210
[I 2025-02-07 15:43:29.666 ServerApp] Connecting to kernel e81baf26-c1c0-477a-bca8-88d78217683f.
[I 2025-02-07 15:43:29.800 ServerApp] Connecting to kernel 3778f05b-f0aa-4031-8177-e401d3378f17.
[I 2025-02-07 15:43:29.870 ServerApp] Connecting to kernel 081410ba-55e9-4769-86c3-b2f3d2f46fdd.
[I 2025-02-07 15:43:29.913 ServerApp] Starting buffering for e81baf26-c1c0-477a-bca8-88d78217683f:e506e396-62a3-432e-8863-c5bb2b883bd2
[I 2025-02-07 15:43:29.916 ServerApp] Starting buffering for 3778f05b-f0aa-4031-8177-e401d3378f17:f3b26c45-1c0b-4f42-a22f-ff63bcd63138
[I 2025-02-07 15:43:29.944 ServerApp] Connecting to kernel f31622da-23e2-461e-a2f4-9ec49d175c26.
[I 2025-02-07 15:43:30.009 ServerApp] Starting buffering for 081410ba-55e9-4769-86c3-b2f3d2f46fdd:9f219f2e-bcae-4f9d-9662-7343111e7aae
[I 2025-02-07 15:43:30.018 ServerApp] Connecting to kernel 30a13a1a-7fd3-49c9-a654-3cc1e85e8eb3.
[I 2025-02-07 15:43:30.092 ServerApp] Connecting to kernel 6c68b07b-8670-4aac-96eb-b4f79164503a.
[I 2025-02-07 15:43:30.139 ServerApp] Starting buffering for 30a13a1a-7fd3-49c9-a654-3cc1e85e8eb3:7cc26dfb-3206-460a-9506-e1ed20f9cb3f
[I 2025-02-07 15:43:30.162 ServerApp] Connecting to kernel 221c45b8-9f73-43f7-8b47-a93e74608977.
[I 2025-02-07 15:43:30.190 ServerApp] Starting buffering for 6c68b07b-8670-4aac-96eb-b4f79164503a:862b014b-274f-4575-b6c0-e76c6d7970bf
[I 2025-02-07 15:43:30.224 ServerApp] Connecting to kernel 4c11896e-fd61-4d30-8ff9-750bc7a5e75e.
[I 2025-02-07 15:43:30.241 ServerApp] Starting buffering for 221c45b8-9f73-43f7-8b47-a93e74608977:8632fd5a-c5ca-4494-a2f8-5929be50d839
[I 2025-02-07 15:43:30.295 ServerApp] Connecting to kernel f7098582-a20c-41ea-be2e-8e96294dcba5.
[I 2025-02-07 15:43:30.299 ServerApp] Starting buffering for 4c11896e-fd61-4d30-8ff9-750bc7a5e75e:f205ce82-30f3-46b1-a020-7bbea21333ae
[I 2025-02-07 15:43:30.394 ServerApp] Starting buffering for f7098582-a20c-41ea-be2e-8e96294dcba5:da294cf1-68d1-40a5-a276-e58c11d4ec4a
[I 2025-02-07 15:44:02.970 ServerApp] Kernel interrupted: f31622da-23e2-461e-a2f4-9ec49d175c26
[W 2025-02-07 15:44:12.092 ServerApp] delete /YJ/15_final_project_crawling/danawa_review_S24+1.parquet
[I 2025-02-07 15:44:50.935 ServerApp] Connecting to kernel e81baf26-c1c0-477a-bca8-88d78217683f.
[I 2025-02-07 15:44:51.000 ServerApp] Connecting to kernel 3778f05b-f0aa-4031-8177-e401d3378f17.
[I 2025-02-07 15:44:51.066 ServerApp] Connecting to kernel 081410ba-55e9-4769-86c3-b2f3d2f46fdd.
[I 2025-02-07 15:44:51.093 ServerApp] Starting buffering for e81baf26-c1c0-477a-bca8-88d78217683f:2f0f8599-f60b-42b3-817b-9ebf1ae0b97d
[I 2025-02-07 15:44:51.096 ServerApp] Starting buffering for 3778f05b-f0aa-4031-8177-e401d3378f17:c7d9e1bb-a2e1-4c03-b690-6786a6a35e4b
[I 2025-02-07 15:44:51.135 ServerApp] Connecting to kernel f31622da-23e2-461e-a2f4-9ec49d175c26.
[I 2025-02-07 15:44:51.148 ServerApp] Starting buffering for 081410ba-55e9-4769-86c3-b2f3d2f46fdd:360ca08e-53d6-4bd2-bf61-287b88a3b228
[I 2025-02-07 15:44:51.260 ServerApp] Connecting to kernel 30a13a1a-7fd3-49c9-a654-3cc1e85e8eb3.
[I 2025-02-07 15:44:51.329 ServerApp] Connecting to kernel 6c68b07b-8670-4aac-96eb-b4f79164503a.
[I 2025-02-07 15:44:51.355 ServerApp] Starting buffering for 30a13a1a-7fd3-49c9-a654-3cc1e85e8eb3:4494abd7-f0ee-41f8-b291-2d7977a42e46
[I 2025-02-07 15:44:51.406 ServerApp] Starting buffering for 6c68b07b-8670-4aac-96eb-b4f79164503a:a0756aa3-f35e-4362-984a-3bf4258281fb
[I 2025-02-07 15:44:51.412 ServerApp] Connecting to kernel 221c45b8-9f73-43f7-8b47-a93e74608977.
[I 2025-02-07 15:44:51.487 ServerApp] Connecting to kernel 4c11896e-fd61-4d30-8ff9-750bc7a5e75e.
[I 2025-02-07 15:44:51.513 ServerApp] Starting buffering for 221c45b8-9f73-43f7-8b47-a93e74608977:0a1390a8-d43a-47e6-a009-e89eb8c2f66e
[I 2025-02-07 15:44:51.563 ServerApp] Connecting to kernel f7098582-a20c-41ea-be2e-8e96294dcba5.
[I 2025-02-07 15:44:51.613 ServerApp] Starting buffering for 4c11896e-fd61-4d30-8ff9-750bc7a5e75e:0d5642a1-677b-4873-9c10-d2236cdf8925
[I 2025-02-07 15:44:51.661 ServerApp] Starting buffering for f7098582-a20c-41ea-be2e-8e96294dcba5:775a8efd-f566-487d-8c73-c208989add35
[I 2025-02-07 15:44:53.291 ServerApp] Saving file at /YJ/15_final_project_crawling/danawa_crawling.py
[I 2025-02-07 15:45:30.118 ServerApp] Saving file at /YJ/15_final_project_crawling/Untitled.ipynb
[I 2025-02-07 17:25:01.214 ServerApp] Saving file at /YJ/15_final_project_crawling/danawa_crawling.py
[I 2025-02-07 17:25:02.366 ServerApp] Saving file at /YJ/15_final_project_crawling/danawa_crawling.py
[I 2025-02-07 17:26:49.497 ServerApp] Kernel restarted: f31622da-23e2-461e-a2f4-9ec49d175c26
[I 2025-02-07 17:26:49.534 ServerApp] Starting buffering for f31622da-23e2-461e-a2f4-9ec49d175c26:d790b219-2811-462a-883f-dabb28436ae7
[I 2025-02-07 17:26:49.565 ServerApp] Connecting to kernel f31622da-23e2-461e-a2f4-9ec49d175c26.
[I 2025-02-07 17:26:49.566 ServerApp] Restoring connection for f31622da-23e2-461e-a2f4-9ec49d175c26:d790b219-2811-462a-883f-dabb28436ae7
[I 2025-02-07 17:27:04.002 ServerApp] Saving file at /YJ/15_final_project_crawling/Untitled.ipynb
[I 2025-02-07 17:28:55.815 ServerApp] Kernel started: 74f70917-e0f2-48b4-b9d4-eacc6b48ffb9
[I 2025-02-07 17:28:55.817 ServerApp] Kernel shutdown: f31622da-23e2-461e-a2f4-9ec49d175c26
[I 2025-02-07 17:28:56.414 ServerApp] Connecting to kernel 74f70917-e0f2-48b4-b9d4-eacc6b48ffb9.
[I 2025-02-07 17:29:04.125 ServerApp] Saving file at /YJ/15_final_project_crawling/Untitled.ipynb
[I 2025-02-07 17:31:04.985 ServerApp] Saving file at /YJ/15_final_project_crawling/Untitled.ipynb
[I 2025-02-07 17:37:26.902 ServerApp] Saving file at /YJ/15_final_project_crawling/Untitled.ipynb
[I 2025-02-07 17:37:38.026 ServerApp] Saving file at /YJ/15_final_project_crawling/danawa_crawling.py
[I 2025-02-07 17:39:49.818 ServerApp] Saving file at /YJ/15_final_project_crawling/Untitled.ipynb
[I 2025-02-07 17:39:49.989 ServerApp] Starting buffering for 74f70917-e0f2-48b4-b9d4-eacc6b48ffb9:d790b219-2811-462a-883f-dabb28436ae7
[I 2025-02-07 17:39:50.125 ServerApp] Connecting to kernel 74f70917-e0f2-48b4-b9d4-eacc6b48ffb9.
[I 2025-02-07 17:39:57.202 ServerApp] Saving file at /YJ/15_final_project_crawling/Untitled.ipynb
[I 2025-02-07 17:40:04.268 ServerApp] Saving file at /YJ/15_final_project_crawling/Untitled.ipynb
[I 2025-02-07 17:40:04.931 ServerApp] Starting buffering for 74f70917-e0f2-48b4-b9d4-eacc6b48ffb9:f7fbde92-f71b-4bf1-ac97-760127adcada
[I 2025-02-07 17:40:06.200 ServerApp] Saving file at /YJ/15_final_project_crawling/danawa_crawling.py
[C 2025-02-07 19:00:01.612 ServerApp] received signal 15, stopping
[I 2025-02-07 19:00:01.634 ServerApp] Shutting down 5 extensions
[I 2025-02-07 19:00:01.635 ServerApp] Shutting down 9 kernels
[I 2025-02-07 19:00:01.645 ServerApp] Kernel shutdown: 4c11896e-fd61-4d30-8ff9-750bc7a5e75e
[I 2025-02-07 19:00:01.646 ServerApp] Kernel shutdown: 6c68b07b-8670-4aac-96eb-b4f79164503a
[I 2025-02-07 19:00:01.646 ServerApp] Kernel shutdown: 221c45b8-9f73-43f7-8b47-a93e74608977
[I 2025-02-07 19:00:01.647 ServerApp] Kernel shutdown: 081410ba-55e9-4769-86c3-b2f3d2f46fdd
[I 2025-02-07 19:00:01.665 ServerApp] Kernel shutdown: e81baf26-c1c0-477a-bca8-88d78217683f
[I 2025-02-07 19:00:01.669 ServerApp] Kernel shutdown: 30a13a1a-7fd3-49c9-a654-3cc1e85e8eb3
[I 2025-02-07 19:00:01.670 ServerApp] Kernel shutdown: f7098582-a20c-41ea-be2e-8e96294dcba5
[I 2025-02-07 19:00:01.672 ServerApp] Kernel shutdown: 74f70917-e0f2-48b4-b9d4-eacc6b48ffb9
[I 2025-02-07 19:00:01.673 ServerApp] Kernel shutdown: 3778f05b-f0aa-4031-8177-e401d3378f17
[I 2025-02-11 14:14:14.068 ServerApp] jupyter_lsp | extension was successfully linked.
[I 2025-02-11 14:14:14.073 ServerApp] jupyter_server_terminals | extension was successfully linked.
[I 2025-02-11 14:14:14.078 ServerApp] jupyterlab | extension was successfully linked.
[W 2025-02-11 14:14:14.080 JupyterNotebookApp] 'password' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-11 14:14:14.083 ServerApp] ServerApp.password config is deprecated in 2.0. Use PasswordIdentityProvider.hashed_password.
[I 2025-02-11 14:14:14.083 ServerApp] notebook | extension was successfully linked.
[I 2025-02-11 14:14:14.596 ServerApp] notebook_shim | extension was successfully linked.
[I 2025-02-11 14:14:14.699 ServerApp] notebook_shim | extension was successfully loaded.
[I 2025-02-11 14:14:14.701 ServerApp] jupyter_lsp | extension was successfully loaded.
[I 2025-02-11 14:14:14.702 ServerApp] jupyter_server_terminals | extension was successfully loaded.
[I 2025-02-11 14:14:14.716 LabApp] JupyterLab extension loaded from /home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyterlab
[I 2025-02-11 14:14:14.716 LabApp] JupyterLab application directory is /home/ubuntu/anaconda3/envs/Project/share/jupyter/lab
[I 2025-02-11 14:14:14.717 LabApp] Extension Manager is 'pypi'.
[I 2025-02-11 14:14:14.769 ServerApp] jupyterlab | extension was successfully loaded.
[I 2025-02-11 14:14:14.772 ServerApp] notebook | extension was successfully loaded.
[I 2025-02-11 14:14:14.773 ServerApp] Serving notebooks from local directory: /home/lab13/project
[I 2025-02-11 14:14:14.773 ServerApp] Jupyter Server 2.14.2 is running at:
[I 2025-02-11 14:14:14.773 ServerApp] http://ip-172-31-13-81:8917/tree
[I 2025-02-11 14:14:14.773 ServerApp]     http://127.0.0.1:8917/tree
[I 2025-02-11 14:14:14.773 ServerApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[I 2025-02-11 14:14:14.792 ServerApp] Skipped non-installed server(s): bash-language-server, dockerfile-language-server-nodejs, javascript-typescript-langserver, jedi-language-server, julia-language-server, pyright, python-language-server, python-lsp-server, r-languageserver, sql-language-server, texlab, typescript-language-server, unified-language-server, vscode-css-languageserver-bin, vscode-html-languageserver-bin, vscode-json-languageserver-bin, yaml-language-server
[I 2025-02-11 14:14:35.034 ServerApp] 302 GET / (@125.129.250.60) 0.49ms
[I 2025-02-11 14:14:35.062 JupyterNotebookApp] 302 GET /tree? (@125.129.250.60) 0.53ms
[W 2025-02-11 14:14:40.492 ServerApp] 401 POST /login?next=%2Ftree%3F (@125.129.250.60) 50.25ms referer=http://15.168.221.131:8917/login?next=%2Ftree%3F
[I 2025-02-11 14:14:43.745 ServerApp] User 1d7b9f3a969049d5a3c840e5cb230b83 logged in.
[I 2025-02-11 14:14:43.746 ServerApp] 302 POST /login?next=%2Ftree%3F (1d7b9f3a969049d5a3c840e5cb230b83@125.129.250.60) 33.25ms
[W 2025-02-11 14:14:49.667 ServerApp] 409 PATCH /api/contents/YJ/Untitled.ipynb?1739250889300 (125.129.250.60): File already exists: YJ/dags/Untitled.ipynb
[W 2025-02-11 14:14:49.667 ServerApp] wrote error: 'File already exists: YJ/dags/Untitled.ipynb'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_server/services/contents/handlers.py", line 204, in patch
        model = await ensure_async(cm.update(model, path))
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_core/utils/__init__.py", line 198, in ensure_async
        result = await obj
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_server/services/contents/manager.py", line 919, in update
        await self.rename(path, new_path)
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_server/services/contents/manager.py", line 906, in rename
        await self.rename_file(old_path, new_path)
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_server/services/contents/filemanager.py", line 1064, in rename_file
        raise web.HTTPError(409, "File already exists: %s" % new_path)
    tornado.web.HTTPError: HTTP 409: Conflict (File already exists: YJ/dags/Untitled.ipynb)
[W 2025-02-11 14:14:49.675 ServerApp] 409 PATCH /api/contents/YJ/Untitled.ipynb?1739250889300 (1d7b9f3a969049d5a3c840e5cb230b83@125.129.250.60) 9.54ms referer=http://15.168.221.131:8917/tree/YJ
[I 2025-02-11 14:14:53.409 ServerApp] Kernel started: e80e56ae-9245-45e4-819a-0d4b54c6bee1
[I 2025-02-11 14:14:54.734 ServerApp] Connecting to kernel e80e56ae-9245-45e4-819a-0d4b54c6bee1.
[I 2025-02-11 14:14:54.812 ServerApp] Starting buffering for e80e56ae-9245-45e4-819a-0d4b54c6bee1:50cd9050-a47d-4e82-a3f6-360590ab5533
[I 2025-02-11 14:14:54.817 ServerApp] Connecting to kernel e80e56ae-9245-45e4-819a-0d4b54c6bee1.
[I 2025-02-11 14:14:54.892 ServerApp] Connecting to kernel e80e56ae-9245-45e4-819a-0d4b54c6bee1.
[I 2025-02-11 14:14:56.069 ServerApp] Connecting to kernel e80e56ae-9245-45e4-819a-0d4b54c6bee1.
[I 2025-02-11 14:56:32.366 ServerApp] Connecting to kernel e80e56ae-9245-45e4-819a-0d4b54c6bee1.
[I 2025-02-11 14:56:32.808 ServerApp] Kernel started: 00f9860c-553d-406c-a62f-bf25c271a740
[I 2025-02-11 14:56:33.247 ServerApp] Connecting to kernel 00f9860c-553d-406c-a62f-bf25c271a740.
[I 2025-02-11 14:56:33.324 ServerApp] Connecting to kernel 00f9860c-553d-406c-a62f-bf25c271a740.
[I 2025-02-11 14:56:33.397 ServerApp] Connecting to kernel 00f9860c-553d-406c-a62f-bf25c271a740.
2025-02-11 14:57:13,824 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:>                                                         (0 + 4) / 35][Stage 0:==============================>                          (19 + 4) / 35]                                                                                [I 2025-02-11 14:58:32.615 ServerApp] Saving file at /YJ/test/hdfs_test.ipynb
[I 2025-02-11 15:00:32.734 ServerApp] Saving file at /YJ/test/hdfs_test.ipynb
2025-02-11 16:24:28,305 WARN util.Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2025-02-11 16:24:28,305 WARN util.Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
2025-02-11 16:24:28,306 WARN util.Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
[I 2025-02-11 16:25:47.918 ServerApp] Saving file at /YJ/test/hdfs_test.ipynb
[I 2025-02-11 16:27:48.021 ServerApp] Saving file at /YJ/test/hdfs_test.ipynb
[I 2025-02-11 16:33:00.246 ServerApp] Connecting to kernel 00f9860c-553d-406c-a62f-bf25c271a740.
[I 2025-02-11 16:33:01.335 ServerApp] Starting buffering for e80e56ae-9245-45e4-819a-0d4b54c6bee1:f8600bf4-cd2a-4c5e-b01c-1927e7056398
[I 2025-02-11 16:33:02.481 ServerApp] Connecting to kernel 00f9860c-553d-406c-a62f-bf25c271a740.
[I 2025-02-11 16:33:48.212 ServerApp] Creating new notebook in /YJ/test
[I 2025-02-11 16:33:48.416 ServerApp] Saving file at /YJ/test/Untitled.ipynb
[I 2025-02-11 16:33:48.482 ServerApp] Kernel started: b4965611-4ba3-4973-a07b-f8690deb28e5
[I 2025-02-11 16:33:48.965 ServerApp] Connecting to kernel b4965611-4ba3-4973-a07b-f8690deb28e5.
[I 2025-02-11 16:33:50.130 ServerApp] Connecting to kernel e80e56ae-9245-45e4-819a-0d4b54c6bee1.
[I 2025-02-11 16:33:50.203 ServerApp] Connecting to kernel 00f9860c-553d-406c-a62f-bf25c271a740.
[I 2025-02-11 16:33:50.293 ServerApp] Connecting to kernel b4965611-4ba3-4973-a07b-f8690deb28e5.
[I 2025-02-11 16:33:50.431 ServerApp] Starting buffering for e80e56ae-9245-45e4-819a-0d4b54c6bee1:ae98ac88-5947-4bae-b2cc-20c87e1da504
[I 2025-02-11 16:33:50.535 ServerApp] Connecting to kernel b4965611-4ba3-4973-a07b-f8690deb28e5.
[I 2025-02-11 16:35:56.500 ServerApp] Saving file at /YJ/test/openai_test.ipynb
[I 2025-02-11 16:42:49.168 ServerApp] Saving file at /YJ/test/openai_test.ipynb
[I 2025-02-11 16:42:53.441 ServerApp] Creating new notebook in /YJ/test
[I 2025-02-11 16:42:53.623 ServerApp] Saving file at /YJ/test/Untitled.ipynb
[I 2025-02-11 16:42:53.690 ServerApp] Kernel started: 1b530485-d08a-44b6-95c9-ffa63f319bbe
[I 2025-02-11 16:42:54.173 ServerApp] Connecting to kernel 1b530485-d08a-44b6-95c9-ffa63f319bbe.
[I 2025-02-11 16:42:55.167 ServerApp] Connecting to kernel e80e56ae-9245-45e4-819a-0d4b54c6bee1.
[I 2025-02-11 16:42:55.232 ServerApp] Connecting to kernel 00f9860c-553d-406c-a62f-bf25c271a740.
[I 2025-02-11 16:42:55.321 ServerApp] Connecting to kernel b4965611-4ba3-4973-a07b-f8690deb28e5.
[I 2025-02-11 16:42:55.398 ServerApp] Connecting to kernel 1b530485-d08a-44b6-95c9-ffa63f319bbe.
[I 2025-02-11 16:42:55.454 ServerApp] Starting buffering for e80e56ae-9245-45e4-819a-0d4b54c6bee1:c470213b-5624-465e-b715-38f1ca6395e8
[I 2025-02-11 16:42:55.544 ServerApp] Connecting to kernel 1b530485-d08a-44b6-95c9-ffa63f319bbe.
[I 2025-02-11 16:45:00.882 ServerApp] Saving file at /YJ/test/llama_test.ipynb
[I 2025-02-11 16:47:01.867 ServerApp] Saving file at /YJ/test/llama_test.ipynb
[I 2025-02-11 16:49:02.865 ServerApp] Saving file at /YJ/test/llama_test.ipynb
[I 2025-02-11 16:55:04.868 ServerApp] Saving file at /YJ/test/llama_test.ipynb
[I 2025-02-11 16:56:46.517 ServerApp] Kernel restarted: 1b530485-d08a-44b6-95c9-ffa63f319bbe
[I 2025-02-11 16:56:46.579 ServerApp] Connecting to kernel 1b530485-d08a-44b6-95c9-ffa63f319bbe.
[I 2025-02-11 16:57:04.989 ServerApp] Saving file at /YJ/test/llama_test.ipynb
[I 2025-02-11 16:58:41.294 ServerApp] Kernel restarted: 1b530485-d08a-44b6-95c9-ffa63f319bbe
[I 2025-02-11 16:58:41.361 ServerApp] Connecting to kernel 1b530485-d08a-44b6-95c9-ffa63f319bbe.
[I 2025-02-11 16:59:05.156 ServerApp] Saving file at /YJ/test/llama_test.ipynb
[I 2025-02-11 17:16:45.394 ServerApp] Saving file at /YJ/test/llama_test.ipynb
[I 2025-02-11 17:17:35.284 ServerApp] AsyncIOLoopKernelRestarter: restarting kernel (1/5), keep random ports
[W 2025-02-11 17:17:35.286 ServerApp] kernel 1b530485-d08a-44b6-95c9-ffa63f319bbe restarted
[W 2025-02-11 17:17:35.286 ServerApp] kernel 1b530485-d08a-44b6-95c9-ffa63f319bbe restarted
[I 2025-02-11 17:17:35.318 ServerApp] Starting buffering for 1b530485-d08a-44b6-95c9-ffa63f319bbe:54a8e8ff-a492-4264-94b0-162a7a6471a3
[I 2025-02-11 17:17:35.347 ServerApp] Connecting to kernel 1b530485-d08a-44b6-95c9-ffa63f319bbe.
[I 2025-02-11 17:17:35.419 ServerApp] Connecting to kernel 1b530485-d08a-44b6-95c9-ffa63f319bbe.
[I 2025-02-11 17:18:27.046 ServerApp] Kernel interrupted: 1b530485-d08a-44b6-95c9-ffa63f319bbe
[I 2025-02-11 17:18:46.308 ServerApp] Saving file at /YJ/test/llama_test.ipynb
[I 2025-02-11 17:19:05.309 ServerApp] AsyncIOLoopKernelRestarter: restarting kernel (1/5), keep random ports
[W 2025-02-11 17:19:05.311 ServerApp] kernel 1b530485-d08a-44b6-95c9-ffa63f319bbe restarted
[W 2025-02-11 17:19:05.312 ServerApp] kernel 1b530485-d08a-44b6-95c9-ffa63f319bbe restarted
[I 2025-02-11 17:19:05.350 ServerApp] Starting buffering for 1b530485-d08a-44b6-95c9-ffa63f319bbe:9681955d-f69a-499a-b6cf-4590d07265e3
[I 2025-02-11 17:19:05.373 ServerApp] Connecting to kernel 1b530485-d08a-44b6-95c9-ffa63f319bbe.
[I 2025-02-11 17:19:05.445 ServerApp] Connecting to kernel 1b530485-d08a-44b6-95c9-ffa63f319bbe.
[I 2025-02-11 17:19:59.338 ServerApp] AsyncIOLoopKernelRestarter: restarting kernel (1/5), keep random ports
[W 2025-02-11 17:19:59.339 ServerApp] kernel 1b530485-d08a-44b6-95c9-ffa63f319bbe restarted
[W 2025-02-11 17:19:59.339 ServerApp] kernel 1b530485-d08a-44b6-95c9-ffa63f319bbe restarted
[I 2025-02-11 17:19:59.373 ServerApp] Starting buffering for 1b530485-d08a-44b6-95c9-ffa63f319bbe:9681955d-f69a-499a-b6cf-4590d07265e3
[I 2025-02-11 17:19:59.403 ServerApp] Connecting to kernel 1b530485-d08a-44b6-95c9-ffa63f319bbe.
[I 2025-02-11 17:19:59.490 ServerApp] Connecting to kernel 1b530485-d08a-44b6-95c9-ffa63f319bbe.
[I 2025-02-11 17:20:46.443 ServerApp] Saving file at /YJ/test/llama_test.ipynb
[I 2025-02-11 17:22:46.577 ServerApp] Saving file at /YJ/test/llama_test.ipynb
[I 2025-02-11 17:24:46.701 ServerApp] Saving file at /YJ/test/llama_test.ipynb
2025-02-11 17:26:16,718 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
2025-02-11 17:26:18,078 WARN util.Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2025-02-11 17:26:18,079 WARN util.Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
2025-02-11 17:26:18,079 WARN util.Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
2025-02-11 17:26:18,079 WARN util.Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [I 2025-02-11 17:27:14.159 ServerApp] Saving file at /YJ/test/llama_test.ipynb
[I 2025-02-11 17:27:14.362 ServerApp] AsyncIOLoopKernelRestarter: restarting kernel (1/5), keep random ports
[W 2025-02-11 17:27:14.362 ServerApp] kernel 1b530485-d08a-44b6-95c9-ffa63f319bbe restarted
[W 2025-02-11 17:27:14.363 ServerApp] kernel 1b530485-d08a-44b6-95c9-ffa63f319bbe restarted
[I 2025-02-11 17:27:14.405 ServerApp] Starting buffering for 1b530485-d08a-44b6-95c9-ffa63f319bbe:54a8e8ff-a492-4264-94b0-162a7a6471a3
[I 2025-02-11 17:27:14.429 ServerApp] Connecting to kernel 1b530485-d08a-44b6-95c9-ffa63f319bbe.
[I 2025-02-11 17:27:14.503 ServerApp] Connecting to kernel 1b530485-d08a-44b6-95c9-ffa63f319bbe.
2025-02-11 17:29:31,064 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
2025-02-11 17:29:32,438 WARN util.Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2025-02-11 17:29:32,439 WARN util.Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
2025-02-11 17:29:32,439 WARN util.Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
2025-02-11 17:29:32,439 WARN util.Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [I 2025-02-11 17:29:59.398 ServerApp] AsyncIOLoopKernelRestarter: restarting kernel (1/5), keep random ports
[W 2025-02-11 17:29:59.399 ServerApp] kernel 1b530485-d08a-44b6-95c9-ffa63f319bbe restarted
[W 2025-02-11 17:29:59.399 ServerApp] kernel 1b530485-d08a-44b6-95c9-ffa63f319bbe restarted
[I 2025-02-11 17:29:59.453 ServerApp] Starting buffering for 1b530485-d08a-44b6-95c9-ffa63f319bbe:9681955d-f69a-499a-b6cf-4590d07265e3
[I 2025-02-11 17:29:59.505 ServerApp] Connecting to kernel 1b530485-d08a-44b6-95c9-ffa63f319bbe.
[I 2025-02-11 17:29:59.579 ServerApp] Connecting to kernel 1b530485-d08a-44b6-95c9-ffa63f319bbe.
[I 2025-02-11 17:31:48.861 ServerApp] Saving file at /YJ/test/llama_test.ipynb
2025-02-11 17:32:41,477 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
2025-02-11 17:32:42,715 WARN util.Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2025-02-11 17:32:42,716 WARN util.Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
2025-02-11 17:32:42,716 WARN util.Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
2025-02-11 17:32:42,716 WARN util.Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [I 2025-02-11 17:33:32.423 ServerApp] AsyncIOLoopKernelRestarter: restarting kernel (1/5), keep random ports
[W 2025-02-11 17:33:32.424 ServerApp] kernel 1b530485-d08a-44b6-95c9-ffa63f319bbe restarted
[W 2025-02-11 17:33:32.432 ServerApp] kernel 1b530485-d08a-44b6-95c9-ffa63f319bbe restarted
[I 2025-02-11 17:33:32.486 ServerApp] Starting buffering for 1b530485-d08a-44b6-95c9-ffa63f319bbe:9681955d-f69a-499a-b6cf-4590d07265e3
[I 2025-02-11 17:33:32.529 ServerApp] Connecting to kernel 1b530485-d08a-44b6-95c9-ffa63f319bbe.
[I 2025-02-11 17:33:32.598 ServerApp] Connecting to kernel 1b530485-d08a-44b6-95c9-ffa63f319bbe.
[I 2025-02-11 17:33:49.009 ServerApp] Saving file at /YJ/test/llama_test.ipynb
[I 2025-02-11 17:35:49.128 ServerApp] Saving file at /YJ/test/llama_test.ipynb
[I 2025-02-11 17:37:23.348 ServerApp] Kernel restarted: 1b530485-d08a-44b6-95c9-ffa63f319bbe
[I 2025-02-11 17:37:23.416 ServerApp] Connecting to kernel 1b530485-d08a-44b6-95c9-ffa63f319bbe.
[I 2025-02-11 17:37:49.250 ServerApp] Saving file at /YJ/test/llama_test.ipynb
2025-02-11 17:39:26,500 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
2025-02-11 17:39:27,814 WARN util.Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2025-02-11 17:39:27,814 WARN util.Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
2025-02-11 17:39:27,815 WARN util.Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
2025-02-11 17:39:27,815 WARN util.Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [I 2025-02-11 17:39:47.338 ServerApp] AsyncIOLoopKernelRestarter: restarting kernel (1/5), keep random ports
[W 2025-02-11 17:39:47.339 ServerApp] kernel 1b530485-d08a-44b6-95c9-ffa63f319bbe restarted
[W 2025-02-11 17:39:47.340 ServerApp] kernel 1b530485-d08a-44b6-95c9-ffa63f319bbe restarted
[I 2025-02-11 17:39:47.373 ServerApp] Starting buffering for 1b530485-d08a-44b6-95c9-ffa63f319bbe:54a8e8ff-a492-4264-94b0-162a7a6471a3
[I 2025-02-11 17:39:47.396 ServerApp] Connecting to kernel 1b530485-d08a-44b6-95c9-ffa63f319bbe.
[I 2025-02-11 17:39:47.475 ServerApp] Connecting to kernel 1b530485-d08a-44b6-95c9-ffa63f319bbe.
[I 2025-02-11 17:39:49.407 ServerApp] Saving file at /YJ/test/llama_test.ipynb
[I 2025-02-11 17:41:49.531 ServerApp] Saving file at /YJ/test/llama_test.ipynb
[I 2025-02-11 17:41:57.693 ServerApp] Saving file at /YJ/test/llama_test.ipynb
[I 2025-02-11 17:43:58.802 ServerApp] Saving file at /YJ/test/llama_test.ipynb
2025-02-11 17:45:44,592 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
2025-02-11 17:45:45,910 WARN util.Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2025-02-11 17:45:45,910 WARN util.Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
2025-02-11 17:45:45,911 WARN util.Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
2025-02-11 17:45:45,911 WARN util.Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [I 2025-02-11 17:45:58.936 ServerApp] Saving file at /YJ/test/llama_test.ipynb
[I 2025-02-11 17:47:20.365 ServerApp] AsyncIOLoopKernelRestarter: restarting kernel (1/5), keep random ports
[W 2025-02-11 17:47:20.366 ServerApp] kernel 1b530485-d08a-44b6-95c9-ffa63f319bbe restarted
[W 2025-02-11 17:47:20.367 ServerApp] kernel 1b530485-d08a-44b6-95c9-ffa63f319bbe restarted
[I 2025-02-11 17:47:20.395 ServerApp] Starting buffering for 1b530485-d08a-44b6-95c9-ffa63f319bbe:54a8e8ff-a492-4264-94b0-162a7a6471a3
[I 2025-02-11 17:47:20.421 ServerApp] Connecting to kernel 1b530485-d08a-44b6-95c9-ffa63f319bbe.
[I 2025-02-11 17:47:20.502 ServerApp] Connecting to kernel 1b530485-d08a-44b6-95c9-ffa63f319bbe.
[I 2025-02-11 17:47:59.056 ServerApp] Saving file at /YJ/test/llama_test.ipynb
[I 2025-02-11 17:49:59.188 ServerApp] Saving file at /YJ/test/llama_test.ipynb
[I 2025-02-11 17:51:59.796 ServerApp] Saving file at /YJ/test/llama_test.ipynb
[I 2025-02-11 17:56:00.789 ServerApp] Saving file at /YJ/test/llama_test.ipynb
[I 2025-02-11 18:00:01.799 ServerApp] Saving file at /YJ/test/llama_test.ipynb
2025-02-11 18:05:51,707 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
2025-02-11 18:05:52,992 WARN util.Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2025-02-11 18:05:52,992 WARN util.Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
2025-02-11 18:05:52,992 WARN util.Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
2025-02-11 18:05:52,992 WARN util.Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [I 2025-02-11 18:06:03.778 ServerApp] Saving file at /YJ/test/llama_test.ipynb
[I 2025-02-11 18:06:17.389 ServerApp] AsyncIOLoopKernelRestarter: restarting kernel (1/5), keep random ports
[W 2025-02-11 18:06:17.390 ServerApp] kernel 1b530485-d08a-44b6-95c9-ffa63f319bbe restarted
[W 2025-02-11 18:06:17.390 ServerApp] kernel 1b530485-d08a-44b6-95c9-ffa63f319bbe restarted
[I 2025-02-11 18:06:17.423 ServerApp] Starting buffering for 1b530485-d08a-44b6-95c9-ffa63f319bbe:54a8e8ff-a492-4264-94b0-162a7a6471a3
[I 2025-02-11 18:06:17.460 ServerApp] Connecting to kernel 1b530485-d08a-44b6-95c9-ffa63f319bbe.
[I 2025-02-11 18:06:17.535 ServerApp] Connecting to kernel 1b530485-d08a-44b6-95c9-ffa63f319bbe.
[I 2025-02-11 18:07:05.655 ServerApp] Saving file at /YJ/test/llama_test.ipynb
[I 2025-02-11 18:07:08.071 ServerApp] Starting buffering for 00f9860c-553d-406c-a62f-bf25c271a740:b97e3fcf-8d28-4f88-aa49-3114b90234b5
[I 2025-02-11 18:07:08.420 ServerApp] Starting buffering for 1b530485-d08a-44b6-95c9-ffa63f319bbe:9681955d-f69a-499a-b6cf-4590d07265e3
[I 2025-02-11 18:07:08.421 ServerApp] Starting buffering for b4965611-4ba3-4973-a07b-f8690deb28e5:5c06afaf-9309-488d-bbb8-2a2fadd62f07
[C 2025-02-11 19:00:02.003 ServerApp] received signal 15, stopping
[I 2025-02-11 19:00:02.004 ServerApp] Shutting down 5 extensions
[I 2025-02-11 19:00:02.016 ServerApp] Shutting down 4 kernels
[I 2025-02-11 19:00:02.078 ServerApp] Kernel shutdown: e80e56ae-9245-45e4-819a-0d4b54c6bee1
[I 2025-02-11 19:00:02.084 ServerApp] Kernel shutdown: 1b530485-d08a-44b6-95c9-ffa63f319bbe
[I 2025-02-11 19:00:02.088 ServerApp] Kernel shutdown: 00f9860c-553d-406c-a62f-bf25c271a740
[I 2025-02-11 19:00:02.091 ServerApp] Kernel shutdown: b4965611-4ba3-4973-a07b-f8690deb28e5
[I 2025-02-12 11:12:19.568 ServerApp] jupyter_lsp | extension was successfully linked.
[I 2025-02-12 11:12:19.574 ServerApp] jupyter_server_terminals | extension was successfully linked.
[I 2025-02-12 11:12:19.579 ServerApp] jupyterlab | extension was successfully linked.
[W 2025-02-12 11:12:19.581 JupyterNotebookApp] 'password' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-12 11:12:19.584 ServerApp] ServerApp.password config is deprecated in 2.0. Use PasswordIdentityProvider.hashed_password.
[I 2025-02-12 11:12:19.584 ServerApp] notebook | extension was successfully linked.
[I 2025-02-12 11:12:19.802 ServerApp] notebook_shim | extension was successfully linked.
[I 2025-02-12 11:12:19.842 ServerApp] notebook_shim | extension was successfully loaded.
[I 2025-02-12 11:12:19.844 ServerApp] jupyter_lsp | extension was successfully loaded.
[I 2025-02-12 11:12:19.845 ServerApp] jupyter_server_terminals | extension was successfully loaded.
[I 2025-02-12 11:12:19.848 LabApp] JupyterLab extension loaded from /home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyterlab
[I 2025-02-12 11:12:19.848 LabApp] JupyterLab application directory is /home/ubuntu/anaconda3/envs/Project/share/jupyter/lab
[I 2025-02-12 11:12:19.848 LabApp] Extension Manager is 'pypi'.
[I 2025-02-12 11:12:19.876 ServerApp] jupyterlab | extension was successfully loaded.
[I 2025-02-12 11:12:19.880 ServerApp] notebook | extension was successfully loaded.
[I 2025-02-12 11:12:19.881 ServerApp] Serving notebooks from local directory: /home/lab13/project
[I 2025-02-12 11:12:19.881 ServerApp] Jupyter Server 2.14.2 is running at:
[I 2025-02-12 11:12:19.881 ServerApp] http://ip-172-31-13-81:8917/tree
[I 2025-02-12 11:12:19.881 ServerApp]     http://127.0.0.1:8917/tree
[I 2025-02-12 11:12:19.881 ServerApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[I 2025-02-12 11:12:19.900 ServerApp] Skipped non-installed server(s): bash-language-server, dockerfile-language-server-nodejs, javascript-typescript-langserver, jedi-language-server, julia-language-server, pyright, python-language-server, python-lsp-server, r-languageserver, sql-language-server, texlab, typescript-language-server, unified-language-server, vscode-css-languageserver-bin, vscode-html-languageserver-bin, vscode-json-languageserver-bin, yaml-language-server
[W 2025-02-12 11:12:24.046 ServerApp] 409 PATCH /api/contents/YJ/Untitled.ipynb?1739326343954 (125.129.250.60): File already exists: YJ/dags/Untitled.ipynb
[W 2025-02-12 11:12:24.047 ServerApp] wrote error: 'File already exists: YJ/dags/Untitled.ipynb'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_server/services/contents/handlers.py", line 204, in patch
        model = await ensure_async(cm.update(model, path))
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_core/utils/__init__.py", line 198, in ensure_async
        result = await obj
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_server/services/contents/manager.py", line 919, in update
        await self.rename(path, new_path)
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_server/services/contents/manager.py", line 906, in rename
        await self.rename_file(old_path, new_path)
      File "/home/ubuntu/anaconda3/envs/Project/lib/python3.8/site-packages/jupyter_server/services/contents/filemanager.py", line 1064, in rename_file
        raise web.HTTPError(409, "File already exists: %s" % new_path)
    tornado.web.HTTPError: HTTP 409: Conflict (File already exists: YJ/dags/Untitled.ipynb)
[W 2025-02-12 11:12:24.055 ServerApp] 409 PATCH /api/contents/YJ/Untitled.ipynb?1739326343954 (fd88012478e1480ba6af768e29928fbc@125.129.250.60) 10.50ms referer=http://15.168.221.131:8917/tree/YJ
[I 2025-02-12 11:12:27.566 ServerApp] Kernel started: 8d1dea47-8ae8-4304-8e66-26f62ea46afb
[I 2025-02-12 11:12:28.891 ServerApp] Connecting to kernel 8d1dea47-8ae8-4304-8e66-26f62ea46afb.
[I 2025-02-12 11:12:30.308 ServerApp] Connecting to kernel 8d1dea47-8ae8-4304-8e66-26f62ea46afb.
[I 2025-02-12 11:12:37.805 ServerApp] Connecting to kernel 8d1dea47-8ae8-4304-8e66-26f62ea46afb.
[I 2025-02-12 11:12:43.075 ServerApp] Starting buffering for 8d1dea47-8ae8-4304-8e66-26f62ea46afb:8df40301-825f-4d83-a0c4-146132d4a762
[I 2025-02-12 11:12:53.498 ServerApp] Connecting to kernel 8d1dea47-8ae8-4304-8e66-26f62ea46afb.
[I 2025-02-12 11:12:53.801 ServerApp] Starting buffering for 8d1dea47-8ae8-4304-8e66-26f62ea46afb:f42de2a9-7dcb-47c6-ae1a-db9bc944d204
[I 2025-02-12 11:12:53.954 ServerApp] Kernel started: 11cb6703-9f13-4a1a-866a-dc70f5b37d78
[I 2025-02-12 11:12:54.498 ServerApp] Connecting to kernel 11cb6703-9f13-4a1a-866a-dc70f5b37d78.
[I 2025-02-12 11:14:53.735 ServerApp] Saving file at /YJ/test/llama_test.ipynb
[I 2025-02-12 11:16:53.990 ServerApp] Saving file at /YJ/test/llama_test.ipynb
[I 2025-02-12 11:17:57.147 ServerApp] Saving file at /YJ/test/llama_test.ipynb
[I 2025-02-12 11:19:57.267 ServerApp] Saving file at /YJ/test/llama_test.ipynb
[I 2025-02-12 11:21:58.155 ServerApp] Saving file at /YJ/test/llama_test.ipynb
[I 2025-02-12 11:22:16.608 ServerApp] Kernel restarted: 11cb6703-9f13-4a1a-866a-dc70f5b37d78
[I 2025-02-12 11:22:16.637 ServerApp] Starting buffering for 11cb6703-9f13-4a1a-866a-dc70f5b37d78:3c92366a-76df-4e46-a4c2-952635741802
[I 2025-02-12 11:22:16.671 ServerApp] Connecting to kernel 11cb6703-9f13-4a1a-866a-dc70f5b37d78.
[I 2025-02-12 11:22:16.671 ServerApp] Restoring connection for 11cb6703-9f13-4a1a-866a-dc70f5b37d78:3c92366a-76df-4e46-a4c2-952635741802
[I 2025-02-12 11:23:58.289 ServerApp] Saving file at /YJ/test/llama_test.ipynb
[I 2025-02-12 11:25:58.521 ServerApp] Saving file at /YJ/test/llama_test.ipynb
[I 2025-02-12 11:27:58.661 ServerApp] Saving file at /YJ/test/llama_test.ipynb
[I 2025-02-12 11:30:47.743 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 11:32:47.862 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 11:34:48.035 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 11:49:34.978 ServerApp] Connecting to kernel 8d1dea47-8ae8-4304-8e66-26f62ea46afb.
[I 2025-02-12 11:49:35.059 ServerApp] Connecting to kernel 11cb6703-9f13-4a1a-866a-dc70f5b37d78.
[I 2025-02-12 11:49:35.338 ServerApp] Starting buffering for 8d1dea47-8ae8-4304-8e66-26f62ea46afb:631fcbce-d544-42fd-9dc0-d0763d57a4fa
[I 2025-02-12 11:49:35.575 ServerApp] Kernel started: f4bcb955-eebf-4c22-8303-cbc4758de986
[I 2025-02-12 11:49:36.728 ServerApp] Connecting to kernel f4bcb955-eebf-4c22-8303-cbc4758de986.
[I 2025-02-12 11:49:36.811 ServerApp] Connecting to kernel f4bcb955-eebf-4c22-8303-cbc4758de986.
[I 2025-02-12 11:49:36.881 ServerApp] Connecting to kernel f4bcb955-eebf-4c22-8303-cbc4758de986.
[I 2025-02-12 11:49:37.131 ServerApp] Connecting to kernel f4bcb955-eebf-4c22-8303-cbc4758de986.
[I 2025-02-12 11:49:39.192 ServerApp] Connecting to kernel f4bcb955-eebf-4c22-8303-cbc4758de986.
[I 2025-02-12 11:50:04.681 ServerApp] Kernel started: c2d5848c-8a78-42cb-9cb2-b7aab8c59871
[I 2025-02-12 11:50:04.682 ServerApp] Kernel shutdown: f4bcb955-eebf-4c22-8303-cbc4758de986
[I 2025-02-12 11:50:05.965 ServerApp] Connecting to kernel c2d5848c-8a78-42cb-9cb2-b7aab8c59871.
[I 2025-02-12 11:50:06.034 ServerApp] Connecting to kernel c2d5848c-8a78-42cb-9cb2-b7aab8c59871.
[I 2025-02-12 11:51:01.665 ServerApp] AsyncIOLoopKernelRestarter: restarting kernel (1/5), keep random ports
[W 2025-02-12 11:51:01.665 ServerApp] kernel c2d5848c-8a78-42cb-9cb2-b7aab8c59871 restarted
[I 2025-02-12 11:51:01.694 ServerApp] Starting buffering for c2d5848c-8a78-42cb-9cb2-b7aab8c59871:7cefd668-64ed-46f8-bfd3-a2e846c66799
[I 2025-02-12 11:51:01.725 ServerApp] Connecting to kernel c2d5848c-8a78-42cb-9cb2-b7aab8c59871.
[I 2025-02-12 11:51:01.725 ServerApp] Restoring connection for c2d5848c-8a78-42cb-9cb2-b7aab8c59871:7cefd668-64ed-46f8-bfd3-a2e846c66799
[I 2025-02-12 11:51:09.086 ServerApp] Connecting to kernel c2d5848c-8a78-42cb-9cb2-b7aab8c59871.
[I 2025-02-12 11:51:11.552 ServerApp] Connecting to kernel 8d1dea47-8ae8-4304-8e66-26f62ea46afb.
[I 2025-02-12 11:51:11.635 ServerApp] Connecting to kernel 11cb6703-9f13-4a1a-866a-dc70f5b37d78.
[I 2025-02-12 11:51:11.664 ServerApp] Starting buffering for 8d1dea47-8ae8-4304-8e66-26f62ea46afb:efe5a217-5dcb-422d-8d0c-3d4b19afd27f
[I 2025-02-12 11:51:12.325 ServerApp] Connecting to kernel 8d1dea47-8ae8-4304-8e66-26f62ea46afb.
[I 2025-02-12 11:51:12.397 ServerApp] Connecting to kernel 11cb6703-9f13-4a1a-866a-dc70f5b37d78.
[I 2025-02-12 11:51:12.460 ServerApp] Starting buffering for 8d1dea47-8ae8-4304-8e66-26f62ea46afb:3e3a5621-cbf7-4a0a-b36e-1ae8daf3295a
[I 2025-02-12 11:51:12.470 ServerApp] Connecting to kernel c2d5848c-8a78-42cb-9cb2-b7aab8c59871.
[I 2025-02-12 11:51:18.996 ServerApp] Connecting to kernel 8d1dea47-8ae8-4304-8e66-26f62ea46afb.
[I 2025-02-12 11:51:19.101 ServerApp] Connecting to kernel 11cb6703-9f13-4a1a-866a-dc70f5b37d78.
[I 2025-02-12 11:51:19.183 ServerApp] Connecting to kernel c2d5848c-8a78-42cb-9cb2-b7aab8c59871.
[I 2025-02-12 11:51:19.322 ServerApp] Starting buffering for 8d1dea47-8ae8-4304-8e66-26f62ea46afb:5ee13ff1-7310-4aaf-9aea-91ae273dce31
[I 2025-02-12 11:51:19.536 ServerApp] Connecting to kernel c2d5848c-8a78-42cb-9cb2-b7aab8c59871.
[I 2025-02-12 11:51:36.123 ServerApp] Saving file at /YJ/youtube_preprocessing2.ipynb
[I 2025-02-12 12:36:34.542 ServerApp] Saving file at /YJ/youtube_preprocessing2.ipynb
[I 2025-02-12 14:25:15.776 ServerApp] Connecting to kernel c2d5848c-8a78-42cb-9cb2-b7aab8c59871.
[I 2025-02-12 14:27:41.939 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 14:29:42.055 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 14:31:42.171 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 14:35:42.575 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 14:37:42.910 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 14:39:43.043 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 14:41:43.152 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 14:43:43.270 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 14:45:43.387 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 14:47:43.536 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 14:51:43.661 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 14:53:43.769 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 14:55:43.888 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 14:57:44.013 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 14:59:44.113 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 15:01:44.228 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 15:03:44.349 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 15:07:44.476 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 15:09:44.593 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 15:11:44.713 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 15:13:44.835 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 15:15:44.948 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 15:17:45.061 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 15:19:45.164 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 15:21:45.269 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 15:23:45.378 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 15:25:45.479 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 15:27:45.586 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 15:29:45.705 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 15:31:45.828 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 15:33:45.945 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 15:35:46.066 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 15:36:06.544 ServerApp] Kernel interrupted: 11cb6703-9f13-4a1a-866a-dc70f5b37d78
[I 2025-02-12 15:36:23.345 ServerApp] Kernel interrupted: 11cb6703-9f13-4a1a-866a-dc70f5b37d78
[I 2025-02-12 15:37:46.193 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 15:39:46.302 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 15:41:46.420 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 15:47:46.541 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 15:49:46.657 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 15:51:46.774 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 15:53:46.891 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 15:55:46.996 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 15:56:26.349 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 15:58:26.457 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 15:59:02.223 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 16:00:26.568 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 16:04:26.683 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 16:06:26.816 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 16:06:38.487 ServerApp] Kernel interrupted: 11cb6703-9f13-4a1a-866a-dc70f5b37d78
[I 2025-02-12 16:07:17.934 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 16:07:26.676 ServerApp] Kernel interrupted: 11cb6703-9f13-4a1a-866a-dc70f5b37d78
[I 2025-02-12 16:07:29.126 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 16:07:33.989 ServerApp] Kernel restarted: 11cb6703-9f13-4a1a-866a-dc70f5b37d78
[I 2025-02-12 16:07:34.023 ServerApp] Starting buffering for 11cb6703-9f13-4a1a-866a-dc70f5b37d78:3c92366a-76df-4e46-a4c2-952635741802
[I 2025-02-12 16:07:34.059 ServerApp] Connecting to kernel 11cb6703-9f13-4a1a-866a-dc70f5b37d78.
[I 2025-02-12 16:07:34.059 ServerApp] Restoring connection for 11cb6703-9f13-4a1a-866a-dc70f5b37d78:3c92366a-76df-4e46-a4c2-952635741802
[I 2025-02-12 16:09:29.256 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 16:09:40.704 ServerApp] Kernel interrupted: 11cb6703-9f13-4a1a-866a-dc70f5b37d78
[I 2025-02-12 16:11:29.430 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 16:12:55.058 ServerApp] Kernel interrupted: 11cb6703-9f13-4a1a-866a-dc70f5b37d78
[I 2025-02-12 16:13:29.549 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 16:13:41.090 ServerApp] Kernel interrupted: 11cb6703-9f13-4a1a-866a-dc70f5b37d78
[I 2025-02-12 16:15:29.673 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 16:15:36.260 ServerApp] Kernel interrupted: 11cb6703-9f13-4a1a-866a-dc70f5b37d78
[I 2025-02-12 16:17:29.801 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 16:17:35.504 ServerApp] Kernel interrupted: 11cb6703-9f13-4a1a-866a-dc70f5b37d78
[I 2025-02-12 16:17:57.252 ServerApp] Kernel interrupted: 11cb6703-9f13-4a1a-866a-dc70f5b37d78
[I 2025-02-12 16:18:29.055 ServerApp] Kernel interrupted: 11cb6703-9f13-4a1a-866a-dc70f5b37d78
[I 2025-02-12 16:19:29.916 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 16:19:32.670 ServerApp] Kernel interrupted: 11cb6703-9f13-4a1a-866a-dc70f5b37d78
[I 2025-02-12 16:20:38.269 ServerApp] Kernel interrupted: 11cb6703-9f13-4a1a-866a-dc70f5b37d78
[I 2025-02-12 16:21:05.237 ServerApp] Kernel interrupted: 11cb6703-9f13-4a1a-866a-dc70f5b37d78
[I 2025-02-12 16:21:30.038 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 16:21:43.421 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 16:23:43.534 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 16:25:43.647 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 16:27:43.783 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 16:33:57.006 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 16:33:59.923 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 16:34:08.167 ServerApp] Saving file at /YJ/test/llm_test.ipynb
[I 2025-02-12 16:34:17.626 ServerApp] Starting buffering for 11cb6703-9f13-4a1a-866a-dc70f5b37d78:3c92366a-76df-4e46-a4c2-952635741802
[I 2025-02-12 16:34:18.203 ServerApp] Starting buffering for c2d5848c-8a78-42cb-9cb2-b7aab8c59871:c76799a2-e4da-4bdb-a95c-55b8eb3ca188
[I 2025-02-12 16:34:25.772 ServerApp] Creating new notebook in /YJ/test
[I 2025-02-12 16:34:25.938 ServerApp] Saving file at /YJ/test/Untitled.ipynb
[I 2025-02-12 16:34:26.008 ServerApp] Kernel started: bb9e3ad7-05bc-4417-836a-454913f5a271
[I 2025-02-12 16:34:27.000 ServerApp] Connecting to kernel bb9e3ad7-05bc-4417-836a-454913f5a271.
[I 2025-02-12 16:34:27.250 ServerApp] Connecting to kernel 8d1dea47-8ae8-4304-8e66-26f62ea46afb.
[I 2025-02-12 16:34:27.332 ServerApp] Connecting to kernel 11cb6703-9f13-4a1a-866a-dc70f5b37d78.
[I 2025-02-12 16:34:27.406 ServerApp] Connecting to kernel c2d5848c-8a78-42cb-9cb2-b7aab8c59871.
[I 2025-02-12 16:34:27.478 ServerApp] Connecting to kernel bb9e3ad7-05bc-4417-836a-454913f5a271.
[I 2025-02-12 16:34:27.509 ServerApp] Starting buffering for 8d1dea47-8ae8-4304-8e66-26f62ea46afb:c816ff27-f337-497e-8520-496033cfe25e
[I 2025-02-12 16:34:27.514 ServerApp] Starting buffering for 11cb6703-9f13-4a1a-866a-dc70f5b37d78:d7e9d036-73dd-44c5-83f7-6d08c2fc2e4d
[I 2025-02-12 16:34:27.543 ServerApp] Starting buffering for c2d5848c-8a78-42cb-9cb2-b7aab8c59871:44879dff-3aba-401f-82f2-3c44510224d1
[I 2025-02-12 16:34:27.599 ServerApp] Connecting to kernel bb9e3ad7-05bc-4417-836a-454913f5a271.
[I 2025-02-12 16:34:42.728 ServerApp] Kernel started: 131a15ef-f2d5-464a-9243-0893fe2a4e05
[I 2025-02-12 16:34:42.729 ServerApp] Kernel shutdown: bb9e3ad7-05bc-4417-836a-454913f5a271
[I 2025-02-12 16:34:43.193 ServerApp] Connecting to kernel 131a15ef-f2d5-464a-9243-0893fe2a4e05.
[I 2025-02-12 16:36:48.948 ServerApp] Saving file at /YJ/test/openAI_test.ipynb
[W 2025-02-12 16:37:56.053 ServerApp] IOPub data rate exceeded.
    The Jupyter server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--ServerApp.iopub_data_rate_limit`.
    
    Current values:
    ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)
    ServerApp.rate_limit_window=3.0 (secs)
    
[I 2025-02-12 16:38:49.055 ServerApp] Saving file at /YJ/test/openAI_test.ipynb
[I 2025-02-12 16:40:21.117 ServerApp] Kernel interrupted: 131a15ef-f2d5-464a-9243-0893fe2a4e05
[W 2025-02-12 16:40:21.299 ServerApp] iopub messages resumed
[I 2025-02-12 16:40:49.212 ServerApp] Saving file at /YJ/test/openAI_test.ipynb
[I 2025-02-12 16:42:49.365 ServerApp] Saving file at /YJ/test/openAI_test.ipynb
[I 2025-02-12 16:44:49.502 ServerApp] Saving file at /YJ/test/openAI_test.ipynb
[I 2025-02-12 16:46:06.429 ServerApp] Saving file at /YJ/test/openAI_test.ipynb
[I 2025-02-12 16:48:02.057 ServerApp] Saving file at /YJ/test/openAI_test.ipynb
[I 2025-02-12 16:50:02.169 ServerApp] Saving file at /YJ/test/openAI_test.ipynb
[I 2025-02-12 16:51:11.695 ServerApp] Saving file at /YJ/test/openAI_test.ipynb
[I 2025-02-12 17:11:11.880 ServerApp] Saving file at /YJ/test/openAI_test.ipynb
[I 2025-02-12 17:13:11.997 ServerApp] Saving file at /YJ/test/openAI_test.ipynb
[I 2025-02-12 17:17:12.125 ServerApp] Saving file at /YJ/test/openAI_test.ipynb
[I 2025-02-12 17:19:12.253 ServerApp] Saving file at /YJ/test/openAI_test.ipynb
[I 2025-02-12 17:19:21.716 ServerApp] Kernel interrupted: 131a15ef-f2d5-464a-9243-0893fe2a4e05
[I 2025-02-12 17:21:12.368 ServerApp] Saving file at /YJ/test/openAI_test.ipynb
[I 2025-02-12 17:22:49.073 ServerApp] Saving file at /YJ/test/openAI_test.ipynb
[I 2025-02-12 17:29:12.491 ServerApp] Saving file at /YJ/test/openAI_test.ipynb
[I 2025-02-12 17:30:38.608 ServerApp] Saving file at /YJ/test/openAI_test.ipynb
[I 2025-02-12 17:46:38.745 ServerApp] Saving file at /YJ/test/openAI_test.ipynb
[I 2025-02-12 17:48:38.848 ServerApp] Saving file at /YJ/test/openAI_test.ipynb
[I 2025-02-12 17:50:38.965 ServerApp] Saving file at /YJ/test/openAI_test.ipynb
[I 2025-02-12 17:58:12.361 ServerApp] Saving file at /YJ/test/openAI_test.ipynb
[I 2025-02-12 17:58:13.041 ServerApp] Connecting to kernel 131a15ef-f2d5-464a-9243-0893fe2a4e05.
[I 2025-02-12 17:59:15.874 ServerApp] Connecting to kernel 8d1dea47-8ae8-4304-8e66-26f62ea46afb.
[I 2025-02-12 17:59:15.978 ServerApp] Connecting to kernel 11cb6703-9f13-4a1a-866a-dc70f5b37d78.
[I 2025-02-12 17:59:16.053 ServerApp] Connecting to kernel c2d5848c-8a78-42cb-9cb2-b7aab8c59871.
[I 2025-02-12 17:59:16.118 ServerApp] Connecting to kernel 131a15ef-f2d5-464a-9243-0893fe2a4e05.
[I 2025-02-12 17:59:16.147 ServerApp] Starting buffering for 11cb6703-9f13-4a1a-866a-dc70f5b37d78:190ad8d2-165c-4e5a-8523-415d401b55ac
[I 2025-02-12 17:59:16.148 ServerApp] Starting buffering for 8d1dea47-8ae8-4304-8e66-26f62ea46afb:6ce9f4c0-0409-49c2-9ded-14033cb97692
[I 2025-02-12 17:59:16.224 ServerApp] Starting buffering for c2d5848c-8a78-42cb-9cb2-b7aab8c59871:2589cb94-cd3b-452a-ba7e-a33b34383139
[I 2025-02-12 17:59:16.270 ServerApp] Connecting to kernel 131a15ef-f2d5-464a-9243-0893fe2a4e05.
[I 2025-02-12 17:59:19.269 ServerApp] Saving file at /YJ/test/openAI_test.ipynb
[I 2025-02-12 18:00:00.570 ServerApp] Saving file at /YJ/test/openAI_test.ipynb
[I 2025-02-12 18:00:25.507 ServerApp] Saving file at /YJ/test/openAI_test.ipynb
[I 2025-02-12 18:00:30.511 ServerApp] Saving file at /YJ/test/openAI_test.ipynb
[I 2025-02-12 18:00:35.811 ServerApp] Connecting to kernel 8d1dea47-8ae8-4304-8e66-26f62ea46afb.
[I 2025-02-12 18:00:35.914 ServerApp] Connecting to kernel 11cb6703-9f13-4a1a-866a-dc70f5b37d78.
[I 2025-02-12 18:00:35.999 ServerApp] Connecting to kernel c2d5848c-8a78-42cb-9cb2-b7aab8c59871.
[I 2025-02-12 18:00:36.082 ServerApp] Connecting to kernel 131a15ef-f2d5-464a-9243-0893fe2a4e05.
[I 2025-02-12 18:00:36.111 ServerApp] Starting buffering for 8d1dea47-8ae8-4304-8e66-26f62ea46afb:482ae72a-8f22-49b7-ac6e-7eb723fe4be1
[I 2025-02-12 18:00:36.112 ServerApp] Starting buffering for 11cb6703-9f13-4a1a-866a-dc70f5b37d78:924ba743-00f2-4422-9f1b-7d8d161aa19e
[I 2025-02-12 18:00:36.162 ServerApp] Starting buffering for c2d5848c-8a78-42cb-9cb2-b7aab8c59871:19c898bb-6987-4a60-96c3-e9063a4b5cf0
[I 2025-02-12 18:00:36.195 ServerApp] Kernel started: fc218f9f-de4e-4ed1-bb73-a7a35a6f92a2
[I 2025-02-12 18:00:37.575 ServerApp] Connecting to kernel fc218f9f-de4e-4ed1-bb73-a7a35a6f92a2.
[I 2025-02-12 18:00:37.654 ServerApp] Starting buffering for fc218f9f-de4e-4ed1-bb73-a7a35a6f92a2:ba60e43b-2dc9-4c85-a363-c73ba551e78f
[I 2025-02-12 18:00:37.659 ServerApp] Connecting to kernel fc218f9f-de4e-4ed1-bb73-a7a35a6f92a2.
[I 2025-02-12 18:00:37.737 ServerApp] Connecting to kernel fc218f9f-de4e-4ed1-bb73-a7a35a6f92a2.
[I 2025-02-12 18:00:37.813 ServerApp] Connecting to kernel fc218f9f-de4e-4ed1-bb73-a7a35a6f92a2.
[I 2025-02-12 18:00:39.371 ServerApp] Starting buffering for fc218f9f-de4e-4ed1-bb73-a7a35a6f92a2:66e0d856-6b5b-4688-b5a6-55322972380d
[I 2025-02-12 18:00:42.122 ServerApp] Connecting to kernel fc218f9f-de4e-4ed1-bb73-a7a35a6f92a2.
[I 2025-02-12 18:00:42.221 ServerApp] Starting buffering for fc218f9f-de4e-4ed1-bb73-a7a35a6f92a2:88861aaa-3b75-4083-8372-7dc757f72bcf
[I 2025-02-12 18:00:42.828 ServerApp] Kernel shutdown: fc218f9f-de4e-4ed1-bb73-a7a35a6f92a2
[W 2025-02-12 18:00:43.112 ServerApp] delete /YJ/test/openai_test.ipynb
[I 2025-02-12 18:00:45.803 ServerApp] Connecting to kernel 8d1dea47-8ae8-4304-8e66-26f62ea46afb.
[I 2025-02-12 18:00:45.895 ServerApp] Connecting to kernel 11cb6703-9f13-4a1a-866a-dc70f5b37d78.
[I 2025-02-12 18:00:45.964 ServerApp] Connecting to kernel c2d5848c-8a78-42cb-9cb2-b7aab8c59871.
[I 2025-02-12 18:00:46.033 ServerApp] Connecting to kernel 131a15ef-f2d5-464a-9243-0893fe2a4e05.
[I 2025-02-12 18:00:46.080 ServerApp] Starting buffering for 11cb6703-9f13-4a1a-866a-dc70f5b37d78:8aa9ac69-39be-49f0-9c53-c76dda67f50f
[I 2025-02-12 18:00:46.081 ServerApp] Starting buffering for 8d1dea47-8ae8-4304-8e66-26f62ea46afb:d6e5c573-46c0-4db4-800b-b82786a4fe8e
[I 2025-02-12 18:00:46.221 ServerApp] Starting buffering for c2d5848c-8a78-42cb-9cb2-b7aab8c59871:edaa5633-587c-4ab5-963f-db7e2dca83c4
[I 2025-02-12 18:00:46.267 ServerApp] Connecting to kernel 11cb6703-9f13-4a1a-866a-dc70f5b37d78.
[I 2025-02-12 18:00:51.756 ServerApp] Starting buffering for 11cb6703-9f13-4a1a-866a-dc70f5b37d78:642cc789-1838-4721-864f-d43447fe1a3f
