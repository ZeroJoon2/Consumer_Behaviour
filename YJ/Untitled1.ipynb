{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e08af8c-ed51-4f2a-916c-a70d3509eeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet('df1.parquet')\n",
    "df['title'] = 'TEST'\n",
    "df.to_parquet('TEST.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7f0ee87-a56c-4cc7-ad66-9692504235c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d730657-8446-4dc9-9ad9-a04f267434bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f488c42-801e-4109-a503-bd24667ceda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "[2025-02-08, 17:39:12 KST] {taskinstance.py:3311} ERROR - Task failed with exception\n",
    "Traceback (most recent call last):\n",
    "  File \"/home/ubuntu/anaconda3/envs/airflow_p38/lib/python3.8/site-packages/airflow/models/taskinstance.py\", line 767, in _execute_task\n",
    "    result = _execute_callable(context=context, **execute_callable_kwargs)\n",
    "  File \"/home/ubuntu/anaconda3/envs/airflow_p38/lib/python3.8/site-packages/airflow/models/taskinstance.py\", line 733, in _execute_callable\n",
    "    return ExecutionCallableRunner(\n",
    "  File \"/home/ubuntu/anaconda3/envs/airflow_p38/lib/python3.8/site-packages/airflow/utils/operator_helpers.py\", line 252, in run\n",
    "    return self.func(*args, **kwargs)\n",
    "  File \"/home/ubuntu/anaconda3/envs/airflow_p38/lib/python3.8/site-packages/airflow/models/baseoperator.py\", line 422, in wrapper\n",
    "    return func(self, *args, **kwargs)\n",
    "  File \"/home/ubuntu/anaconda3/envs/airflow_p38/lib/python3.8/site-packages/airflow/operators/python.py\", line 238, in execute\n",
    "    return_value = self.execute_callable()\n",
    "  File \"/home/ubuntu/anaconda3/envs/airflow_p38/lib/python3.8/site-packages/airflow/operators/python.py\", line 256, in execute_callable\n",
    "    return runner.run(*self.op_args, **self.op_kwargs)\n",
    "  File \"/home/ubuntu/anaconda3/envs/airflow_p38/lib/python3.8/site-packages/airflow/utils/operator_helpers.py\", line 252, in run\n",
    "    return self.func(*args, **kwargs)\n",
    "  File \"/home/lab13/airflow/dags/danawa_preprocessing.py\", line 93, in main\n",
    "    save_to_sql(df)\n",
    "  File \"/home/lab13/airflow/dags/danawa_preprocessing.py\", line 76, in save_to_sql\n",
    "    df.write.format('jdbc')\\\n",
    "  File \"/opt/spark/python/pyspark/sql/readwriter.py\", line 1107, in save\n",
    "    self._jwrite.save()\n",
    "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1304, in __call__\n",
    "    return_value = get_return_value(\n",
    "  File \"/opt/spark/python/pyspark/sql/utils.py\", line 111, in deco\n",
    "    return f(*a, **kw)\n",
    "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\", line 326, in get_return_value\n",
    "    raise Py4JJavaError(\n",
    "py4j.protocol.Py4JJavaError: An error occurred while calling o43.save.\n",
    ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 3 in stage 1.0 failed 1 times, most recent failure: Lost task 3.0 in stage 1.0 (TID 4) (ip-172-31-13-81.ap-northeast-3.compute.internal executor driver): java.sql.BatchUpdateException: Data truncated for column 'scoring' at row 1\n",
    "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
    "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
    "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
    "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
    "\tat com.mysql.jdbc.Util.handleNewInstance(Util.java:403)\n",
    "\tat com.mysql.jdbc.Util.getInstance(Util.java:386)\n",
    "\tat com.mysql.jdbc.SQLError.createBatchUpdateException(SQLError.java:1154)\n",
    "\tat com.mysql.jdbc.PreparedStatement.executeBatchSerially(PreparedStatement.java:1835)\n",
    "\tat com.mysql.jdbc.PreparedStatement.executeBatchInternal(PreparedStatement.java:1319)\n",
    "\tat com.mysql.jdbc.StatementImpl.executeBatch(StatementImpl.java:954)\n",
    "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:692)\n",
    "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:856)\n",
    "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:854)\n",
    "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1020)\n",
    "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1020)\n",
    "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2236)\n",
    "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
    "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
    "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
    "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
    "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
    "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
    "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
    "\tat java.lang.Thread.run(Thread.java:750)\n",
    "Caused by: java.sql.SQLException: Data truncated for column 'scoring' at row 1\n",
    "\tat com.mysql.jdbc.SQLError.createSQLException(SQLError.java:965)\n",
    "\tat com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3933)\n",
    "\tat com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3869)\n",
    "\tat com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:2524)\n",
    "\tat com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2675)\n",
    "\tat com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2465)\n",
    "\tat com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1915)\n",
    "\tat com.mysql.jdbc.PreparedStatement.executeUpdateInternal(PreparedStatement.java:2136)\n",
    "\tat com.mysql.jdbc.PreparedStatement.executeBatchSerially(PreparedStatement.java:1813)\n",
    "\t... 16 more\n",
    "Driver stacktrace:\n",
    "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)\n",
    "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)\n",
    "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)\n",
    "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
    "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
    "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
    "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)\n",
    "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1079)\n",
    "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1079)\n",
    "\tat scala.Option.foreach(Option.scala:407)\n",
    "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1079)\n",
    "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2445)\n",
    "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)\n",
    "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)\n",
    "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
    "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)\n",
    "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)\n",
    "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2217)\n",
    "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2236)\n",
    "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2261)\n",
    "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$1(RDD.scala:1020)\n",
    "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
    "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
    "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\n",
    "\tat org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:1018)\n",
    "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.saveTable(JdbcUtils.scala:854)\n",
    "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:68)\n",
    "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:46)\n",
    "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:70)\n",
    "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:68)\n",
    "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.doExecute(commands.scala:90)\n",
    "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)\n",
    "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\n",
    "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
    "\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\n",
    "\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:176)\n",
    "\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:132)\n",
    "\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:131)\n",
    "\tat org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:989)\n",
    "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
    "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
    "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
    "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
    "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
    "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:989)\n",
    "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:438)\n",
    "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:415)\n",
    "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:301)\n",
    "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
    "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
    "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
    "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
    "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
    "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
    "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
    "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
    "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
    "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
    "\tat java.lang.Thread.run(Thread.java:750)\n",
    "Caused by: java.sql.BatchUpdateException: Data truncated for column 'scoring' at row 1\n",
    "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
    "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
    "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
    "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
    "\tat com.mysql.jdbc.Util.handleNewInstance(Util.java:403)\n",
    "\tat com.mysql.jdbc.Util.getInstance(Util.java:386)\n",
    "\tat com.mysql.jdbc.SQLError.createBatchUpdateException(SQLError.java:1154)\n",
    "\tat com.mysql.jdbc.PreparedStatement.executeBatchSerially(PreparedStatement.java:1835)\n",
    "\tat com.mysql.jdbc.PreparedStatement.executeBatchInternal(PreparedStatement.java:1319)\n",
    "\tat com.mysql.jdbc.StatementImpl.executeBatch(StatementImpl.java:954)\n",
    "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:692)\n",
    "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:856)\n",
    "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:854)\n",
    "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1020)\n",
    "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1020)\n",
    "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2236)\n",
    "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
    "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
    "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
    "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
    "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
    "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
    "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
    "\t... 1 more\n",
    "Caused by: java.sql.SQLException: Data truncated for column 'scoring' at row 1\n",
    "\tat com.mysql.jdbc.SQLError.createSQLException(SQLError.java:965)\n",
    "\tat com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3933)\n",
    "\tat com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3869)\n",
    "\tat com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:2524)\n",
    "\tat com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2675)\n",
    "\tat com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2465)\n",
    "\tat com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1915)\n",
    "\tat com.mysql.jdbc.PreparedStatement.executeUpdateInternal(PreparedStatement.java:2136)\n",
    "\tat com.mysql.jdbc.PreparedStatement.executeBatchSerially(PreparedStatement.java:1813)\n",
    "\t... 16 more"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_p38",
   "language": "python",
   "name": "tensorflow_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
